
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.0">
    
    
      
        <title>Detr - kerod</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.8b42a75e.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.3f5d1f46.min.css">
        
          
          
          <meta name="theme-color" content="#e92063">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="pink" data-md-color-accent="amber">
  
    
    <script>function __prefix(e){return new URL("../../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-kerodmodeldetr" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="kerod" class="md-header__button md-logo" aria-label="kerod" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            kerod
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Detr
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/LSanselme/kerod/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    kerod
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="kerod" class="md-nav__button md-logo" aria-label="kerod" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    kerod
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/LSanselme/kerod/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    kerod
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../CONTRIBUTING/" class="md-nav__link">
        Contributing
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/BENCHMARKS/" class="md-nav__link">
        Benchmarks
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1">
          Kerod
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Kerod" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Kerod
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_2" type="checkbox" id="__nav_4_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_2">
          Core
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Core" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_2">
          <span class="md-nav__icon md-icon"></span>
          Core
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/box_coder/" class="md-nav__link">
        Box Coder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/box_ops/" class="md-nav__link">
        Box Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/constants/" class="md-nav__link">
        Constants
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/learning_rate_schedule/" class="md-nav__link">
        Learning Rate Schedule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/losses/" class="md-nav__link">
        Losses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/matcher/" class="md-nav__link">
        Matcher
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/sampling_ops/" class="md-nav__link">
        Sampling Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/similarity/" class="md-nav__link">
        Similarity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/standard_fields/" class="md-nav__link">
        Standard Fields
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core/target_assigner/" class="md-nav__link">
        Target Assigner
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_3" type="checkbox" id="__nav_4_1_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_3">
          Dataset
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Dataset" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_3">
          <span class="md-nav__icon md-icon"></span>
          Dataset
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/augmentation/" class="md-nav__link">
        Augmentation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/preprocessing/" class="md-nav__link">
        Preprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/utils/" class="md-nav__link">
        Utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_4" type="checkbox" id="__nav_4_1_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_4">
          Layers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Layers" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_4">
          <span class="md-nav__icon md-icon"></span>
          Layers
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/anchors/" class="md-nav__link">
        Anchors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/attentions/" class="md-nav__link">
        Attentions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/patches/" class="md-nav__link">
        Patches
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/positional_encoding/" class="md-nav__link">
        Positional Encoding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/transformer/" class="md-nav__link">
        Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_4_7" type="checkbox" id="__nav_4_1_4_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_4_7">
          Detection
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Detection" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_1_4_7">
          <span class="md-nav__icon md-icon"></span>
          Detection
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/detection/abstract_detection_head/" class="md-nav__link">
        Abstract Detection Head
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/detection/fast_rcnn/" class="md-nav__link">
        Fast Rcnn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/detection/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/detection/pooling_ops/" class="md-nav__link">
        Pooling Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/detection/rpn/" class="md-nav__link">
        Rpn
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_4_8" type="checkbox" id="__nav_4_1_4_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_4_8">
          Post Processing
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Post Processing" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_1_4_8">
          <span class="md-nav__icon md-icon"></span>
          Post Processing
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/post_processing/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/post_processing/non_maximum_suppression/" class="md-nav__link">
        Non Maximum Suppression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/post_processing/post_processing_detr/" class="md-nav__link">
        Post Processing Detr
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_4_9" type="checkbox" id="__nav_4_1_4_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_4_9">
          Smca
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Smca" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_1_4_9">
          <span class="md-nav__icon md-icon"></span>
          Smca
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/smca/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/smca/reference_points/" class="md-nav__link">
        Reference Points
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/smca/weight_map/" class="md-nav__link">
        Weight Map
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_5" type="checkbox" id="__nav_4_1_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_5">
          Model
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_5">
          <span class="md-nav__icon md-icon"></span>
          Model
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Detr
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Detr
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compute_detr_metrics" class="md-nav__link">
    compute_detr_metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#detr" class="md-nav__link">
    DeTr
  </a>
  
    <nav class="md-nav" aria-label="DeTr">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-arguments" class="md-nav__link">
    Call arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-returns" class="md-nav__link">
    Call returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detrresnet50" class="md-nav__link">
    DeTrResnet50
  </a>
  
    <nav class="md-nav" aria-label="DeTrResnet50">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments_1" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-arguments_1" class="md-nav__link">
    Call arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-returns_1" class="md-nav__link">
    Call returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call_1" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile_1" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss_1" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics_1" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_1" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator_1" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator_1" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer_1" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights_1" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function_1" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function_1" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function_1" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator_1" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch_1" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step_1" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics_1" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states_1" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_1" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec_1" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights_1" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch_1" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step_1" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json_1" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml_1" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch_1" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step_1" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detrresnet50pytorch" class="md-nav__link">
    DeTrResnet50Pytorch
  </a>
  
    <nav class="md-nav" aria-label="DeTrResnet50Pytorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments_2" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-arguments_2" class="md-nav__link">
    Call arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-returns_2" class="md-nav__link">
    Call returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call_2" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile_2" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss_2" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics_2" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_2" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator_2" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator_2" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer_2" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights_2" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function_2" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function_2" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function_2" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator_2" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch_2" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step_2" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics_2" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states_2" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_2" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec_2" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights_2" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_2" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch_2" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step_2" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json_2" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml_2" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch_2" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step_2" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../factory/" class="md-nav__link">
        Factory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../faster_rcnn/" class="md-nav__link">
        Faster Rcnn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../smca_detr/" class="md-nav__link">
        Smca Detr
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_5_6" type="checkbox" id="__nav_4_1_5_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_5_6">
          Backbone
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Backbone" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_1_5_6">
          <span class="md-nav__icon md-icon"></span>
          Backbone
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../backbone/fpn/" class="md-nav__link">
        Fpn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../backbone/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../backbone/resnet/" class="md-nav__link">
        Resnet
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_6" type="checkbox" id="__nav_4_1_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_6">
          Utils
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Utils" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_6">
          <span class="md-nav__icon md-icon"></span>
          Utils
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/documentation/" class="md-nav__link">
        Documentation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/drawing/" class="md-nav__link">
        Drawing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/ops/" class="md-nav__link">
        Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/training/" class="md-nav__link">
        Training
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compute_detr_metrics" class="md-nav__link">
    compute_detr_metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#detr" class="md-nav__link">
    DeTr
  </a>
  
    <nav class="md-nav" aria-label="DeTr">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-arguments" class="md-nav__link">
    Call arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-returns" class="md-nav__link">
    Call returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detrresnet50" class="md-nav__link">
    DeTrResnet50
  </a>
  
    <nav class="md-nav" aria-label="DeTrResnet50">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments_1" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-arguments_1" class="md-nav__link">
    Call arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-returns_1" class="md-nav__link">
    Call returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call_1" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile_1" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss_1" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics_1" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_1" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator_1" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator_1" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer_1" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights_1" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function_1" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function_1" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function_1" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_1" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator_1" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch_1" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step_1" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics_1" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states_1" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_1" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec_1" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights_1" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch_1" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step_1" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json_1" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml_1" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch_1" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step_1" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detrresnet50pytorch" class="md-nav__link">
    DeTrResnet50Pytorch
  </a>
  
    <nav class="md-nav" aria-label="DeTrResnet50Pytorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments_2" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-arguments_2" class="md-nav__link">
    Call arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-returns_2" class="md-nav__link">
    Call returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call_2" class="md-nav__link">
    call
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compile_2" class="md-nav__link">
    compile
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_loss_2" class="md-nav__link">
    compute_loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compute_metrics_2" class="md-nav__link">
    compute_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_2" class="md-nav__link">
    evaluate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate_generator_2" class="md-nav__link">
    evaluate_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_2" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_generator_2" class="md-nav__link">
    fit_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_layer_2" class="md-nav__link">
    get_layer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_weights_2" class="md-nav__link">
    load_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_predict_function_2" class="md-nav__link">
    make_predict_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_test_function_2" class="md-nav__link">
    make_test_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_train_function_2" class="md-nav__link">
    make_train_function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_2" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_generator_2" class="md-nav__link">
    predict_generator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_on_batch_2" class="md-nav__link">
    predict_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_step_2" class="md-nav__link">
    predict_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_metrics_2" class="md-nav__link">
    reset_metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reset_states_2" class="md-nav__link">
    reset_states
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_2" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_spec_2" class="md-nav__link">
    save_spec
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_weights_2" class="md-nav__link">
    save_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_2" class="md-nav__link">
    summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_on_batch_2" class="md-nav__link">
    test_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_step_2" class="md-nav__link">
    test_step
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_json_2" class="md-nav__link">
    to_json
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_yaml_2" class="md-nav__link">
    to_yaml
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_on_batch_2" class="md-nav__link">
    train_on_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_step_2" class="md-nav__link">
    train_step
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/LSanselme/kerod/edit/main/reference/kerod/model/detr.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="module-kerodmodeldetr">Module kerod.model.detr</h1>
<p>None</p>
<p>None</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.losses</span> <span class="kn">import</span> <span class="n">SparseCategoricalCrossentropy</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="kn">import</span> <span class="n">data_adapter</span>

<span class="kn">from</span> <span class="nn">tensorflow_addons.losses.giou_loss</span> <span class="kn">import</span> <span class="n">GIoULoss</span>

<span class="kn">from</span> <span class="nn">kerod.core.box_ops</span> <span class="kn">import</span> <span class="p">(</span><span class="n">convert_to_center_coordinates</span><span class="p">,</span> <span class="n">convert_to_xyxy_coordinates</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">kerod.core.losses</span> <span class="kn">import</span> <span class="n">L1Loss</span>

<span class="kn">from</span> <span class="nn">kerod.core.matcher</span> <span class="kn">import</span> <span class="n">hungarian_matching</span>

<span class="kn">from</span> <span class="nn">kerod.core.similarity</span> <span class="kn">import</span> <span class="n">DetrSimilarity</span>

<span class="kn">from</span> <span class="nn">kerod.core.standard_fields</span> <span class="kn">import</span> <span class="n">BoxField</span><span class="p">,</span> <span class="n">DatasetField</span>

<span class="kn">from</span> <span class="nn">kerod.core.target_assigner</span> <span class="kn">import</span> <span class="n">TargetAssigner</span>

<span class="kn">from</span> <span class="nn">kerod.layers</span> <span class="kn">import</span> <span class="n">PositionEmbeddingSine</span><span class="p">,</span> <span class="n">Transformer</span>

<span class="kn">from</span> <span class="nn">kerod.layers.post_processing.post_processing_detr</span> <span class="kn">import</span> \

    <span class="n">post_processing</span> <span class="k">as</span> <span class="n">detr_postprocessing</span>

<span class="kn">from</span> <span class="nn">kerod.model.backbone.resnet</span> <span class="kn">import</span> <span class="n">ResNet50</span><span class="p">,</span> <span class="n">ResNet50PytorchStyle</span>

<span class="kn">from</span> <span class="nn">kerod.utils</span> <span class="kn">import</span> <span class="n">item_assignment</span>

<span class="kn">from</span> <span class="nn">kerod.utils.documentation</span> <span class="kn">import</span> <span class="n">remove_unwanted_doc</span>

<span class="n">__pdoc__</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">class</span> <span class="nc">DeTr</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Build a DeTr model according to the paper</span>

<span class="sd">    [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)</span>

<span class="sd">    You can use it as follow:</span>

<span class="sd">    ```python</span>

<span class="sd">    model = DeTrResnet50Pytorch(80)</span>

<span class="sd">    base_lr = 0.1</span>

<span class="sd">    optimizer = tf.keras.optimizers.SGD(learning_rate=base_lr)</span>

<span class="sd">    model.compile(optimizer=optimizer, loss=None)</span>

<span class="sd">    model.fit(ds_train, validation_data=ds_test, epochs=11,)</span>

<span class="sd">    ```</span>

<span class="sd">    Arguments:</span>

<span class="sd">        num_classes: The number of classes of your dataset</span>

<span class="sd">            (**do not include the background class** it is handle for you)</span>

<span class="sd">        backbone: A vision model like ResNet50.</span>

<span class="sd">        num_queries: number of object queries, ie detection slot.</span>

<span class="sd">            This is the maximal number of objects</span>

<span class="sd">            DETR can detect in a single image. For COCO, we recommend 100 queries.</span>

<span class="sd">    Call arguments:</span>

<span class="sd">        inputs: Tuple</span>

<span class="sd">            1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="sd">            2. image_informations: A 1D tensor of float32 and shape [(height, width),].</span>

<span class="sd">                It contains the shape of the image without any padding.</span>

<span class="sd">            3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]</span>

<span class="sd">                composed of 0 and 1 which allows to know where a padding has been applied.</span>

<span class="sd">        training: Is automatically set to `True` in train mode</span>

<span class="sd">    Call returns:</span>

<span class="sd">        Tuple:</span>

<span class="sd">            - `logits`: A Tensor of shape [batch_size, h, num_classes + 1] class logits</span>

<span class="sd">            - `boxes`: A Tensor of shape [batch_size, h, 4]</span>

<span class="sd">            where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="sd">            training is true and num_queries otherwise.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">backbone</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_queries</span> <span class="o">=</span> <span class="n">num_queries</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">backbone</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_proj</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span> <span class="o">=</span> <span class="n">PositionEmbeddingSine</span><span class="p">(</span><span class="n">output_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span> <span class="o">=</span> <span class="mi">6</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span><span class="p">,</span>

                                       <span class="n">d_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>

                                       <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>

                                       <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (x1, y1, x2, y2)</span>

        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Will create a learnable embedding matrix for all our queries</span>

        <span class="c1"># It is a matrix of [num_queries, self.hidden_dim]</span>

        <span class="c1"># The embedding layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">query_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>

            <span class="n">num_queries</span><span class="p">,</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>

            <span class="n">embeddings_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomNormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">num_queries</span><span class="p">)</span>

        <span class="c1"># Loss computation</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weight_class</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_l1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_giou</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span>

        <span class="n">similarity_func</span> <span class="o">=</span> <span class="n">DetrSimilarity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_class</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_l1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_giou</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">target_assigner</span> <span class="o">=</span> <span class="n">TargetAssigner</span><span class="p">(</span><span class="n">similarity_func</span><span class="p">,</span>

                                              <span class="n">hungarian_matching</span><span class="p">,</span>

                                              <span class="k">lambda</span> <span class="n">gt</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">gt</span><span class="p">,</span>

                                              <span class="n">negative_class_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># Relative classification weight applied to the no-object category</span>

        <span class="c1"># It down-weight the log-probability term of a no-object</span>

        <span class="c1"># by a factor 10 to account for class imbalance</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">non_object_weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="c1"># Losses</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">giou</span> <span class="o">=</span> <span class="n">GIoULoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scc</span> <span class="o">=</span> <span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>

                                                 <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Metrics</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">giou_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;giou_last_layer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">l1_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;l1_last_layer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scc_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;scc_last_layer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">precision_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>

        <span class="c1"># Object recall = foreground</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">recall_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;object_recall&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="p">[</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">giou_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scc_metric</span><span class="p">,</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">precision_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">recall_metric</span>

        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Perform an inference in training.</span>

<span class="sd">        Arguments:</span>

<span class="sd">            inputs: Tuple</span>

<span class="sd">                1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="sd">                2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="sd">                of the image without any padding.</span>

<span class="sd">                3. images_padding_mask: A 3D tensor of int8 and shape</span>

<span class="sd">                    [batch_size, None, None] composed of 0 and 1 which</span>

<span class="sd">                    allows to know where a padding has been applied.</span>

<span class="sd">            training: Is automatically set to `True` in train mode</span>

<span class="sd">        Returns:</span>

<span class="sd">            Tuple:</span>

<span class="sd">                - `logits`: A Tensor of shape [batch_size, h, num_classes + 1] class logits</span>

<span class="sd">                - `boxes`: A Tensor of shape [batch_size, h, 4]</span>

<span class="sd">                where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="sd">                training is true and num_queries otherwise.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">]</span>

        <span class="n">images_padding_masks</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES_PMASK</span><span class="p">]</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>

                                        <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

                                        <span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ResizeMethod</span><span class="o">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>

        <span class="c1"># Positional_encoding for the backbone</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_the_queries</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">query_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span>

        <span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Flatten the position embedding and the spatial tensor</span>

        <span class="c1"># to allow the preprocessing by the Transformer</span>

        <span class="c1"># [batch_size, h * w,  self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="c1"># Flatten the padding masks</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">decoder_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>

                                          <span class="n">pos_embed</span><span class="p">,</span>

                                          <span class="n">query_embed</span><span class="p">,</span>

                                          <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span>

                                          <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="n">boxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">:</span> <span class="n">logits</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">:</span> <span class="n">boxes</span><span class="p">,</span>

        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">input_shape</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>

    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="sd">        Arguments:</span>

<span class="sd">            ground_truths: see output kerod.dataset.preprocessing for the doc</span>

<span class="sd">            y_pred: A dict</span>

<span class="sd">                - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="sd">                - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="sd">            input_shape: [height, width] of the input tensor.</span>

<span class="sd">                It is the shape of the images will all the padding included.</span>

<span class="sd">                It is used to normalize the ground_truths boxes.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">normalized_boxes</span> <span class="o">=</span> <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">]</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

        <span class="n">centered_normalized_boxes</span> <span class="o">=</span> <span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span>

        <span class="n">ground_truths</span> <span class="o">=</span> <span class="p">{</span>

            <span class="c1"># We add one because the background is not counted in ground_truths [BoxField.LABELS]</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>

                <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">:</span>

                <span class="n">centered_normalized_boxes</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">:</span>

                <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">],</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">NUM_BOXES</span><span class="p">:</span>

                <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">NUM_BOXES</span><span class="p">]</span>

        <span class="p">}</span>

        <span class="n">boxes_per_lvl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits_per_lvl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">y_pred_per_lvl</span> <span class="o">=</span> <span class="p">[{</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">:</span> <span class="n">boxes</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">:</span> <span class="n">logits</span>

        <span class="p">}</span> <span class="k">for</span> <span class="n">boxes</span><span class="p">,</span> <span class="n">logits</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">boxes_per_lvl</span><span class="p">,</span> <span class="n">logits_per_lvl</span><span class="p">)]</span>

        <span class="n">num_boxes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">NUM_BOXES</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Compute the Giou, L1 and SCC at each layers of the transformer decoder</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">):</span>

            <span class="c1"># Logs the metrics for the last layer of the decoder</span>

            <span class="n">compute_metrics</span> <span class="o">=</span> <span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span>

                                       <span class="n">ground_truths</span><span class="p">,</span>

                                       <span class="n">num_boxes</span><span class="p">,</span>

                                       <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">_compute_loss</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">num_boxes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>

        <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

    <span class="p">):</span>

        <span class="n">y_true</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_assigner</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">)</span>

        <span class="c1"># Reduce the class imbalanced by applying to the weights</span>

        <span class="c1"># self.non_object_weight for the non object (pos 0)</span>

        <span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_assignment</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span>

                                                   <span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>

                                                   <span class="bp">self</span><span class="o">.</span><span class="n">non_object_weight</span><span class="p">)</span>

        <span class="c1"># Caveats GIoU is buggy and if the batch_size is 1 and the sample_weight</span>

        <span class="c1"># is provided will raise an error</span>

        <span class="n">giou</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">giou</span><span class="p">(</span><span class="n">convert_to_xyxy_coordinates</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">]),</span>

                         <span class="n">convert_to_xyxy_coordinates</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">]),</span>

                         <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">])</span>

        <span class="n">l1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span>

                     <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span>

                     <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">])</span>

        <span class="c1"># SparseCategoricalCrossentropy</span>

        <span class="n">scc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scc</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span>

                       <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span>

                       <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">])</span>

        <span class="n">giou</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_giou</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">giou</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_boxes</span>

        <span class="n">l1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_l1</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_boxes</span>

        <span class="n">scc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_class</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">scc</span><span class="p">)</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">compute_metrics</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">giou_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">giou</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">l1_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">scc_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">scc</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">precision_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span>

                                               <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span>

                                               <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">])</span>

            <span class="n">recall</span> <span class="o">=</span> <span class="n">compute_detr_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">recall_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">giou</span> <span class="o">+</span> <span class="n">l1</span> <span class="o">+</span> <span class="n">scc</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># To compute the loss we need to get the results of each decoder layer</span>

        <span class="c1"># Setting training to True will provide it</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Perform an inference and returns the boxes, scores and labels associated.</span>

<span class="sd">        Background is discarded the max and argmax operation are performed.</span>

<span class="sd">        It means that if background was predicted the second maximum score would</span>

<span class="sd">        be outputed.</span>

<span class="sd">        Example: background + 3 classes</span>

<span class="sd">        [0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</span>

<span class="sd">        &quot;To optimize for AP, we override the prediction of these slots</span>

<span class="sd">        with the second highest scoring class, using the corresponding confidence&quot;</span>

<span class="sd">        Part 4. Experiments of Object Detection with Transformers</span>

<span class="sd">        Returns:</span>

<span class="sd">            boxes: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]</span>

<span class="sd">                containing the boxes with the coordinates between 0 and 1.</span>

<span class="sd">            scores: A Tensor of shape [batch_size, self.num_queries] containing</span>

<span class="sd">                the score of the boxes.</span>

<span class="sd">            classes: A Tensor of shape [batch_size, self.num_queries]</span>

<span class="sd">                containing the class of the boxes [0, num_classes).</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">detr_postprocessing</span><span class="p">(</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span>

            <span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES_INFO</span><span class="p">],</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

        <span class="p">)</span>

        <span class="k">return</span> <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span>

<span class="k">class</span> <span class="nc">DeTrResnet50</span><span class="p">(</span><span class="n">DeTr</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">resnet</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="n">num_queries</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DeTrResnet50Pytorch</span><span class="p">(</span><span class="n">DeTr</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50PytorchStyle</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">resnet</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="n">num_queries</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_detr_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Useful metrics that allows to track how behave the training.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        y_true: A one-hot encoded vector with shape [batch_size, num_object_queries, num_classes]</span>

<span class="sd">        y_pred: A tensor with shape [batch_size, num_object_queries, num_classes],</span>

<span class="sd">            representing the classification logits.</span>

<span class="sd">    Returns:</span>

<span class="sd">        tf.Tensor: Recall Among all the boxes that we had to find how much did we found.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">#Even if the softmax has not been applyed the argmax can be usefull</span>

    <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;label_prediction&#39;</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Compute accuracy and false negative on all the foreground boxes</span>

    <span class="n">fg_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">recall</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">fg_inds</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">recall</span>

<span class="n">remove_unwanted_doc</span><span class="p">(</span><span class="n">DeTr</span><span class="p">,</span> <span class="n">__pdoc__</span><span class="p">)</span>

<span class="n">remove_unwanted_doc</span><span class="p">(</span><span class="n">DeTrResnet50</span><span class="p">,</span> <span class="n">__pdoc__</span><span class="p">)</span>

<span class="n">remove_unwanted_doc</span><span class="p">(</span><span class="n">DeTrResnet50Pytorch</span><span class="p">,</span> <span class="n">__pdoc__</span><span class="p">)</span>
</code></pre></div>

</details>
<h2 id="functions">Functions</h2>
<h3 id="compute_detr_metrics">compute_detr_metrics</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_detr_metrics</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span>
</code></pre></div>

<p>Useful metrics that allows to track how behave the training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>y_true</td>
<td>A one-hot encoded vector with shape [batch_size, num_object_queries, num_classes]</td>
</tr>
<tr>
<td>y_pred</td>
<td>A tensor with shape [batch_size, num_object_queries, num_classes],<br>representing the classification logits.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>tf.Tensor</td>
<td>Recall Among all the boxes that we had to find how much did we found.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">compute_detr_metrics</span><span class="p">(</span><span class="nl">y_true:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"> </span><span class="nl">y_pred:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;Useful metrics that allows to track how behave the training.</span>

<span class="w">    </span><span class="nl">Arguments:</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_true:</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">one</span><span class="o">-</span><span class="n">hot</span><span class="w"> </span><span class="n">encoded</span><span class="w"> </span><span class="n">vector</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">num_object_queries</span><span class="p">,</span><span class="w"> </span><span class="n">num_classes</span><span class="p">]</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred:</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">num_object_queries</span><span class="p">,</span><span class="w"> </span><span class="n">num_classes</span><span class="p">],</span><span class="w"></span>

<span class="w">            </span><span class="n">representing</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">classification</span><span class="w"> </span><span class="n">logits</span><span class="p">.</span><span class="w"></span>

<span class="w">    </span><span class="nl">Returns:</span><span class="w"></span>

<span class="w">        </span><span class="n">tf</span><span class="p">.</span><span class="nl">Tensor:</span><span class="w"> </span><span class="n">Recall</span><span class="w"> </span><span class="n">Among</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">boxes</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">had</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">find</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">much</span><span class="w"> </span><span class="n">did</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">found</span><span class="p">.</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">    </span><span class="p">#</span><span class="n">Even</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">softmax</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">applyed</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">argmax</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">usefull</span><span class="w"></span>

<span class="w">    </span><span class="n">prediction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=-</span><span class="mh">1</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="o">=</span><span class="p">&#39;</span><span class="n">label_prediction</span><span class="p">&#39;,</span><span class="w"> </span><span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prediction</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="p">#</span><span class="w"> </span><span class="n">Compute</span><span class="w"> </span><span class="n">accuracy</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">false</span><span class="w"> </span><span class="n">negative</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">foreground</span><span class="w"> </span><span class="n">boxes</span><span class="w"></span>

<span class="w">    </span><span class="n">fg_inds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_true</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mh">0</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">recall</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span><span class="w"> </span><span class="n">fg_inds</span><span class="p">),</span><span class="w"> </span><span class="n">name</span><span class="o">=</span><span class="p">&#39;</span><span class="n">recall</span><span class="p">&#39;)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">recall</span><span class="w"></span>
</code></pre></div>

</details>
<h2 id="classes">Classes</h2>
<h3 id="detr">DeTr</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeTr</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">backbone</span><span class="p">,</span>
    <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p><a href="https://arxiv.org/abs/2005.12872">End-to-End Object Detection with Transformers</a></p>
<p>You can use it as follow:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">DeTrResnet50Pytorch</span><span class="p">(</span><span class="mi">80</span><span class="p">)</span>
<span class="n">base_lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">base_lr</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">ds_test</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">11</span><span class="p">,)</span>
</code></pre></div>

<h4 id="arguments">Arguments</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_classes</td>
<td>The number of classes of your dataset<br>(<strong>do not include the background class</strong> it is handle for you)</td>
</tr>
<tr>
<td>backbone</td>
<td>A vision model like ResNet50.</td>
</tr>
<tr>
<td>num_queries</td>
<td>number of object queries, ie detection slot.<br>This is the maximal number of objects<br>DETR can detect in a single image. For COCO, we recommend 100 queries.</td>
</tr>
</tbody>
</table>
<h4 id="call-arguments">Call arguments</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>Tuple<br>1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]<br>2. image_informations: A 1D tensor of float32 and shape [(height, width),].<br>    It contains the shape of the image without any padding.<br>3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]<br>    composed of 0 and 1 which allows to know where a padding has been applied.</td>
</tr>
<tr>
<td>training</td>
<td>Is automatically set to <code>True</code> in train mode</td>
</tr>
</tbody>
</table>
<h4 id="call-returns">Call returns</h4>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tuple</td>
<td>- <code>logits</code>: A Tensor of shape [batch_size, h, num_classes + 1] class logits<br>- <code>boxes</code>: A Tensor of shape [batch_size, h, 4]<br>where h is num_queries * transformer_decoder.transformer_num_layers if<br>training is true and num_queries otherwise.</td>
</tr>
</tbody>
</table>
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>keras.engine.training.Model</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
<li>keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="descendants">Descendants</h4>
<ul>
<li>kerod.model.detr.DeTrResnet50</li>
<li>kerod.model.detr.DeTrResnet50Pytorch</li>
</ul>
<h4 id="methods">Methods</h4>
<h4 id="call">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference in training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>Tuple<br>1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]<br>2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape<br>of the image without any padding.<br>3. images_padding_mask: A 3D tensor of int8 and shape<br>    [batch_size, None, None] composed of 0 and 1 which<br>    allows to know where a padding has been applied.</td>
</tr>
<tr>
<td>training</td>
<td>Is automatically set to <code>True</code> in train mode</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tuple</td>
<td>- <code>logits</code>: A Tensor of shape [batch_size, h, num_classes + 1] class logits<br>- <code>boxes</code>: A Tensor of shape [batch_size, h, 4]<br>where h is num_queries * transformer_decoder.transformer_num_layers if<br>training is true and num_queries otherwise.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Perform an inference in training.</span>

<span class="s2">        Arguments:</span>

<span class="s2">            inputs: Tuple</span>

<span class="s2">                1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="s2">                2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="s2">                of the image without any padding.</span>

<span class="s2">                3. images_padding_mask: A 3D tensor of int8 and shape</span>

<span class="s2">                    [batch_size, None, None] composed of 0 and 1 which</span>

<span class="s2">                    allows to know where a padding has been applied.</span>

<span class="s2">            training: Is automatically set to `True` in train mode</span>

<span class="s2">        Returns:</span>

<span class="s2">            Tuple:</span>

<span class="s2">                - `logits`: A Tensor of shape [batch_size, h, num_classes + 1] class logits</span>

<span class="s2">                - `boxes`: A Tensor of shape [batch_size, h, 4]</span>

<span class="s2">                where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="s2">                training is true and num_queries otherwise.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">images_padding_masks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_PMASK</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="err">[</span><span class="p">...,</span><span class="w"> </span><span class="k">None</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="w"></span>

<span class="w">                                        </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="err">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="err">]</span><span class="p">,</span><span class="w"></span>

<span class="w">                                        </span><span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ResizeMethod</span><span class="p">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="kt">bool</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Positional_encoding for the backbone</span><span class="w"></span>

<span class="w">        </span><span class="n">pos_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, num_queries, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">all_the_queries</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_the_queries</span><span class="err">[</span><span class="k">None</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, num_queries, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">query_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Flatten the position embedding and the spatial tensor</span><span class="w"></span>

<span class="w">        </span><span class="c1"># to allow the preprocessing by the Transformer</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, h * w,  self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="n">pos_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Flatten the padding masks</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="n">decoder_out</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">pos_embed</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">query_embed</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="o">:</span><span class="w"> </span><span class="n">logits</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="o">:</span><span class="w"> </span><span class="n">boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compile">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">jit_compile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span>
                       <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FalseNegatives</span><span class="p">()])</span>
</code></pre></div>

<p>Args:
    optimizer: String (name of optimizer) or optimizer instance. See
      <code>tf.keras.optimizers</code>.
    loss: Loss function. Maybe be a string (name of loss function), or
      a <code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. A loss
      function is any callable with the signature <code>loss = fn(y_true,
      y_pred)</code>, where <code>y_true</code> are the ground truth values, and
      <code>y_pred</code> are the model's predictions.
      <code>y_true</code> should have shape
      <code>(batch_size, d0, .. dN)</code> (except in the case of
      sparse loss functions such as
      sparse categorical crossentropy which expects integer arrays of shape
      <code>(batch_size, d0, .. dN-1)</code>).
      <code>y_pred</code> should have shape <code>(batch_size, d0, .. dN)</code>.
      The loss function should return a float tensor.
      If a custom <code>Loss</code> instance is
      used and reduction is set to <code>None</code>, return value has shape
      <code>(batch_size, d0, .. dN-1)</code> i.e. per-sample or per-timestep loss
      values; otherwise, it is a scalar. If the model has multiple outputs,
      you can use a different loss on each output by passing a dictionary
      or a list of losses. The loss value that will be minimized by the
      model will then be the sum of all individual losses, unless
      <code>loss_weights</code> is specified.
    metrics: List of metrics to be evaluated by the model during training
      and testing. Each of this can be a string (name of a built-in
      function), function or a <code>tf.keras.metrics.Metric</code> instance. See
      <code>tf.keras.metrics</code>. Typically you will use <code>metrics=['accuracy']</code>. A
      function is any callable with the signature <code>result = fn(y_true,
      y_pred)</code>. To specify different metrics for different outputs of a
      multi-output model, you could also pass a dictionary, such as
      <code>metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>.
      You can also pass a list to specify a metric or a list of metrics
      for each output, such as <code>metrics=[['accuracy'], ['accuracy', 'mse']]</code>
      or <code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the
      strings 'accuracy' or 'acc', we convert this to one of
      <code>tf.keras.metrics.BinaryAccuracy</code>,
      <code>tf.keras.metrics.CategoricalAccuracy</code>,
      <code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss
      function used and the model output shape. We do a similar
      conversion for the strings 'crossentropy' and 'ce' as well.
    loss_weights: Optional list or dictionary specifying scalar coefficients
      (Python floats) to weight the loss contributions of different model
      outputs. The loss value that will be minimized by the model will then
      be the <em>weighted sum</em> of all individual losses, weighted by the
      <code>loss_weights</code> coefficients.
        If a list, it is expected to have a 1:1 mapping to the model's
          outputs. If a dict, it is expected to map output names (strings)
          to scalar coefficients.
    weighted_metrics: List of metrics to be evaluated and weighted by
      <code>sample_weight</code> or <code>class_weight</code> during training and testing.
    run_eagerly: Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s
      logic will not be wrapped in a <code>tf.function</code>. Recommended to leave
      this as <code>None</code> unless your <code>Model</code> cannot be run inside a
      <code>tf.function</code>. <code>run_eagerly=True</code> is not supported when using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    steps_per_execution: Int. Defaults to 1. The number of batches to run
      during each <code>tf.function</code> call. Running multiple batches inside a
      single <code>tf.function</code> call can greatly improve performance on TPUs or
      small models with a large Python overhead. At most, one full epoch
      will be run each execution. If a number larger than the size of the
      epoch is passed, the execution will be truncated to the size of the
      epoch. Note that if <code>steps_per_execution</code> is set to <code>N</code>,
      <code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods will
      only be called every <code>N</code> batches (i.e. before/after each <code>tf.function</code>
      execution).
    jit_compile: If <code>True</code>, compile the model training step with XLA.
      <a href="https://www.tensorflow.org/xla">XLA</a> is an optimizing compiler for
      machine learning.
      <code>jit_compile</code> is not enabled for by default.
      This option cannot be enabled with <code>run_eagerly=True</code>.
      Note that <code>jit_compile=True</code> is
      may not necessarily work for all models.
      For more information on supported operations please refer to the
      <a href="https://www.tensorflow.org/xla">XLA documentation</a>.
      Also refer to
      <a href="https://www.tensorflow.org/xla/known_issues">known XLA issues</a> for
      more details.
    **kwargs: Arguments supported for backwards compatibility only.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="p">@</span><span class="n">traceback_utils</span><span class="p">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compile</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">optimizer</span><span class="o">=</span><span class="err">&#39;</span><span class="n">rmsprop</span><span class="err">&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">loss</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;Configures the model for training.</span>

<span class="w">    </span><span class="nl">Example</span><span class="p">:</span><span class="w"></span>

<span class="w">    </span><span class="err">```</span><span class="n">python</span><span class="w"></span>

<span class="w">    </span><span class="n">model</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span><span class="w"></span>

<span class="w">                  </span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span><span class="w"></span>

<span class="w">                  </span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span><span class="w"></span>

<span class="w">                           </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">FalseNegatives</span><span class="p">()])</span><span class="w"></span>

<span class="w">    </span><span class="err">```</span><span class="w"></span>

<span class="w">    </span><span class="nl">Args</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="nl">optimizer</span><span class="p">:</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">optimizer</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="n">function</span><span class="p">.</span><span class="w"> </span><span class="n">Maybe</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">or</span><span class="w"></span>

<span class="w">          </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ground</span><span class="w"> </span><span class="n">truth</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">predictions</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="p">(</span><span class="n">except</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"></span>

<span class="w">          </span><span class="n">sparse</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">functions</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"></span>

<span class="w">          </span><span class="n">sparse</span><span class="w"> </span><span class="n">categorical</span><span class="w"> </span><span class="n">crossentropy</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">integer</span><span class="w"> </span><span class="n">arrays</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="p">).</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">custom</span><span class="w"> </span><span class="err">`</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="n">is</span><span class="w"></span>

<span class="w">          </span><span class="n">used</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">reduction</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">sample</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">timestep</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">values</span><span class="p">;</span><span class="w"> </span><span class="n">otherwise</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">scalar</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">you</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">passing</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dictionary</span><span class="w"></span>

<span class="w">          </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">losses</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">unless</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">specified</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"></span>

<span class="w">          </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">built</span><span class="o">-</span><span class="k">in</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Metric</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Typically</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="n">multi</span><span class="o">-</span><span class="n">output</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dictionary</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="err">&#39;</span><span class="n">output_a</span><span class="err">&#39;</span><span class="o">:</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">output_b</span><span class="err">&#39;</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]}</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="w"></span>

<span class="w">          </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">&#39;</span><span class="n">acc</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">convert</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">of</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">CategoricalAccuracy</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="err">`</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">similar</span><span class="w"></span>

<span class="w">          </span><span class="n">conversion</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">crossentropy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">&#39;</span><span class="n">ce</span><span class="err">&#39;</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">well</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">loss_weights</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dictionary</span><span class="w"> </span><span class="n">specifying</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="n">coefficients</span><span class="w"></span>

<span class="w">          </span><span class="p">(</span><span class="n">Python</span><span class="w"> </span><span class="n">floats</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">contributions</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">model</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"></span>

<span class="w">          </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">*</span><span class="n">weighted</span><span class="w"> </span><span class="n">sum</span><span class="o">*</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w"></span>

<span class="w">            </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="w"> </span><span class="n">mapping</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"></span>

<span class="w">              </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dict</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">map</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="p">(</span><span class="n">strings</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">weighted_metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">sample_weight</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">class_weight</span><span class="err">`</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">run_eagerly</span><span class="p">:</span><span class="w"> </span><span class="n">Bool</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">False</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`&#39;</span><span class="n">s</span><span class="w"></span>

<span class="w">          </span><span class="n">logic</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">wrapped</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Recommended</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">leave</span><span class="w"></span>

<span class="w">          </span><span class="n">this</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="w"> </span><span class="n">unless</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">using</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">ParameterServerStrategy</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">steps_per_execution</span><span class="p">:</span><span class="w"> </span><span class="n">Int</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mf">1.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">run</span><span class="w"></span>

<span class="w">          </span><span class="n">during</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="p">.</span><span class="w"> </span><span class="n">Running</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="n">single</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">greatly</span><span class="w"> </span><span class="n">improve</span><span class="w"> </span><span class="n">performance</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">TPUs</span><span class="w"> </span><span class="n">or</span><span class="w"></span>

<span class="w">          </span><span class="n">small</span><span class="w"> </span><span class="n">models</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="n">overhead</span><span class="p">.</span><span class="w"> </span><span class="n">At</span><span class="w"> </span><span class="n">most</span><span class="p">,</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">full</span><span class="w"> </span><span class="n">epoch</span><span class="w"></span>

<span class="w">          </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">execution</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">larger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">passed</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">truncated</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_begin</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_end</span><span class="err">`</span><span class="w"> </span><span class="n">methods</span><span class="w"> </span><span class="n">will</span><span class="w"></span>

<span class="w">          </span><span class="n">only</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">every</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">before</span><span class="o">/</span><span class="n">after</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"></span>

<span class="w">          </span><span class="n">execution</span><span class="p">).</span><span class="w"></span>

<span class="w">        </span><span class="nl">jit_compile</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">compile</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">XLA</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">XLA</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla) is an optimizing compiler for</span>

<span class="w">          </span><span class="n">machine</span><span class="w"> </span><span class="n">learning</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="k">default</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">This</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"></span>

<span class="w">          </span><span class="n">may</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">necessarily</span><span class="w"> </span><span class="n">work</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">models</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">For</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">operations</span><span class="w"> </span><span class="n">please</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">XLA</span><span class="w"> </span><span class="n">documentation</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla).</span>

<span class="w">          </span><span class="n">Also</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">known</span><span class="w"> </span><span class="n">XLA</span><span class="w"> </span><span class="n">issues</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla/known_issues) for</span>

<span class="w">          </span><span class="n">more</span><span class="w"> </span><span class="n">details</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Arguments</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">backwards</span><span class="w"> </span><span class="n">compatibility</span><span class="w"> </span><span class="n">only</span><span class="p">.</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="err">&#39;</span><span class="n">compile</span><span class="err">&#39;</span><span class="p">).</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="err">&#39;</span><span class="n">experimental_steps_per_execution</span><span class="err">&#39;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="err">&#39;</span><span class="n">The</span><span class="w"> </span><span class="n">argument</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">longer</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">                        </span><span class="err">&#39;</span><span class="n">experimental</span><span class="p">.</span><span class="w"> </span><span class="n">Pass</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">instead</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">                        </span><span class="err">&#39;`</span><span class="n">experimental_steps_per_execution</span><span class="err">`</span><span class="p">.</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="err">&#39;</span><span class="n">experimental_steps_per_execution</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="cp"># When compiling from an already-serialized model, we do not want to</span>

<span class="w">      </span><span class="cp"># reapply some processing steps (e.g. metric renaming for multi-output</span>

<span class="w">      </span><span class="cp"># models, which have prefixes added for each corresponding output name).</span>

<span class="w">      </span><span class="n">from_serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="err">&#39;</span><span class="n">from_serialized</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">False</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_eagerly</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">loss_weights</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="n">weighted_metrics</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">from_serialized</span><span class="o">=</span><span class="n">from_serialized</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="cp"># Initializes attrs that are reset each time `compile` is called.</span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="p">{}</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dynamic</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="err">&#39;</span><span class="n">You</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">enable</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">            </span><span class="err">&#39;</span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">same</span><span class="w"> </span><span class="n">time</span><span class="p">.</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nl">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="nb">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jit_compile</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_loss">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

<p>Apply the GIoU, L1 and SCC to each layers of the transformer decoder</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ground_truths</td>
<td>see output kerod.dataset.preprocessing for the doc</td>
</tr>
<tr>
<td>y_pred</td>
<td>A dict<br>- <em>scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits<br>- </em>bbox*: A Tensor of shape [batch_size, num_queries, 4]</td>
</tr>
<tr>
<td>input_shape</td>
<td>[height, width] of the input tensor.<br>It is the shape of the images will all the padding included.<br>It is used to normalize the ground_truths boxes.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">ground_truths</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">int</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="ss">        Arguments:</span>

<span class="ss">            ground_truths: see output kerod.dataset.preprocessing for the doc</span>

<span class="ss">            y_pred: A dict</span>

<span class="ss">                - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="ss">                - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="ss">            input_shape: [height, width] of the input tensor.</span>

<span class="ss">                It is the shape of the images will all the padding included.</span>

<span class="ss">                It is used to normalize the ground_truths boxes.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, 2</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">centered_normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">counted</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">LABELS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">centered_normalized_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">WEIGHTS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.WEIGHTS</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">NUM_BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.SCORES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">{</span>

<span class="n">            BoxField.BOXES: boxes,</span>

<span class="n">            BoxField.SCORES: logits</span>

<span class="n">        } for boxes, logits in zip(boxes_per_lvl, logits_per_lvl)</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Giou</span><span class="p">,</span><span class="w"> </span><span class="n">L1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">SCC</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">layers</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Logs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">            </span><span class="n">compute_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">num_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_metrics">compute_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span>
<span class="p">)</span>
</code></pre></div>

<p>Update metric states and collect all metrics to be returned.</p>
<p>Subclasses can optionally override this method to provide custom metric
updating and collection logic.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>

    <span class="c1"># This super call updates `self.compiled_metrics` and returns results</span>
    <span class="c1"># for all metrics listed in `self.metrics`.</span>
    <span class="n">metric_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="c1"># Note that `self.custom_metric` is not listed in `self.metrics`.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">metric_results</span><span class="p">[</span><span class="s1">&#39;custom_metric_name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">metric_results</span>
</code></pre></div>

<p>Args:
  x: Input data.
  y: Target data.
  y_pred: Predictions returned by the model (output of <code>model.call(x)</code>)
  sample_weight: Sample weights for weighting the loss function.</p>
<p>Returns:
  A <code>dict</code> containing values that will be passed to
  <code>tf.keras.callbacks.CallbackList.on_train_batch_end()</code>. Typically, the
  values of the metrics listed in <code>self.metrics</code> are returned. Example:
  <code>{'loss': 0.2, 'accuracy': 0.7}</code>.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Update metric states and collect all metrics to be returned.</span>

<span class="s2">    Subclasses can optionally override this method to provide custom metric</span>

<span class="s2">    updating and collection logic.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    class MyModel(tf.keras.Sequential):</span>

<span class="s2">      def compute_metrics(self, x, y, y_pred, sample_weight):</span>

<span class="s2">        # This super call updates `self.compiled_metrics` and returns results</span>

<span class="s2">        # for all metrics listed in `self.metrics`.</span>

<span class="s2">        metric_results = super(MyModel, self).compute_metrics(</span>

<span class="s2">            x, y, y_pred, sample_weight)</span>

<span class="s2">        # Note that `self.custom_metric` is not listed in `self.metrics`.</span>

<span class="s2">        self.custom_metric.update_state(x, y, y_pred, sample_weight)</span>

<span class="s2">        metric_results[&#39;custom_metric_name&#39;] = self.custom_metric.result()</span>

<span class="s2">        return metric_results</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      x: Input data.</span>

<span class="s2">      y: Target data.</span>

<span class="s2">      y_pred: Predictions returned by the model (output of `model.call(x)`)</span>

<span class="s2">      sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">    Returns:</span>

<span class="s2">      A `dict` containing values that will be passed to</span>

<span class="s2">      `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the</span>

<span class="s2">      values of the metrics listed in `self.metrics` are returned. Example:</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Collect metrics to return</span><span class="w"></span>

<span class="w">    </span><span class="n">return_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">return_metrics</span><span class="p">.</span><span class="k">update</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">return_metrics</span><span class="err">[</span><span class="n">metric</span><span class="p">.</span><span class="k">name</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">return_metrics</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="evaluate">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>  if the model has named inputs.<br>- A <code>tf.data</code> dataset. Should return a tuple<br>  of either <code>(inputs, targets)</code> or<br>  <code>(inputs, targets, sample_weights)</code>.<br>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code><br>  or <code>(inputs, targets, sample_weights)</code>.<br>A more detailed description of unpacking behavior for iterator types<br>(Dataset, generator, Sequence) is given in the <code>Unpacking behavior&lt;br&gt;for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely). If<br><code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance, <code>y</code><br>should not be specified (since targets will be obtained from the<br>iterator/dataset).</td>
</tr>
<tr>
<td>batch_size</td>
<td>Integer or <code>None</code>. Number of samples per batch of<br>computation. If unspecified, <code>batch_size</code> will default to 32. Do not<br>specify the <code>batch_size</code> if your data is in the form of a dataset,<br>generators, or <code>keras.utils.Sequence</code> instances (since they generate<br>batches).</td>
</tr>
<tr>
<td>verbose</td>
<td>0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional Numpy array of weights for the test samples,<br>used for weighting the loss function. You can either pass a flat (1D)<br>Numpy array with the same length as the input samples<br>  (1:1 mapping between weights and samples), or in the case of<br>    temporal data, you can pass a 2D array with shape <code>(samples,&lt;br&gt;    sequence_length)</code>, to apply a different weight to every timestep<br>    of every sample. This argument is not supported when <code>x</code> is a<br>    dataset, instead pass sample weights as the third element of <code>x</code>.</td>
</tr>
<tr>
<td>steps</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)<br>before declaring the evaluation round finished. Ignored with the<br>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code> is<br>None, 'evaluate' will run until the dataset is exhausted. This<br>argument is not supported with array inputs.</td>
</tr>
<tr>
<td>callbacks</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of<br>callbacks to apply during evaluation. See<br><a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code><br>input only. Maximum size for the generator queue. If unspecified,<br><code>max_queue_size</code> will default to 10.</td>
</tr>
<tr>
<td>workers</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using process-based<br>threading. If unspecified, <code>workers</code> will default to 1.</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to the<br>generator as they can't be passed easily to children processes.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
<tr>
<td>**kwargs</td>
<td>Unused at this time.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">    Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">            if the model has named inputs.</span>

<span class="s2">          - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">            of either `(inputs, targets)` or</span>

<span class="s2">            `(inputs, targets, sample_weights)`.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="s2">            or `(inputs, targets, sample_weights)`.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>

<span class="s2">          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`</span>

<span class="s2">          should not be specified (since targets will be obtained from the</span>

<span class="s2">          iterator/dataset).</span>

<span class="s2">        batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">          computation. If unspecified, `batch_size` will default to 32. Do not</span>

<span class="s2">          specify the `batch_size` if your data is in the form of a dataset,</span>

<span class="s2">          generators, or `keras.utils.Sequence` instances (since they generate</span>

<span class="s2">          batches).</span>

<span class="s2">        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</span>

<span class="s2">        sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">          used for weighting the loss function. You can either pass a flat (1D)</span>

<span class="s2">          Numpy array with the same length as the input samples</span>

<span class="s2">            (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">              temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">              sequence_length)`, to apply a different weight to every timestep</span>

<span class="s2">              of every sample. This argument is not supported when `x` is a</span>

<span class="s2">              dataset, instead pass sample weights as the third element of `x`.</span>

<span class="s2">        steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">          before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">          default value of `None`. If x is a `tf.data` dataset and `steps` is</span>

<span class="s2">          None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">          argument is not supported with array inputs.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">          callbacks to apply during evaluation. See</span>

<span class="s2">          [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">          input only. Maximum size for the generator queue. If unspecified,</span>

<span class="s2">          `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">          only. Maximum number of processes to spin up when using process-based</span>

<span class="s2">          threading. If unspecified, `workers` will default to 1.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">          `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">          threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">          `False`. Note that because this implementation relies on</span>

<span class="s2">          multiprocessing, you should not pass non-picklable arguments to the</span>

<span class="s2">          generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">        **kwargs: Unused at this time.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">use_cached_eval_dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;_use_cached_eval_dataset&#39;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Invalid keyword arguments: {list(kwargs.keys())}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">coordinator</span><span class="p">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">use_cached_eval_dataset</span><span class="w"></span>

<span class="w">          </span><span class="k">and</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">        </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">            </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">profiler</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"> </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span><span class="w"></span>

<span class="w">                </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">              </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span><span class="w">  </span><span class="c1"># No error, now safe to assign to logs.</span><span class="w"></span>

<span class="w">              </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="evaluate_generator">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.evaluate` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.evaluate_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.evaluate`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="fit">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Args:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code>
        or <code>(inputs, targets, sample_weights)</code>.
      - A <code>tf.keras.utils.experimental.DatasetCreator</code>, which wraps a
        callable that takes a single argument of type
        <code>tf.distribute.InputContext</code>, and returns a <code>tf.data.Dataset</code>.
        <code>DatasetCreator</code> should be used when users prefer to specify the
        per-replica batching and sharding logic for the <code>Dataset</code>.
        See <code>tf.keras.utils.experimental.DatasetCreator</code> doc for more
        information.
      A more detailed description of unpacking behavior for iterator types
      (Dataset, generator, Sequence) is given below. If using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>, only
      <code>DatasetCreator</code> type is supported for <code>x</code>.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided
        (unless the <code>steps_per_epoch</code> flag is set to
        something other than None).
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 'auto', 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        'auto' defaults to 1 for most cases, but 2 when used with
        <code>ParameterServerStrategy</code>. Note that the progress bar is not
        particularly useful when logged to a file, so verbose=2 is
        recommended when not running interactively (eg, in a production
        environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note <code>tf.keras.callbacks.ProgbarLogger</code>
        and <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
        Callbacks with batch-level calls are currently unsupported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>, and users are
        advised to implement epoch-level calls instead with an appropriate
        <code>steps_per_epoch</code> value.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
        not supported when <code>x</code> is a dataset, generator or
       <code>keras.utils.Sequence</code> instance.
        <code>validation_split</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using <code>validation_split</code>
        or <code>validation_data</code> is not affected by regularization layers like
        noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - A tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors.
          - A tuple <code>(x_val, y_val, val_sample_weights)</code> of NumPy arrays.
          - A <code>tf.data.Dataset</code>.
          - A Python generator or <code>keras.utils.Sequence</code> returning
          <code>(inputs, targets)</code> or <code>(inputs, targets, sample_weights)</code>.
        <code>validation_data</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is ignored
        when <code>x</code> is a generator or an object of tf.data.Dataset.
        'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample. This
        argument is not supported when <code>x</code> is a dataset, generator, or
       <code>keras.utils.Sequence</code> instance, instead provide the sample_weights
        as the third element of <code>x</code>.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is exhausted.
        When passing an infinitely repeating dataset, you must specify the
        <code>steps_per_epoch</code> argument. If <code>steps_per_epoch=-1</code> the training
        will run indefinitely with an infinitely repeating dataset.
        This argument is not supported with array inputs.
        When using <code>tf.distribute.experimental.ParameterServerStrategy</code>:
          * <code>steps_per_epoch=None</code> is not supported.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None, validation
        will run until the <code>validation_data</code> dataset is exhausted. In the
        case of an infinitely repeated dataset, it will run into an
        infinite loop. If 'validation_steps' is specified and only part of
        the dataset will be consumed, the evaluation will start from the
        beginning of the dataset at each epoch. This ensures that the same
        validation samples are used every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    validation_freq: Only relevant if validation data is provided. Integer
        or <code>collections.abc.Container</code> instance (e.g. list, tuple, etc.).
        If an integer, specifies how many training epochs to run before a
        new validation run is performed, e.g. <code>validation_freq=2</code> runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
        validation at the end of the 1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or <code>keras.utils.Sequence</code>
        input only. Maximum size for the generator queue.
        If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as 'x'. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code>x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">In</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">mismatch</span><span class="w"> </span><span class="n">between</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"></span>
<span class="w">    </span><span class="n">and</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="o">.</span><span class="w"></span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Args:</span>

<span class="sd">        x: Input data. It could be:</span>

<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">            if the model has named inputs.</span>

<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">            of either `(inputs, targets)` or</span>

<span class="sd">            `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="sd">            or `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a</span>

<span class="sd">            callable that takes a single argument of type</span>

<span class="sd">            `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.</span>

<span class="sd">            `DatasetCreator` should be used when users prefer to specify the</span>

<span class="sd">            per-replica batching and sharding logic for the `Dataset`.</span>

<span class="sd">            See `tf.keras.utils.experimental.DatasetCreator` doc for more</span>

<span class="sd">            information.</span>

<span class="sd">          A more detailed description of unpacking behavior for iterator types</span>

<span class="sd">          (Dataset, generator, Sequence) is given below. If using</span>

<span class="sd">          `tf.distribute.experimental.ParameterServerStrategy`, only</span>

<span class="sd">          `DatasetCreator` type is supported for `x`.</span>

<span class="sd">        y: Target data. Like the input data `x`,</span>

<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">          not be specified (since targets will be obtained from `x`).</span>

<span class="sd">        batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per gradient update.</span>

<span class="sd">            If unspecified, `batch_size` will default to 32.</span>

<span class="sd">            Do not specify the `batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">            data provided</span>

<span class="sd">            (unless the `steps_per_epoch` flag is set to</span>

<span class="sd">            something other than None).</span>

<span class="sd">            Note that in conjunction with `initial_epoch`,</span>

<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">            The model is not trained for a number of iterations</span>

<span class="sd">            given by `epochs`, but merely until the epoch</span>

<span class="sd">            of index `epochs` is reached.</span>

<span class="sd">        verbose: &#39;auto&#39;, 0, 1, or 2. Verbosity mode.</span>

<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">            &#39;auto&#39; defaults to 1 for most cases, but 2 when used with</span>

<span class="sd">            `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="sd">            particularly useful when logged to a file, so verbose=2 is</span>

<span class="sd">            recommended when not running interactively (eg, in a production</span>

<span class="sd">            environment).</span>

<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`</span>

<span class="sd">            and `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">            and need not be passed into `model.fit`.</span>

<span class="sd">            `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">            `verbose` argument to `model.fit`.</span>

<span class="sd">            Callbacks with batch-level calls are currently unsupported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`, and users are</span>

<span class="sd">            advised to implement epoch-level calls instead with an appropriate</span>

<span class="sd">            `steps_per_epoch` value.</span>

<span class="sd">        validation_split: Float between 0 and 1.</span>

<span class="sd">            Fraction of the training data to be used as validation data.</span>

<span class="sd">            The model will set apart this fraction of the training data,</span>

<span class="sd">            will not train on it, and will evaluate</span>

<span class="sd">            the loss and any model metrics</span>

<span class="sd">            on this data at the end of each epoch.</span>

<span class="sd">            The validation data is selected from the last samples</span>

<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>

<span class="sd">            not supported when `x` is a dataset, generator or</span>

<span class="sd">           `keras.utils.Sequence` instance.</span>

<span class="sd">            `validation_split` is not yet supported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">        validation_data: Data on which to evaluate</span>

<span class="sd">            the loss and any model metrics at the end of each epoch.</span>

<span class="sd">            The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">            that the validation loss of data provided using `validation_split`</span>

<span class="sd">            or `validation_data` is not affected by regularization layers like</span>

<span class="sd">            noise and dropout.</span>

<span class="sd">            `validation_data` will override `validation_split`.</span>

<span class="sd">            `validation_data` could be:</span>

<span class="sd">              - A tuple `(x_val, y_val)` of Numpy arrays or tensors.</span>

<span class="sd">              - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.</span>

<span class="sd">              - A `tf.data.Dataset`.</span>

<span class="sd">              - A Python generator or `keras.utils.Sequence` returning</span>

<span class="sd">              `(inputs, targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">            `validation_data` is not yet supported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">            before each epoch) or str (for &#39;batch&#39;). This argument is ignored</span>

<span class="sd">            when `x` is a generator or an object of tf.data.Dataset.</span>

<span class="sd">            &#39;batch&#39; is a special option for dealing</span>

<span class="sd">            with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">            chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">            to a weight (float) value, used for weighting the loss function</span>

<span class="sd">            (during training only).</span>

<span class="sd">            This can be useful to tell the model to</span>

<span class="sd">            &quot;pay more attention&quot; to samples from</span>

<span class="sd">            an under-represented class.</span>

<span class="sd">        sample_weight: Optional Numpy array of weights for</span>

<span class="sd">            the training samples, used for weighting the loss function</span>

<span class="sd">            (during training only). You can either pass a flat (1D)</span>

<span class="sd">            Numpy array with the same length as the input samples</span>

<span class="sd">            (1:1 mapping between weights and samples),</span>

<span class="sd">            or in the case of temporal data,</span>

<span class="sd">            you can pass a 2D array with shape</span>

<span class="sd">            `(samples, sequence_length)`,</span>

<span class="sd">            to apply a different weight to every timestep of every sample. This</span>

<span class="sd">            argument is not supported when `x` is a dataset, generator, or</span>

<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>

<span class="sd">            as the third element of `x`.</span>

<span class="sd">        initial_epoch: Integer.</span>

<span class="sd">            Epoch at which to start training</span>

<span class="sd">            (useful for resuming a previous training run).</span>

<span class="sd">        steps_per_epoch: Integer or `None`.</span>

<span class="sd">            Total number of steps (batches of samples)</span>

<span class="sd">            before declaring one epoch finished and starting the</span>

<span class="sd">            next epoch. When training with input tensors such as</span>

<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">            the number of samples in your dataset divided by</span>

<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>

<span class="sd">            When passing an infinitely repeating dataset, you must specify the</span>

<span class="sd">            `steps_per_epoch` argument. If `steps_per_epoch=-1` the training</span>

<span class="sd">            will run indefinitely with an infinitely repeating dataset.</span>

<span class="sd">            This argument is not supported with array inputs.</span>

<span class="sd">            When using `tf.distribute.experimental.ParameterServerStrategy`:</span>

<span class="sd">              * `steps_per_epoch=None` is not supported.</span>

<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">            samples) to draw before stopping when performing validation</span>

<span class="sd">            at the end of every epoch. If &#39;validation_steps&#39; is None, validation</span>

<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>

<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>

<span class="sd">            infinite loop. If &#39;validation_steps&#39; is specified and only part of</span>

<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>

<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>

<span class="sd">            validation samples are used every time.</span>

<span class="sd">        validation_batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per validation batch.</span>

<span class="sd">            If unspecified, will default to `batch_size`.</span>

<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>

<span class="sd">            or `collections.abc.Container` instance (e.g. list, tuple, etc.).</span>

<span class="sd">            If an integer, specifies how many training epochs to run before a</span>

<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>

<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>

<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>

<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="sd">            input only. Maximum size for the generator queue.</span>

<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">            only. Maximum number of processes to spin up</span>

<span class="sd">            when using process-based threading. If unspecified, `workers`</span>

<span class="sd">            will default to 1.</span>

<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">            `False`. Note that because this implementation relies on</span>

<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">        A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">      yield not only features (x) but optionally targets (y) and sample weights.</span>

<span class="sd">      Keras requires that the output of such iterator-likes be unambiguous. The</span>

<span class="sd">      iterator should return a tuple of length 1, 2, or 3, where the optional</span>

<span class="sd">      second and third elements will be used for y and sample_weight</span>

<span class="sd">      respectively. Any other type provided will be wrapped in a length one</span>

<span class="sd">      tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they</span>

<span class="sd">      should still adhere to the top-level tuple structure.</span>

<span class="sd">      e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">      features, targets, and weights from the keys of a single dict.</span>

<span class="sd">        A notable unsupported data type is the namedtuple. The reason is that</span>

<span class="sd">      it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">      datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">          `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">      it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">      interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">          `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">      where it is unclear if the tuple was intended to be unpacked into x, y,</span>

<span class="sd">      and sample_weight or passed through as a single element to `x`. As a</span>

<span class="sd">      result the data processing code will simply raise a ValueError if it</span>

<span class="sd">      encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>

<span class="sd">        A `History` object. Its `History.history` attribute is</span>

<span class="sd">        a record of training loss values and metrics values</span>

<span class="sd">        at successive epochs, as well as validation loss values</span>

<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>

<span class="sd">        RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">        2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">        ValueError: In case of mismatch between the provided input data</span>

<span class="sd">            and what the model expects or when the input data is empty.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;auto&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w">  </span><span class="c1"># Default to epoch-level logging for PSStrategy.</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w">  </span><span class="c1"># Default to batch-level logging otherwise.</span><span class="w"></span>

<span class="w">    </span><span class="k">elif</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;`verbose=1` is not allowed with `ParameterServerStrategy` for &#39;</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="s1">&#39;performance reasons. Received: `verbose`={verbose}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">validation_split</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Create the validation data using the training data. Only supported for</span><span class="w"></span>

<span class="w">      </span><span class="c1"># `Tensor` and `NumPy` input.</span><span class="w"></span>

<span class="w">      </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">))</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">val_x</span><span class="p">,</span><span class="w"> </span><span class="n">val_y</span><span class="p">,</span><span class="w"> </span><span class="n">val_sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">))</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">coordinator</span><span class="o">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span>\<span class="w"></span>

<span class="w">         </span><span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Handle fault-tolerance for multi-worker.</span><span class="w"></span>

<span class="w">      </span><span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span><span class="w"></span>

<span class="w">      </span><span class="c1"># happen after `callbacks.on_train_begin`.</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">          </span><span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">))</span><span class="w"></span>

<span class="w">      </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span><span class="w"></span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span><span class="w"></span>

<span class="w">                </span><span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">              </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span><span class="w">  </span><span class="c1"># No error, now safe to assign to logs.</span><span class="w"></span>

<span class="w">              </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="k">break</span><span class="w"></span>

<span class="w">        </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">logs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected result of `train_function` &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;(Empty logs). Please use &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;`Model.compile(..., run_eagerly=True)`, or &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;`tf.config.run_functions_eagerly(True)` for more &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;information of where went wrong, or file a &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;issue/bug to `tf.keras`.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">epoch_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Run validation.</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">validation_freq</span><span class="p">):</span><span class="w"></span>

<span class="w">          </span><span class="c1"># Create data_handler for evaluation and cache it.</span><span class="w"></span>

<span class="w">          </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">_use_cached_eval_dataset</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="s1">&#39;val_&#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">epoch_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">epoch_logs</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="k">break</span><span class="w"></span>

<span class="w">      </span><span class="c1"># If eval data_handler exists, delete it after all epochs are done.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="fit_generator">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to use
  this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">fit_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.fit` now supports generators, so there is no longer any need to use</span>

<span class="ss">      this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.fit_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.fit`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_layer">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>String, name of layer.</td>
</tr>
<tr>
<td>index</td>
<td>Integer, index of layer.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">    If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">    Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">    Args:</span>

<span class="s2">        name: String, name of layer.</span>

<span class="s2">        index: Integer, index of layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A layer instance.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span><span class="w"></span>

<span class="w">    </span><span class="c1"># since they are constant, but we have not done that yet.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide only a layer name or a layer index. Received: &#39;</span><span class="w"></span>

<span class="w">                       </span><span class="n">f</span><span class="s1">&#39;index={index}, name={name}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="k">index</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Was asked to retrieve layer at index {index}&#39;</span><span class="w"></span>

<span class="w">                         </span><span class="n">f</span><span class="s1">&#39; but model only has {len(self.layers)}&#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39; layers.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">name</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="n">layer</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;No such layer: {name}. Existing layers are: &#39;</span><span class="w"></span>

<span class="w">                       </span><span class="n">f</span><span class="s1">&#39;{list(layer.name for layer in self.layers)}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index at &#39;</span><span class="w"></span>

<span class="w">                     </span><span class="s1">&#39;`get_layer`.&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="load_weights">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don't have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<code>tf.keras.Model</code>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>String, path to the weights file to load. For weight files in<br>TensorFlow format, this is the file prefix (the same as was passed<br>to <code>save_weights</code>). This can also be a path to a SavedModel<br>saved from <code>model.save</code>.</td>
</tr>
<tr>
<td>by_name</td>
<td>Boolean, whether to load weights by name or by topological<br>order. Only topological loading is supported for weight files in<br>TensorFlow format.</td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>Boolean, whether to skip loading of layers where there is<br>a mismatch in the number of weights, or a mismatch in the shape of<br>the weight (only valid when <code>by_name=True</code>).</td>
</tr>
<tr>
<td>options</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for loading weights.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same status<br>object as <code>tf.train.Checkpoint.restore</code>. When graph building, restore<br>ops are run automatically as soon as the network is built (on first call<br>for user-defined classes inheriting from <code>Model</code>, immediately if it is<br>already built).<br><br>When loading weights in HDF5 format, returns <code>None</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available and the weight file is in HDF5<br>format.</td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is<br><code>False</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">    If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">    topology. This means the architecture should be the same as when the weights</span>

<span class="sd">    were saved.  Note that layers that don&#39;t have weights are not taken into</span>

<span class="sd">    account in the topological ordering, so adding or removing layers is fine as</span>

<span class="sd">    long as they don&#39;t have weights.</span>

<span class="sd">    If `by_name` is True, weights are loaded into layers only if they share the</span>

<span class="sd">    same name. This is useful for fine-tuning or transfer-learning models where</span>

<span class="sd">    some of the layers have changed.</span>

<span class="sd">    Only topological loading (`by_name=False`) is supported when loading weights</span>

<span class="sd">    from the TensorFlow format. Note that topological loading differs slightly</span>

<span class="sd">    between TensorFlow and HDF5 formats for user-defined classes inheriting from</span>

<span class="sd">    `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>

<span class="sd">    TensorFlow format loads based on the object-local names of attributes to</span>

<span class="sd">    which layers are assigned in the `Model`&#39;s constructor.</span>

<span class="sd">    Args:</span>

<span class="sd">        filepath: String, path to the weights file to load. For weight files in</span>

<span class="sd">            TensorFlow format, this is the file prefix (the same as was passed</span>

<span class="sd">            to `save_weights`). This can also be a path to a SavedModel</span>

<span class="sd">            saved from `model.save`.</span>

<span class="sd">        by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">            order. Only topological loading is supported for weight files in</span>

<span class="sd">            TensorFlow format.</span>

<span class="sd">        skip_mismatch: Boolean, whether to skip loading of layers where there is</span>

<span class="sd">            a mismatch in the number of weights, or a mismatch in the shape of</span>

<span class="sd">            the weight (only valid when `by_name=True`).</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for loading weights.</span>

<span class="sd">    Returns:</span>

<span class="sd">        When loading a weight file in TensorFlow format, returns the same status</span>

<span class="sd">        object as `tf.train.Checkpoint.restore`. When graph building, restore</span>

<span class="sd">        ops are run automatically as soon as the network is built (on first call</span>

<span class="sd">        for user-defined classes inheriting from `Model`, immediately if it is</span>

<span class="sd">        already built).</span>

<span class="sd">        When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If `h5py` is not available and the weight file is in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">          `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"></span>

<span class="w">          </span><span class="p">(</span><span class="ow">not</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span><span class="w"></span>

<span class="w">        </span><span class="n">spr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not implemented with TPUStrategy &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;with `steps_per_run` greater than 1. The &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="n">f</span><span class="s1">&#39;`steps_per_run` is {spr}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;When calling model.load_weights, skip_mismatch can only be set to &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;True when by_name is True.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_detect_save_format</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Weights may only be loaded based on topology into Models when &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;loading TensorFlow-formatted weights (got by_name=True to &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;load_weights).&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Restore existing variables (if any) immediately, and set up a</span><span class="w"></span>

<span class="w">        </span><span class="c1"># streaming restore for any variables created in the future.</span><span class="w"></span>

<span class="w">        </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                   </span><span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;`load_weights` requires h5py package when loading weights from &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;HDF5. Try installing h5py.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Unable to load weights saved in HDF5 format into a subclassed &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Model which has not created its variables yet. Call the Model &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;first, then load the weights.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="s1">&#39;layer_names&#39;</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="s1">&#39;model_weights&#39;</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Perform any layer defined finalization of the layer state.</span><span class="w"></span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">layer</span><span class="o">.</span><span class="n">finalize_state</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">status</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_predict_function">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the predict function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">    This method can be overridden to support custom inference logic.</span>

<span class="s2">    This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.predict_step`.</span>

<span class="s2">    This function is cached the first time `Model.predict` or</span>

<span class="s2">    `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the predict function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">tf</span><span class="p">.</span><span class="n">autograph</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span><span class="p">(</span><span class="w"></span>

<span class="w">                  </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span><span class="w"></span>

<span class="w">                                </span><span class="k">for</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="err">]</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">step_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="o">:</span><span class="w"> </span><span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="err">]</span><span class="p">),</span><span class="w"></span>

<span class="w">                                          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">step_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">predict_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_test_function">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the test function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">    This method can be overridden to support custom evaluation logic.</span>

<span class="s2">    This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.test_step`.</span>

<span class="s2">    This function is cached the first time `Model.evaluate` or</span>

<span class="s2">    `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the test function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If we&#39;re using a coordinator, use the value of self._steps_per_execution</span><span class="w"></span>

<span class="w">    </span><span class="c1"># at the time the function is called/scheduled, and not when it is actually</span><span class="w"></span>

<span class="w">    </span><span class="c1"># executed.</span><span class="w"></span>

<span class="w">    </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">          </span><span class="n">test_function</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">()))</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_train_function">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the train function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">    This method can be overridden to support custom training logic.</span>

<span class="s2">    This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">    logic to `Model.train_step`.</span>

<span class="s2">    This function is cached the first time `Model.fit` or</span>

<span class="s2">    `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the train function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If we&#39;re using a coordinator, use the value of self._steps_per_execution</span><span class="w"></span>

<span class="w">    </span><span class="c1"># at the time the function is called/scheduled, and not when it is actually</span><span class="w"></span>

<span class="w">    </span><span class="c1"># executed.</span><span class="w"></span>

<span class="w">    </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">          </span><span class="n">train_function</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">()))</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for batch processing
of large numbers of inputs. It is not intended for use inside of loops
that iterate over your data and process small numbers of inputs at a time.</p>
<p>For small numbers of inputs that fit in one batch,
directly use <code>__call__()</code> for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behave differently during
inference. You may pair the individual model call with a <code>tf.function</code>
for additional performance inside your inner loop.
If you need access to numpy array values instead of tensors after your
model call, you can use <code>tensor.numpy()</code> to get the numpy array value of
an eager tensor.</p>
<p>Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p>Note: See <a href="https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call">this FAQ entry</a>
for more details about the difference between <code>Model</code> methods <code>predict()</code>
and <code>__call__()</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input samples. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A <code>tf.data</code> dataset.<br>- A generator or <code>keras.utils.Sequence</code> instance.<br>A more detailed description of unpacking behavior for iterator types<br>(Dataset, generator, Sequence) is given in the <code>Unpacking behavior&lt;br&gt;for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
</tr>
<tr>
<td>batch_size</td>
<td>Integer or <code>None</code>.<br>Number of samples per batch.<br>If unspecified, <code>batch_size</code> will default to 32.<br>Do not specify the <code>batch_size</code> if your data is in the<br>form of dataset, generators, or <code>keras.utils.Sequence</code> instances<br>(since they generate batches).</td>
</tr>
<tr>
<td>verbose</td>
<td>Verbosity mode, 0 or 1.</td>
</tr>
<tr>
<td>steps</td>
<td>Total number of steps (batches of samples)<br>before declaring the prediction round finished.<br>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code><br>dataset and <code>steps</code> is None, <code>predict()</code> will<br>run until the input dataset is exhausted.</td>
</tr>
<tr>
<td>callbacks</td>
<td>List of <code>keras.callbacks.Callback</code> instances.<br>List of callbacks to apply during prediction.<br>See <a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code><br>input only. Maximum size for the generator queue.<br>If unspecified, <code>max_queue_size</code> will default to 10.</td>
</tr>
<tr>
<td>workers</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default<br>to 1.</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children processes.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided<br>input data and the model's expectations,<br>or in case a stateful model receives a number of samples<br>that is not a multiple of the batch size.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">    Computation is done in batches. This method is designed for batch processing</span>

<span class="s2">    of large numbers of inputs. It is not intended for use inside of loops</span>

<span class="s2">    that iterate over your data and process small numbers of inputs at a time.</span>

<span class="s2">    For small numbers of inputs that fit in one batch,</span>

<span class="s2">    directly use `__call__()` for faster execution, e.g.,</span>

<span class="s2">    `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">    `tf.keras.layers.BatchNormalization` that behave differently during</span>

<span class="s2">    inference. You may pair the individual model call with a `tf.function`</span>

<span class="s2">    for additional performance inside your inner loop.</span>

<span class="s2">    If you need access to numpy array values instead of tensors after your</span>

<span class="s2">    model call, you can use `tensor.numpy()` to get the numpy array value of</span>

<span class="s2">    an eager tensor.</span>

<span class="s2">    Also, note the fact that test loss is not affected by</span>

<span class="s2">    regularization layers like noise and dropout.</span>

<span class="s2">    Note: See [this FAQ entry](</span>

<span class="s2">    https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)</span>

<span class="s2">    for more details about the difference between `Model` methods `predict()`</span>

<span class="s2">    and `__call__()`.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input samples. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A `tf.data` dataset.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        batch_size: Integer or `None`.</span>

<span class="s2">            Number of samples per batch.</span>

<span class="s2">            If unspecified, `batch_size` will default to 32.</span>

<span class="s2">            Do not specify the `batch_size` if your data is in the</span>

<span class="s2">            form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">            (since they generate batches).</span>

<span class="s2">        verbose: Verbosity mode, 0 or 1.</span>

<span class="s2">        steps: Total number of steps (batches of samples)</span>

<span class="s2">            before declaring the prediction round finished.</span>

<span class="s2">            Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">            dataset and `steps` is None, `predict()` will</span>

<span class="s2">            run until the input dataset is exhausted.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">            List of callbacks to apply during prediction.</span>

<span class="s2">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">            input only. Maximum size for the generator queue.</span>

<span class="s2">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">            only. Maximum number of processes to spin up when using</span>

<span class="s2">            process-based threading. If unspecified, `workers` will default</span>

<span class="s2">            to 1.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">            `False`. Note that because this implementation relies on</span>

<span class="s2">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`. Note that Model.predict uses the same interpretation rules as</span>

<span class="s2">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>

<span class="s2">    three methods.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Numpy array(s) of predictions.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.predict` is wrapped in a `tf.function`.</span>

<span class="s2">        ValueError: In case of mismatch between the provided</span>

<span class="s2">            input data and the model&#39;s expectations,</span>

<span class="s2">            or in case a stateful model receives a number of samples</span>

<span class="s2">            that is not a multiple of the batch size.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># TODO(yashkatariya): Cache model on the coordinator for faster prediction.</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If running under PSS, then swap it with OneDeviceStrategy so that</span><span class="w"></span>

<span class="w">    </span><span class="c1"># execution will run on the coordinator.</span><span class="w"></span>

<span class="w">    </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Cluster coordinator is set by `.fit()` and `.evaluate()` which is not</span><span class="w"></span>

<span class="w">    </span><span class="c1"># needed in `.predict()` because all the predictions happen on the</span><span class="w"></span>

<span class="w">    </span><span class="c1"># coordinator/locally.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">      </span><span class="n">dataset_types</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">_is_tpu_multi_host</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">))</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">try</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span><span class="w"></span>

<span class="w">          </span><span class="n">data_option</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span><span class="w"></span>

<span class="w">          </span><span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_option</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">except</span><span class="w"> </span><span class="n">ValueError</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;Using Model.predict with MultiWorkerMirroredStrategy or &#39;</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;TPUStrategy and AutoShardPolicy.FILE might lead to out-of-order &#39;</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;result. Consider setting it to AutoShardPolicy.DATA.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">tmp_batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_batch_outputs</span><span class="w">  </span><span class="c1"># No error, now safe to assign.</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span><span class="w"></span>

<span class="w">                                           </span><span class="n">batch_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="w"></span>

<span class="w">                  </span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"></span>

<span class="w">                  </span><span class="n">lambda</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">),</span><span class="w"></span>

<span class="w">                  </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">batch_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="s1">&#39;outputs&#39;</span><span class="o">:</span><span class="w"> </span><span class="n">batch_outputs</span><span class="err">}</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">batch_outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected result of `predict_function` &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;(Empty batch_outputs). Please use &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;`Model.compile(..., run_eagerly=True)`, or &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;`tf.config.run_functions_eagerly(True)` for more &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;information of where went wrong, or file a &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;issue/bug to `tf.keras`.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">all_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"> </span><span class="n">concat</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If originally PSS strategy was used, then replace it back since predict</span><span class="w"></span>

<span class="w">    </span><span class="c1"># is running under `OneDeviceStrategy` after the swap and once its done</span><span class="w"></span>

<span class="w">    </span><span class="c1"># we need to replace it back to PSS again.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_generator">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">predict_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.predict` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.predict_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.predict`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_on_batch">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">predict_on_batch</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">x</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Returns predictions for a single batch of samples.</span>

    <span class="nv">Args</span>:

        <span class="nv">x</span>: <span class="nv">Input</span> <span class="nv">data</span>. <span class="nv">It</span> <span class="nv">could</span> <span class="nv">be</span>:

          <span class="o">-</span> <span class="nv">A</span> <span class="nv">Numpy</span> <span class="nv">array</span> <span class="ss">(</span><span class="nv">or</span> <span class="nv">array</span><span class="o">-</span><span class="nv">like</span><span class="ss">)</span>, <span class="nv">or</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">of</span> <span class="nv">arrays</span> <span class="ss">(</span><span class="nv">in</span> <span class="nv">case</span> <span class="nv">the</span>

              <span class="nv">model</span> <span class="nv">has</span> <span class="nv">multiple</span> <span class="nv">inputs</span><span class="ss">)</span>.

          <span class="o">-</span> <span class="nv">A</span> <span class="nv">TensorFlow</span> <span class="nv">tensor</span>, <span class="nv">or</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">of</span> <span class="nv">tensors</span> <span class="ss">(</span><span class="nv">in</span> <span class="nv">case</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">has</span>

              <span class="nv">multiple</span> <span class="nv">inputs</span><span class="ss">)</span>.

    <span class="nv">Returns</span>:

        <span class="nv">Numpy</span> <span class="nv">array</span><span class="ss">(</span><span class="nv">s</span><span class="ss">)</span> <span class="nv">of</span> <span class="nv">predictions</span>.

    <span class="nv">Raises</span>:

        <span class="nv">RuntimeError</span>: <span class="k">If</span> `<span class="nv">model</span>.<span class="nv">predict_on_batch</span>` <span class="nv">is</span> <span class="nv">wrapped</span> <span class="nv">in</span> <span class="nv">a</span> `<span class="nv">tf</span>.<span class="nv">function</span>`.

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">self</span>.<span class="nv">_check_call_args</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">predict_on_batch</span><span class="s1">&#39;</span><span class="ss">)</span>

    <span class="nv">_disallow_inside_tf_function</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">predict_on_batch</span><span class="s1">&#39;</span><span class="ss">)</span>

    <span class="nv">with</span> <span class="nv">self</span>.<span class="nv">distribute_strategy</span>.<span class="nv">scope</span><span class="ss">()</span>:

      <span class="nv">iterator</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">single_batch_iterator</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>, <span class="nv">x</span><span class="ss">)</span>

      <span class="nv">self</span>.<span class="nv">predict_function</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">make_predict_function</span><span class="ss">()</span>

      <span class="nv">outputs</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">predict_function</span><span class="ss">(</span><span class="nv">iterator</span><span class="ss">)</span>

    <span class="k">return</span> <span class="nv">tf_utils</span>.<span class="nv">sync_to_numpy_or_python_type</span><span class="ss">(</span><span class="nv">outputs</span><span class="ss">)</span>
</code></pre></div>

</details>
<h4 id="predict_step">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference and returns the boxes, scores and labels associated.</p>
<p>Background is discarded the max and argmax operation are performed.
It means that if background was predicted the second maximum score would
be outputed.</p>
<p>Example: background + 3 classes
[0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</p>
<p>"To optimize for AP, we override the prediction of these slots
with the second highest scoring class, using the corresponding confidence"
Part 4. Experiments of Object Detection with Transformers</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>boxes</td>
<td>A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]<br>containing the boxes with the coordinates between 0 and 1.<br>scores: A Tensor of shape [batch_size, self.num_queries] containing<br>    the score of the boxes.<br>classes: A Tensor of shape [batch_size, self.num_queries]<br>    containing the class of the boxes [0, num_classes).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="nv">def</span> <span class="nv">predict_step</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">data</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Perform an inference and returns the boxes, scores and labels associated.</span>

        <span class="nv">Background</span> <span class="nv">is</span> <span class="nv">discarded</span> <span class="nv">the</span> <span class="nv">max</span> <span class="nv">and</span> <span class="nv">argmax</span> <span class="nv">operation</span> <span class="nv">are</span> <span class="nv">performed</span>.

        <span class="nv">It</span> <span class="nv">means</span> <span class="nv">that</span> <span class="k">if</span> <span class="nv">background</span> <span class="nv">was</span> <span class="nv">predicted</span> <span class="nv">the</span> <span class="nv">second</span> <span class="nv">maximum</span> <span class="nv">score</span> <span class="nv">would</span>

        <span class="nv">be</span> <span class="nv">outputed</span>.

        <span class="nv">Example</span>: <span class="nv">background</span> <span class="o">+</span> <span class="mi">3</span> <span class="nv">classes</span>

        [<span class="mi">0</span>.<span class="mi">54</span>, <span class="mi">0</span>.<span class="mi">40</span>, <span class="mi">0</span>.<span class="mi">03</span>, <span class="mi">0</span>.<span class="mi">03</span>] <span class="o">=&gt;</span> <span class="nv">score</span> <span class="o">=</span> <span class="mi">0</span>.<span class="mi">40</span>, <span class="nv">label</span> <span class="o">=</span> <span class="mi">0</span> <span class="ss">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="ss">)</span>

        <span class="s2">&quot;</span><span class="s">To optimize for AP, we override the prediction of these slots</span>

        <span class="nv">with</span> <span class="nv">the</span> <span class="nv">second</span> <span class="nv">highest</span> <span class="nv">scoring</span> <span class="nv">class</span>, <span class="nv">using</span> <span class="nv">the</span> <span class="nv">corresponding</span> <span class="nv">confidence</span><span class="s2">&quot;</span>

        <span class="nv">Part</span> <span class="mi">4</span>. <span class="nv">Experiments</span> <span class="nv">of</span> <span class="nv">Object</span> <span class="nv">Detection</span> <span class="nv">with</span> <span class="nv">Transformers</span>

        <span class="nv">Returns</span>:

            <span class="nv">boxes</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>, <span class="ss">(</span><span class="nv">y1</span>,<span class="nv">x1</span>,<span class="nv">y2</span>,<span class="nv">x2</span><span class="ss">)</span>]

                <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">boxes</span> <span class="nv">with</span> <span class="nv">the</span> <span class="nv">coordinates</span> <span class="nv">between</span> <span class="mi">0</span> <span class="nv">and</span> <span class="mi">1</span>.

            <span class="nv">scores</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>] <span class="nv">containing</span>

                <span class="nv">the</span> <span class="nv">score</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">boxes</span>.

            <span class="nv">classes</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>]

                <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">class</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">boxes</span> [<span class="mi">0</span>, <span class="nv">num_classes</span><span class="ss">)</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">data</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">expand_1d</span><span class="ss">(</span><span class="nv">data</span><span class="ss">)</span>

        <span class="nv">x</span>, <span class="nv">_</span>, <span class="nv">_</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">unpack_x_y_sample_weight</span><span class="ss">(</span><span class="nv">data</span><span class="ss">)</span>

        <span class="nv">y_pred</span> <span class="o">=</span> <span class="nv">self</span><span class="ss">(</span><span class="nv">x</span>, <span class="nv">training</span><span class="o">=</span><span class="nv">False</span><span class="ss">)</span>

        <span class="nv">boxes_without_padding</span>, <span class="nv">scores</span>, <span class="nv">labels</span> <span class="o">=</span> <span class="nv">detr_postprocessing</span><span class="ss">(</span>

            <span class="nv">y_pred</span>[<span class="nv">BoxField</span>.<span class="nv">BOXES</span>],

            <span class="nv">y_pred</span>[<span class="nv">BoxField</span>.<span class="nv">SCORES</span>],

            <span class="nv">x</span>[<span class="nv">DatasetField</span>.<span class="nv">IMAGES_INFO</span>],

            <span class="nv">tf</span>.<span class="nv">shape</span><span class="ss">(</span><span class="nv">x</span>[<span class="nv">DatasetField</span>.<span class="nv">IMAGES</span>]<span class="ss">)</span>[<span class="mi">1</span>:<span class="mi">3</span>],

        <span class="ss">)</span>

        <span class="k">return</span> <span class="nv">boxes_without_padding</span>, <span class="nv">scores</span>, <span class="nv">labels</span>
</code></pre></div>

</details>
<h4 id="reset_metrics">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
_ = model.fit(x, y, verbose=0)
assert all(float(m.result()) for m in model.metrics)</p>
<p>model.reset_metrics()
assert all(float(m.result()) == 0 for m in model.metrics)</p>
</blockquote>
</blockquote>
</blockquote>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">reset_metrics</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Resets the state of all the metrics in the model.</span>

    <span class="nv">Examples</span>:

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">inputs</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">layers</span>.<span class="nv">Input</span><span class="ss">(</span><span class="nv">shape</span><span class="o">=</span><span class="ss">(</span><span class="mi">3</span>,<span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">outputs</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">layers</span>.<span class="nv">Dense</span><span class="ss">(</span><span class="mi">2</span><span class="ss">)(</span><span class="nv">inputs</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">models</span>.<span class="nv">Model</span><span class="ss">(</span><span class="nv">inputs</span><span class="o">=</span><span class="nv">inputs</span>, <span class="nv">outputs</span><span class="o">=</span><span class="nv">outputs</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">optimizer</span><span class="o">=</span><span class="s2">&quot;</span><span class="s">Adam</span><span class="s2">&quot;</span>, <span class="nv">loss</span><span class="o">=</span><span class="s2">&quot;</span><span class="s">mse</span><span class="s2">&quot;</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s2">&quot;</span><span class="s">mae</span><span class="s2">&quot;</span>]<span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">x</span> <span class="o">=</span> <span class="nv">np</span>.<span class="k">random</span>.<span class="k">random</span><span class="ss">((</span><span class="mi">2</span>, <span class="mi">3</span><span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">y</span> <span class="o">=</span> <span class="nv">np</span>.<span class="k">random</span>.<span class="nv">randint</span><span class="ss">(</span><span class="mi">0</span>, <span class="mi">2</span>, <span class="ss">(</span><span class="mi">2</span>, <span class="mi">2</span><span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">_</span> <span class="o">=</span> <span class="nv">model</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">x</span>, <span class="nv">y</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">assert</span> <span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span> <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span>.<span class="nv">reset_metrics</span><span class="ss">()</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">assert</span> <span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">metrics</span>:

      <span class="nv">m</span>.<span class="nv">reset_state</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="reset_states">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">reset_states</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

    <span class="k">for</span> <span class="nv">layer</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">layers</span>:

      <span class="k">if</span> <span class="nv">hasattr</span><span class="ss">(</span><span class="nv">layer</span>, <span class="s1">&#39;</span><span class="s">reset_states</span><span class="s1">&#39;</span><span class="ss">)</span> <span class="nv">and</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">layer</span>, <span class="s1">&#39;</span><span class="s">stateful</span><span class="s1">&#39;</span>, <span class="nv">False</span><span class="ss">)</span>:

        <span class="nv">layer</span>.<span class="nv">reset_states</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="save">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p>Args:
    filepath: String, PathLike, path to SavedModel or H5 file to save the
        model.
    overwrite: Whether to silently overwrite any existing file at the
        target location, or provide the user with a manual prompt.
    include_optimizer: If True, save optimizer's state together.
    save_format: Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the
        model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,
        and 'h5' in TF 1.X.
    signatures: Signatures to save with the SavedModel. Applicable to the
        'tf' format only. Please see the <code>signatures</code> argument in
        <code>tf.saved_model.save</code> for details.
    options: (only applies to SavedModel format)
        <code>tf.saved_model.SaveOptions</code> object that specifies options for
        saving to SavedModel.
    save_traces: (only applies to SavedModel format) When enabled, the
        SavedModel will store the function traces for each layer. This
        can be disabled, so that only the configs of each layer are stored.
        Defaults to <code>True</code>. Disabling this will decrease serialization time
        and reduce file size, but it requires that all custom layers/models
        implement a <code>get_config()</code> method.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>  <span class="c1"># creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a compiled model</span>
<span class="c1"># identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="c1"># pylint: disable=line-too-long</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">    Please see `tf.keras.models.save_model` or the</span>

<span class="s2">    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">    for details.</span>

<span class="s2">    Args:</span>

<span class="s2">        filepath: String, PathLike, path to SavedModel or H5 file to save the</span>

<span class="s2">            model.</span>

<span class="s2">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">            target location, or provide the user with a manual prompt.</span>

<span class="s2">        include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">        save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">            model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X,</span>

<span class="s2">            and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">        signatures: Signatures to save with the SavedModel. Applicable to the</span>

<span class="s2">            &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">            `tf.saved_model.save` for details.</span>

<span class="s2">        options: (only applies to SavedModel format)</span>

<span class="s2">            `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">            saving to SavedModel.</span>

<span class="s2">        save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">            SavedModel will store the function traces for each layer. This</span>

<span class="s2">            can be disabled, so that only the configs of each layer are stored.</span>

<span class="s2">            Defaults to `True`. Disabling this will decrease serialization time</span>

<span class="s2">            and reduce file size, but it requires that all custom layers/models</span>

<span class="s2">            implement a `get_config()` method.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    from keras.models import load_model</span>

<span class="s2">    model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">    del model  # deletes the existing model</span>

<span class="s2">    # returns a compiled model</span>

<span class="s2">    # identical to the previous one</span>

<span class="s2">    model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># pylint: enable=line-too-long</span><span class="w"></span>

<span class="w">    </span><span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">overwrite</span><span class="p">,</span><span class="w"> </span><span class="n">include_optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">signatures</span><span class="p">,</span><span class="w"> </span><span class="k">options</span><span class="p">,</span><span class="w"> </span><span class="n">save_traces</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="save_spec">save_spec</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_spec</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dynamic_batch</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the <code>tf.TensorSpec</code> of call inputs as a tuple <code>(args, kwargs)</code>.</p>
<p>This value is automatically defined after calling the model for the first
time. Afterwards, you can use it when exporting the model for serving:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">serve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="c1"># Apply postprocessing steps, or add additional outputs.</span>
  <span class="o">...</span>
  <span class="k">return</span> <span class="n">outputs</span>

<span class="c1"># arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is</span>
<span class="c1"># an empty dict since functional models do not use keyword arguments.</span>
<span class="n">arg_specs</span><span class="p">,</span> <span class="n">kwarg_specs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">save_spec</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">signatures</span><span class="o">=</span><span class="p">{</span>
  <span class="s1">&#39;serving_default&#39;</span><span class="p">:</span> <span class="n">serve</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="o">*</span><span class="n">arg_specs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwarg_specs</span><span class="p">)</span>
<span class="p">})</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>dynamic_batch</td>
<td>Whether to set the batch sizes of all the returned<br><code>tf.TensorSpec</code> to <code>None</code>. (Note that when defining functional or<br>Sequential models with <code>tf.keras.Input([...], batch_size=X)</code>, the<br>batch size will always be preserved). Defaults to <code>True</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>If the model inputs are defined, returns a tuple <code>(args, kwargs)</code>. All<br>elements in <code>args</code> and <code>kwargs</code> are <code>tf.TensorSpec</code>.<br>If the model inputs are not defined, returns <code>None</code>.<br>The model inputs are automatically set when calling the model,<br><code>model.fit</code>, <code>model.evaluate</code> or <code>model.predict</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save_spec</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.</span>

<span class="s2">    This value is automatically defined after calling the model for the first</span>

<span class="s2">    time. Afterwards, you can use it when exporting the model for serving:</span>

<span class="s2">    ```python</span>

<span class="s2">    model = tf.keras.Model(...)</span>

<span class="s2">    @tf.function</span>

<span class="s2">    def serve(*args, **kwargs):</span>

<span class="s2">      outputs = model(*args, **kwargs)</span>

<span class="s2">      # Apply postprocessing steps, or add additional outputs.</span>

<span class="s2">      ...</span>

<span class="s2">      return outputs</span>

<span class="s2">    # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is</span>

<span class="s2">    # an empty dict since functional models do not use keyword arguments.</span>

<span class="s2">    arg_specs, kwarg_specs = model.save_spec()</span>

<span class="s2">    model.save(path, signatures={</span>

<span class="s2">      &#39;serving_default&#39;: serve.get_concrete_function(*arg_specs, **kwarg_specs)</span>

<span class="s2">    })</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      dynamic_batch: Whether to set the batch sizes of all the returned</span>

<span class="s2">        `tf.TensorSpec` to `None`. (Note that when defining functional or</span>

<span class="s2">        Sequential models with `tf.keras.Input([...], batch_size=X)`, the</span>

<span class="s2">        batch size will always be preserved). Defaults to `True`.</span>

<span class="s2">    Returns:</span>

<span class="s2">      If the model inputs are defined, returns a tuple `(args, kwargs)`. All</span>

<span class="s2">      elements in `args` and `kwargs` are `tf.TensorSpec`.</span>

<span class="s2">      If the model inputs are not defined, returns `None`.</span>

<span class="s2">      The model inputs are automatically set when calling the model,</span>

<span class="s2">      `model.fit`, `model.evaluate` or `model.predict`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_save_spec</span><span class="p">(</span><span class="n">dynamic_batch</span><span class="p">,</span><span class="w"> </span><span class="n">inputs_only</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="save_weights">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <code>tf.train.Checkpoint</code>, including any <code>Layer</code>
instances or <code>Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code>tf.keras.Model(inputs,
outputs)</code>, <code>Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <code>tf.keras.Model</code>,
<code>Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <code>tf.train.Checkpoint</code> and
<code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should be
loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code> this
is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached. This
means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading into a
<code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa) will not match
the <code>Model</code>'s variables. See the
<a href="https://www.tensorflow.org/guide/checkpoint">guide to training checkpoints</a>
for details on the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>String or PathLike, path to the file to save the weights to.<br>When saving in TensorFlow format, this is the prefix used for<br>checkpoint files (multiple files are generated). Note that the '.h5'<br>suffix causes weights to be saved in HDF5 format.</td>
</tr>
<tr>
<td>overwrite</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
</tr>
<tr>
<td>save_format</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or<br>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>. Otherwise<br><code>None</code> defaults to 'tf'.</td>
</tr>
<tr>
<td>options</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for saving weights.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available when attempting to save in HDF5<br>format.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">    Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">    argument.</span>

<span class="sd">    When saving in HDF5 format, the weight file has:</span>

<span class="sd">      - `layer_names` (attribute), a list of strings</span>

<span class="sd">          (ordered names of model layers).</span>

<span class="sd">      - For every layer, a `group` named `layer.name`</span>

<span class="sd">          - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">              a list of strings</span>

<span class="sd">              (ordered names of weights tensor of the layer).</span>

<span class="sd">          - For every weight in the layer, a dataset</span>

<span class="sd">              storing the weight value, named after the weight tensor.</span>

<span class="sd">    When saving in TensorFlow format, all objects referenced by the network are</span>

<span class="sd">    saved in the same format as `tf.train.Checkpoint`, including any `Layer`</span>

<span class="sd">    instances or `Optimizer` instances assigned to object attributes. For</span>

<span class="sd">    networks constructed from inputs and outputs using `tf.keras.Model(inputs,</span>

<span class="sd">    outputs)`, `Layer` instances used by the network are tracked/saved</span>

<span class="sd">    automatically. For user-defined classes which inherit from `tf.keras.Model`,</span>

<span class="sd">    `Layer` instances must be assigned to object attributes, typically in the</span>

<span class="sd">    constructor. See the documentation of `tf.train.Checkpoint` and</span>

<span class="sd">    `tf.keras.Model` for details.</span>

<span class="sd">    While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be</span>

<span class="sd">    loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">    `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">    `save_weights` for training checkpoints.</span>

<span class="sd">    The TensorFlow format matches objects and variables by starting at a root</span>

<span class="sd">    object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">    names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this</span>

<span class="sd">    is the `Checkpoint` even if the `Checkpoint` has a model attached. This</span>

<span class="sd">    means saving a `tf.keras.Model` using `save_weights` and loading into a</span>

<span class="sd">    `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match</span>

<span class="sd">    the `Model`&#39;s variables. See the</span>

<span class="sd">    [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)</span>

<span class="sd">    for details on the TensorFlow format.</span>

<span class="sd">    Args:</span>

<span class="sd">        filepath: String or PathLike, path to the file to save the weights to.</span>

<span class="sd">            When saving in TensorFlow format, this is the prefix used for</span>

<span class="sd">            checkpoint files (multiple files are generated). Note that the &#39;.h5&#39;</span>

<span class="sd">            suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">            target location, or provide the user with a manual prompt.</span>

<span class="sd">        save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">            &#39;.keras&#39; will default to HDF5 if `save_format` is `None`. Otherwise</span>

<span class="sd">            `None` defaults to &#39;tf&#39;.</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for saving weights.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If `h5py` is not available when attempting to save in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath_is_h5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">user_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">elif</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;hdf5&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;keras&#39;</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">f</span><span class="s1">&#39;Unknown format. Received: `save_format`={save_format}. Was &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="s1">&#39;filepath ({filepath}) looks like an HDF5 file. &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;Omit the &quot;.h5&quot;/&quot;.keras&quot; when saving in TensorFlow format.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;`save_weights` requires h5py when saving in hdf5, but h5py is not &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;available. Try installing h5py package.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;.index&#39;</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If file exists and should not be overwritten:</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">overwrite</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="n">proceed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">proceed</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Record this checkpoint so it&#39;s visible from tf.train.latest_checkpoint.</span><span class="w"></span>

<span class="w">      </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">update_checkpoint_state</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span><span class="w"></span>

<span class="w">          </span><span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">])</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="summary">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show_trainable</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>Total length of printed lines<br>(e.g. set this to adapt the display to different<br>terminal window sizes).</td>
</tr>
<tr>
<td>positions</td>
<td>Relative or absolute positions of log elements<br>in each line. If not provided,<br>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
</tr>
<tr>
<td>print_fn</td>
<td>Print function to use. Defaults to <code>print</code>.<br>It will be called on each line of the summary.<br>You can set it to a custom function<br>in order to capture the string summary.</td>
</tr>
<tr>
<td>expand_nested</td>
<td>Whether to expand the nested models.<br>If not provided, defaults to <code>False</code>.</td>
</tr>
<tr>
<td>show_trainable</td>
<td>Whether to show if a layer is trainable.<br>If not provided, defaults to <code>False</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">expand_nested</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">show_trainable</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">    Args:</span>

<span class="s2">        line_length: Total length of printed lines</span>

<span class="s2">            (e.g. set this to adapt the display to different</span>

<span class="s2">            terminal window sizes).</span>

<span class="s2">        positions: Relative or absolute positions of log elements</span>

<span class="s2">            in each line. If not provided,</span>

<span class="s2">            defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">        print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">            It will be called on each line of the summary.</span>

<span class="s2">            You can set it to a custom function</span>

<span class="s2">            in order to capture the string summary.</span>

<span class="s2">        expand_nested: Whether to expand the nested models.</span>

<span class="s2">            If not provided, defaults to `False`.</span>

<span class="s2">        show_trainable: Whether to show if a layer is trainable.</span>

<span class="s2">            If not provided, defaults to `False`.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;This model has not yet been built. &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;Build the model first by calling `build()` or by calling &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;the model on a batch of data.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">expand_nested</span><span class="o">=</span><span class="n">expand_nested</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">show_trainable</span><span class="o">=</span><span class="n">show_trainable</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="test_on_batch">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors, if<br>    the model has named inputs.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case of<br>temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated across<br>batches.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">test_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="s2">              model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="s2">              multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors, if</span>

<span class="s2">              the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="test_step">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="p">#</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">need</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">get</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">results</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">decoder</span><span class="w"> </span><span class="n">layer</span><span class="w"></span>

<span class="w">        </span><span class="p">#</span><span class="w"> </span><span class="n">Setting</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">True</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">provide</span><span class="w"> </span><span class="n">it</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mh">1</span><span class="o">:</span><span class="mh">3</span><span class="p">],</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_dtype</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">loss_metric</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">m</span><span class="p">.</span><span class="nl">name:</span><span class="w"> </span><span class="n">m</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">}</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="to_json">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>Additional keyword arguments<br>to be passed to <code>json.dumps()</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">    To load a network from a JSON save file, use</span>

<span class="sd">    `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">    Args:</span>

<span class="sd">        **kwargs: Additional keyword arguments</span>

<span class="sd">            to be passed to `json.dumps()`.</span>

<span class="sd">    Returns:</span>

<span class="sd">        A JSON string.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">model_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">model_config</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="to_yaml">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>Note: Since TF 2.6, this method is no longer supported and will raise a
RuntimeError.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>Additional keyword arguments<br>to be passed to <code>yaml.dump()</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>announces that the method poses a security risk</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">    Note: Since TF 2.6, this method is no longer supported and will raise a</span>

<span class="s2">    RuntimeError.</span>

<span class="s2">    To load a network from a yaml save file, use</span>

<span class="s2">    `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">    `custom_objects` should be a dictionary mapping</span>

<span class="s2">    the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">    functions / classes.</span>

<span class="s2">    Args:</span>

<span class="s2">        **kwargs: Additional keyword arguments</span>

<span class="s2">            to be passed to `yaml.dump()`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A YAML string.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: announces that the method poses a security risk</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">raise</span><span class="w"> </span><span class="n">RuntimeError</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Method `model.to_yaml()` has been removed due to security risk of &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;arbitrary code execution. Please use `model.to_json()` instead.&#39;</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="train_on_batch">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>    (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>    (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case of<br>temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
</tr>
<tr>
<td>class_weight</td>
<td>Optional dictionary mapping class indices (integers) to a<br>weight (float) to apply to the model's loss for the samples from this<br>class during training. This can be useful to tell the model to "pay<br>more attention" to samples from an under-represented class.</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated across<br>batches.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss<br>(if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">              if the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        class_weight: Optional dictionary mapping class indices (integers) to a</span>

<span class="s2">          weight (float) to apply to the model&#39;s loss for the samples from this</span>

<span class="s2">          class during training. This can be useful to tell the model to &quot;</span><span class="n">pay</span><span class="w"></span>

<span class="w">          </span><span class="n">more</span><span class="w"> </span><span class="n">attention</span><span class="s2">&quot; to samples from an under-represented class.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar training loss</span>

<span class="s2">        (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">      RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">         </span><span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">class_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="train_step">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">tape</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span><span class="w"> </span><span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span><span class="w"></span>
</code></pre></div>

</details>
<h3 id="detrresnet50">DeTrResnet50</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeTrResnet50</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="p">,</span>
    <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p><a href="https://arxiv.org/abs/2005.12872">End-to-End Object Detection with Transformers</a></p>
<p>You can use it as follow:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">DeTrResnet50Pytorch</span><span class="p">(</span><span class="mi">80</span><span class="p">)</span>
<span class="n">base_lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">base_lr</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">ds_test</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">11</span><span class="p">,)</span>
</code></pre></div>

<h4 id="arguments_1">Arguments</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_classes</td>
<td>The number of classes of your dataset<br>(<strong>do not include the background class</strong> it is handle for you)</td>
</tr>
<tr>
<td>backbone</td>
<td>A vision model like ResNet50.</td>
</tr>
<tr>
<td>num_queries</td>
<td>number of object queries, ie detection slot.<br>This is the maximal number of objects<br>DETR can detect in a single image. For COCO, we recommend 100 queries.</td>
</tr>
</tbody>
</table>
<h4 id="call-arguments_1">Call arguments</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>Tuple<br>1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]<br>2. image_informations: A 1D tensor of float32 and shape [(height, width),].<br>    It contains the shape of the image without any padding.<br>3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]<br>    composed of 0 and 1 which allows to know where a padding has been applied.</td>
</tr>
<tr>
<td>training</td>
<td>Is automatically set to <code>True</code> in train mode</td>
</tr>
</tbody>
</table>
<h4 id="call-returns_1">Call returns</h4>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tuple</td>
<td>- <code>logits</code>: A Tensor of shape [batch_size, h, num_classes + 1] class logits<br>- <code>boxes</code>: A Tensor of shape [batch_size, h, 4]<br>where h is num_queries * transformer_decoder.transformer_num_layers if<br>training is true and num_queries otherwise.</td>
</tr>
</tbody>
</table>
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>kerod.model.detr.DeTr</li>
<li>keras.engine.training.Model</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
<li>keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="methods_1">Methods</h4>
<h4 id="call_1">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference in training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>Tuple<br>1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]<br>2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape<br>of the image without any padding.<br>3. images_padding_mask: A 3D tensor of int8 and shape<br>    [batch_size, None, None] composed of 0 and 1 which<br>    allows to know where a padding has been applied.</td>
</tr>
<tr>
<td>training</td>
<td>Is automatically set to <code>True</code> in train mode</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tuple</td>
<td>- <code>logits</code>: A Tensor of shape [batch_size, h, num_classes + 1] class logits<br>- <code>boxes</code>: A Tensor of shape [batch_size, h, 4]<br>where h is num_queries * transformer_decoder.transformer_num_layers if<br>training is true and num_queries otherwise.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Perform an inference in training.</span>

<span class="s2">        Arguments:</span>

<span class="s2">            inputs: Tuple</span>

<span class="s2">                1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="s2">                2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="s2">                of the image without any padding.</span>

<span class="s2">                3. images_padding_mask: A 3D tensor of int8 and shape</span>

<span class="s2">                    [batch_size, None, None] composed of 0 and 1 which</span>

<span class="s2">                    allows to know where a padding has been applied.</span>

<span class="s2">            training: Is automatically set to `True` in train mode</span>

<span class="s2">        Returns:</span>

<span class="s2">            Tuple:</span>

<span class="s2">                - `logits`: A Tensor of shape [batch_size, h, num_classes + 1] class logits</span>

<span class="s2">                - `boxes`: A Tensor of shape [batch_size, h, 4]</span>

<span class="s2">                where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="s2">                training is true and num_queries otherwise.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">images_padding_masks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_PMASK</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="err">[</span><span class="p">...,</span><span class="w"> </span><span class="k">None</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="w"></span>

<span class="w">                                        </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="err">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="err">]</span><span class="p">,</span><span class="w"></span>

<span class="w">                                        </span><span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ResizeMethod</span><span class="p">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="kt">bool</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Positional_encoding for the backbone</span><span class="w"></span>

<span class="w">        </span><span class="n">pos_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, num_queries, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">all_the_queries</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_the_queries</span><span class="err">[</span><span class="k">None</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, num_queries, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">query_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Flatten the position embedding and the spatial tensor</span><span class="w"></span>

<span class="w">        </span><span class="c1"># to allow the preprocessing by the Transformer</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, h * w,  self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="n">pos_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Flatten the padding masks</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="n">decoder_out</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">pos_embed</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">query_embed</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="o">:</span><span class="w"> </span><span class="n">logits</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="o">:</span><span class="w"> </span><span class="n">boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compile_1">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">jit_compile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span>
                       <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FalseNegatives</span><span class="p">()])</span>
</code></pre></div>

<p>Args:
    optimizer: String (name of optimizer) or optimizer instance. See
      <code>tf.keras.optimizers</code>.
    loss: Loss function. Maybe be a string (name of loss function), or
      a <code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. A loss
      function is any callable with the signature <code>loss = fn(y_true,
      y_pred)</code>, where <code>y_true</code> are the ground truth values, and
      <code>y_pred</code> are the model's predictions.
      <code>y_true</code> should have shape
      <code>(batch_size, d0, .. dN)</code> (except in the case of
      sparse loss functions such as
      sparse categorical crossentropy which expects integer arrays of shape
      <code>(batch_size, d0, .. dN-1)</code>).
      <code>y_pred</code> should have shape <code>(batch_size, d0, .. dN)</code>.
      The loss function should return a float tensor.
      If a custom <code>Loss</code> instance is
      used and reduction is set to <code>None</code>, return value has shape
      <code>(batch_size, d0, .. dN-1)</code> i.e. per-sample or per-timestep loss
      values; otherwise, it is a scalar. If the model has multiple outputs,
      you can use a different loss on each output by passing a dictionary
      or a list of losses. The loss value that will be minimized by the
      model will then be the sum of all individual losses, unless
      <code>loss_weights</code> is specified.
    metrics: List of metrics to be evaluated by the model during training
      and testing. Each of this can be a string (name of a built-in
      function), function or a <code>tf.keras.metrics.Metric</code> instance. See
      <code>tf.keras.metrics</code>. Typically you will use <code>metrics=['accuracy']</code>. A
      function is any callable with the signature <code>result = fn(y_true,
      y_pred)</code>. To specify different metrics for different outputs of a
      multi-output model, you could also pass a dictionary, such as
      <code>metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>.
      You can also pass a list to specify a metric or a list of metrics
      for each output, such as <code>metrics=[['accuracy'], ['accuracy', 'mse']]</code>
      or <code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the
      strings 'accuracy' or 'acc', we convert this to one of
      <code>tf.keras.metrics.BinaryAccuracy</code>,
      <code>tf.keras.metrics.CategoricalAccuracy</code>,
      <code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss
      function used and the model output shape. We do a similar
      conversion for the strings 'crossentropy' and 'ce' as well.
    loss_weights: Optional list or dictionary specifying scalar coefficients
      (Python floats) to weight the loss contributions of different model
      outputs. The loss value that will be minimized by the model will then
      be the <em>weighted sum</em> of all individual losses, weighted by the
      <code>loss_weights</code> coefficients.
        If a list, it is expected to have a 1:1 mapping to the model's
          outputs. If a dict, it is expected to map output names (strings)
          to scalar coefficients.
    weighted_metrics: List of metrics to be evaluated and weighted by
      <code>sample_weight</code> or <code>class_weight</code> during training and testing.
    run_eagerly: Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s
      logic will not be wrapped in a <code>tf.function</code>. Recommended to leave
      this as <code>None</code> unless your <code>Model</code> cannot be run inside a
      <code>tf.function</code>. <code>run_eagerly=True</code> is not supported when using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    steps_per_execution: Int. Defaults to 1. The number of batches to run
      during each <code>tf.function</code> call. Running multiple batches inside a
      single <code>tf.function</code> call can greatly improve performance on TPUs or
      small models with a large Python overhead. At most, one full epoch
      will be run each execution. If a number larger than the size of the
      epoch is passed, the execution will be truncated to the size of the
      epoch. Note that if <code>steps_per_execution</code> is set to <code>N</code>,
      <code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods will
      only be called every <code>N</code> batches (i.e. before/after each <code>tf.function</code>
      execution).
    jit_compile: If <code>True</code>, compile the model training step with XLA.
      <a href="https://www.tensorflow.org/xla">XLA</a> is an optimizing compiler for
      machine learning.
      <code>jit_compile</code> is not enabled for by default.
      This option cannot be enabled with <code>run_eagerly=True</code>.
      Note that <code>jit_compile=True</code> is
      may not necessarily work for all models.
      For more information on supported operations please refer to the
      <a href="https://www.tensorflow.org/xla">XLA documentation</a>.
      Also refer to
      <a href="https://www.tensorflow.org/xla/known_issues">known XLA issues</a> for
      more details.
    **kwargs: Arguments supported for backwards compatibility only.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="p">@</span><span class="n">traceback_utils</span><span class="p">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compile</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">optimizer</span><span class="o">=</span><span class="err">&#39;</span><span class="n">rmsprop</span><span class="err">&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">loss</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;Configures the model for training.</span>

<span class="w">    </span><span class="nl">Example</span><span class="p">:</span><span class="w"></span>

<span class="w">    </span><span class="err">```</span><span class="n">python</span><span class="w"></span>

<span class="w">    </span><span class="n">model</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span><span class="w"></span>

<span class="w">                  </span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span><span class="w"></span>

<span class="w">                  </span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span><span class="w"></span>

<span class="w">                           </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">FalseNegatives</span><span class="p">()])</span><span class="w"></span>

<span class="w">    </span><span class="err">```</span><span class="w"></span>

<span class="w">    </span><span class="nl">Args</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="nl">optimizer</span><span class="p">:</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">optimizer</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="n">function</span><span class="p">.</span><span class="w"> </span><span class="n">Maybe</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">or</span><span class="w"></span>

<span class="w">          </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ground</span><span class="w"> </span><span class="n">truth</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">predictions</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="p">(</span><span class="n">except</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"></span>

<span class="w">          </span><span class="n">sparse</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">functions</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"></span>

<span class="w">          </span><span class="n">sparse</span><span class="w"> </span><span class="n">categorical</span><span class="w"> </span><span class="n">crossentropy</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">integer</span><span class="w"> </span><span class="n">arrays</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="p">).</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">custom</span><span class="w"> </span><span class="err">`</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="n">is</span><span class="w"></span>

<span class="w">          </span><span class="n">used</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">reduction</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">sample</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">timestep</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">values</span><span class="p">;</span><span class="w"> </span><span class="n">otherwise</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">scalar</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">you</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">passing</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dictionary</span><span class="w"></span>

<span class="w">          </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">losses</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">unless</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">specified</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"></span>

<span class="w">          </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">built</span><span class="o">-</span><span class="k">in</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Metric</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Typically</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="n">multi</span><span class="o">-</span><span class="n">output</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dictionary</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="err">&#39;</span><span class="n">output_a</span><span class="err">&#39;</span><span class="o">:</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">output_b</span><span class="err">&#39;</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]}</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="w"></span>

<span class="w">          </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">&#39;</span><span class="n">acc</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">convert</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">of</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">CategoricalAccuracy</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="err">`</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">similar</span><span class="w"></span>

<span class="w">          </span><span class="n">conversion</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">crossentropy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">&#39;</span><span class="n">ce</span><span class="err">&#39;</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">well</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">loss_weights</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dictionary</span><span class="w"> </span><span class="n">specifying</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="n">coefficients</span><span class="w"></span>

<span class="w">          </span><span class="p">(</span><span class="n">Python</span><span class="w"> </span><span class="n">floats</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">contributions</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">model</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"></span>

<span class="w">          </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">*</span><span class="n">weighted</span><span class="w"> </span><span class="n">sum</span><span class="o">*</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w"></span>

<span class="w">            </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="w"> </span><span class="n">mapping</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"></span>

<span class="w">              </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dict</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">map</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="p">(</span><span class="n">strings</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">weighted_metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">sample_weight</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">class_weight</span><span class="err">`</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">run_eagerly</span><span class="p">:</span><span class="w"> </span><span class="n">Bool</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">False</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`&#39;</span><span class="n">s</span><span class="w"></span>

<span class="w">          </span><span class="n">logic</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">wrapped</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Recommended</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">leave</span><span class="w"></span>

<span class="w">          </span><span class="n">this</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="w"> </span><span class="n">unless</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">using</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">ParameterServerStrategy</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">steps_per_execution</span><span class="p">:</span><span class="w"> </span><span class="n">Int</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mf">1.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">run</span><span class="w"></span>

<span class="w">          </span><span class="n">during</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="p">.</span><span class="w"> </span><span class="n">Running</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="n">single</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">greatly</span><span class="w"> </span><span class="n">improve</span><span class="w"> </span><span class="n">performance</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">TPUs</span><span class="w"> </span><span class="n">or</span><span class="w"></span>

<span class="w">          </span><span class="n">small</span><span class="w"> </span><span class="n">models</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="n">overhead</span><span class="p">.</span><span class="w"> </span><span class="n">At</span><span class="w"> </span><span class="n">most</span><span class="p">,</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">full</span><span class="w"> </span><span class="n">epoch</span><span class="w"></span>

<span class="w">          </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">execution</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">larger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">passed</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">truncated</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_begin</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_end</span><span class="err">`</span><span class="w"> </span><span class="n">methods</span><span class="w"> </span><span class="n">will</span><span class="w"></span>

<span class="w">          </span><span class="n">only</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">every</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">before</span><span class="o">/</span><span class="n">after</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"></span>

<span class="w">          </span><span class="n">execution</span><span class="p">).</span><span class="w"></span>

<span class="w">        </span><span class="nl">jit_compile</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">compile</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">XLA</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">XLA</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla) is an optimizing compiler for</span>

<span class="w">          </span><span class="n">machine</span><span class="w"> </span><span class="n">learning</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="k">default</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">This</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"></span>

<span class="w">          </span><span class="n">may</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">necessarily</span><span class="w"> </span><span class="n">work</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">models</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">For</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">operations</span><span class="w"> </span><span class="n">please</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">XLA</span><span class="w"> </span><span class="n">documentation</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla).</span>

<span class="w">          </span><span class="n">Also</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">known</span><span class="w"> </span><span class="n">XLA</span><span class="w"> </span><span class="n">issues</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla/known_issues) for</span>

<span class="w">          </span><span class="n">more</span><span class="w"> </span><span class="n">details</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Arguments</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">backwards</span><span class="w"> </span><span class="n">compatibility</span><span class="w"> </span><span class="n">only</span><span class="p">.</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="err">&#39;</span><span class="n">compile</span><span class="err">&#39;</span><span class="p">).</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="err">&#39;</span><span class="n">experimental_steps_per_execution</span><span class="err">&#39;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="err">&#39;</span><span class="n">The</span><span class="w"> </span><span class="n">argument</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">longer</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">                        </span><span class="err">&#39;</span><span class="n">experimental</span><span class="p">.</span><span class="w"> </span><span class="n">Pass</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">instead</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">                        </span><span class="err">&#39;`</span><span class="n">experimental_steps_per_execution</span><span class="err">`</span><span class="p">.</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="err">&#39;</span><span class="n">experimental_steps_per_execution</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="cp"># When compiling from an already-serialized model, we do not want to</span>

<span class="w">      </span><span class="cp"># reapply some processing steps (e.g. metric renaming for multi-output</span>

<span class="w">      </span><span class="cp"># models, which have prefixes added for each corresponding output name).</span>

<span class="w">      </span><span class="n">from_serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="err">&#39;</span><span class="n">from_serialized</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">False</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_eagerly</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">loss_weights</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="n">weighted_metrics</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">from_serialized</span><span class="o">=</span><span class="n">from_serialized</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="cp"># Initializes attrs that are reset each time `compile` is called.</span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="p">{}</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dynamic</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="err">&#39;</span><span class="n">You</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">enable</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">            </span><span class="err">&#39;</span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">same</span><span class="w"> </span><span class="n">time</span><span class="p">.</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nl">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="nb">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jit_compile</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_loss_1">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

<p>Apply the GIoU, L1 and SCC to each layers of the transformer decoder</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ground_truths</td>
<td>see output kerod.dataset.preprocessing for the doc</td>
</tr>
<tr>
<td>y_pred</td>
<td>A dict<br>- <em>scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits<br>- </em>bbox*: A Tensor of shape [batch_size, num_queries, 4]</td>
</tr>
<tr>
<td>input_shape</td>
<td>[height, width] of the input tensor.<br>It is the shape of the images will all the padding included.<br>It is used to normalize the ground_truths boxes.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">ground_truths</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">int</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="ss">        Arguments:</span>

<span class="ss">            ground_truths: see output kerod.dataset.preprocessing for the doc</span>

<span class="ss">            y_pred: A dict</span>

<span class="ss">                - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="ss">                - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="ss">            input_shape: [height, width] of the input tensor.</span>

<span class="ss">                It is the shape of the images will all the padding included.</span>

<span class="ss">                It is used to normalize the ground_truths boxes.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, 2</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">centered_normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">counted</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">LABELS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">centered_normalized_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">WEIGHTS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.WEIGHTS</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">NUM_BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.SCORES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">{</span>

<span class="n">            BoxField.BOXES: boxes,</span>

<span class="n">            BoxField.SCORES: logits</span>

<span class="n">        } for boxes, logits in zip(boxes_per_lvl, logits_per_lvl)</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Giou</span><span class="p">,</span><span class="w"> </span><span class="n">L1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">SCC</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">layers</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Logs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">            </span><span class="n">compute_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">num_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_metrics_1">compute_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span>
<span class="p">)</span>
</code></pre></div>

<p>Update metric states and collect all metrics to be returned.</p>
<p>Subclasses can optionally override this method to provide custom metric
updating and collection logic.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>

    <span class="c1"># This super call updates `self.compiled_metrics` and returns results</span>
    <span class="c1"># for all metrics listed in `self.metrics`.</span>
    <span class="n">metric_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="c1"># Note that `self.custom_metric` is not listed in `self.metrics`.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">metric_results</span><span class="p">[</span><span class="s1">&#39;custom_metric_name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">metric_results</span>
</code></pre></div>

<p>Args:
  x: Input data.
  y: Target data.
  y_pred: Predictions returned by the model (output of <code>model.call(x)</code>)
  sample_weight: Sample weights for weighting the loss function.</p>
<p>Returns:
  A <code>dict</code> containing values that will be passed to
  <code>tf.keras.callbacks.CallbackList.on_train_batch_end()</code>. Typically, the
  values of the metrics listed in <code>self.metrics</code> are returned. Example:
  <code>{'loss': 0.2, 'accuracy': 0.7}</code>.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Update metric states and collect all metrics to be returned.</span>

<span class="s2">    Subclasses can optionally override this method to provide custom metric</span>

<span class="s2">    updating and collection logic.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    class MyModel(tf.keras.Sequential):</span>

<span class="s2">      def compute_metrics(self, x, y, y_pred, sample_weight):</span>

<span class="s2">        # This super call updates `self.compiled_metrics` and returns results</span>

<span class="s2">        # for all metrics listed in `self.metrics`.</span>

<span class="s2">        metric_results = super(MyModel, self).compute_metrics(</span>

<span class="s2">            x, y, y_pred, sample_weight)</span>

<span class="s2">        # Note that `self.custom_metric` is not listed in `self.metrics`.</span>

<span class="s2">        self.custom_metric.update_state(x, y, y_pred, sample_weight)</span>

<span class="s2">        metric_results[&#39;custom_metric_name&#39;] = self.custom_metric.result()</span>

<span class="s2">        return metric_results</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      x: Input data.</span>

<span class="s2">      y: Target data.</span>

<span class="s2">      y_pred: Predictions returned by the model (output of `model.call(x)`)</span>

<span class="s2">      sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">    Returns:</span>

<span class="s2">      A `dict` containing values that will be passed to</span>

<span class="s2">      `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the</span>

<span class="s2">      values of the metrics listed in `self.metrics` are returned. Example:</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Collect metrics to return</span><span class="w"></span>

<span class="w">    </span><span class="n">return_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">return_metrics</span><span class="p">.</span><span class="k">update</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">return_metrics</span><span class="err">[</span><span class="n">metric</span><span class="p">.</span><span class="k">name</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">return_metrics</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="evaluate_1">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>  if the model has named inputs.<br>- A <code>tf.data</code> dataset. Should return a tuple<br>  of either <code>(inputs, targets)</code> or<br>  <code>(inputs, targets, sample_weights)</code>.<br>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code><br>  or <code>(inputs, targets, sample_weights)</code>.<br>A more detailed description of unpacking behavior for iterator types<br>(Dataset, generator, Sequence) is given in the <code>Unpacking behavior&lt;br&gt;for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely). If<br><code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance, <code>y</code><br>should not be specified (since targets will be obtained from the<br>iterator/dataset).</td>
</tr>
<tr>
<td>batch_size</td>
<td>Integer or <code>None</code>. Number of samples per batch of<br>computation. If unspecified, <code>batch_size</code> will default to 32. Do not<br>specify the <code>batch_size</code> if your data is in the form of a dataset,<br>generators, or <code>keras.utils.Sequence</code> instances (since they generate<br>batches).</td>
</tr>
<tr>
<td>verbose</td>
<td>0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional Numpy array of weights for the test samples,<br>used for weighting the loss function. You can either pass a flat (1D)<br>Numpy array with the same length as the input samples<br>  (1:1 mapping between weights and samples), or in the case of<br>    temporal data, you can pass a 2D array with shape <code>(samples,&lt;br&gt;    sequence_length)</code>, to apply a different weight to every timestep<br>    of every sample. This argument is not supported when <code>x</code> is a<br>    dataset, instead pass sample weights as the third element of <code>x</code>.</td>
</tr>
<tr>
<td>steps</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)<br>before declaring the evaluation round finished. Ignored with the<br>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code> is<br>None, 'evaluate' will run until the dataset is exhausted. This<br>argument is not supported with array inputs.</td>
</tr>
<tr>
<td>callbacks</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of<br>callbacks to apply during evaluation. See<br><a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code><br>input only. Maximum size for the generator queue. If unspecified,<br><code>max_queue_size</code> will default to 10.</td>
</tr>
<tr>
<td>workers</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using process-based<br>threading. If unspecified, <code>workers</code> will default to 1.</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to the<br>generator as they can't be passed easily to children processes.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
<tr>
<td>**kwargs</td>
<td>Unused at this time.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">    Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">            if the model has named inputs.</span>

<span class="s2">          - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">            of either `(inputs, targets)` or</span>

<span class="s2">            `(inputs, targets, sample_weights)`.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="s2">            or `(inputs, targets, sample_weights)`.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>

<span class="s2">          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`</span>

<span class="s2">          should not be specified (since targets will be obtained from the</span>

<span class="s2">          iterator/dataset).</span>

<span class="s2">        batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">          computation. If unspecified, `batch_size` will default to 32. Do not</span>

<span class="s2">          specify the `batch_size` if your data is in the form of a dataset,</span>

<span class="s2">          generators, or `keras.utils.Sequence` instances (since they generate</span>

<span class="s2">          batches).</span>

<span class="s2">        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</span>

<span class="s2">        sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">          used for weighting the loss function. You can either pass a flat (1D)</span>

<span class="s2">          Numpy array with the same length as the input samples</span>

<span class="s2">            (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">              temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">              sequence_length)`, to apply a different weight to every timestep</span>

<span class="s2">              of every sample. This argument is not supported when `x` is a</span>

<span class="s2">              dataset, instead pass sample weights as the third element of `x`.</span>

<span class="s2">        steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">          before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">          default value of `None`. If x is a `tf.data` dataset and `steps` is</span>

<span class="s2">          None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">          argument is not supported with array inputs.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">          callbacks to apply during evaluation. See</span>

<span class="s2">          [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">          input only. Maximum size for the generator queue. If unspecified,</span>

<span class="s2">          `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">          only. Maximum number of processes to spin up when using process-based</span>

<span class="s2">          threading. If unspecified, `workers` will default to 1.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">          `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">          threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">          `False`. Note that because this implementation relies on</span>

<span class="s2">          multiprocessing, you should not pass non-picklable arguments to the</span>

<span class="s2">          generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">        **kwargs: Unused at this time.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">use_cached_eval_dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;_use_cached_eval_dataset&#39;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Invalid keyword arguments: {list(kwargs.keys())}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">coordinator</span><span class="p">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">use_cached_eval_dataset</span><span class="w"></span>

<span class="w">          </span><span class="k">and</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">        </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">            </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">profiler</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"> </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span><span class="w"></span>

<span class="w">                </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">              </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span><span class="w">  </span><span class="c1"># No error, now safe to assign to logs.</span><span class="w"></span>

<span class="w">              </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="evaluate_generator_1">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.evaluate` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.evaluate_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.evaluate`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="fit_1">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Args:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code>
        or <code>(inputs, targets, sample_weights)</code>.
      - A <code>tf.keras.utils.experimental.DatasetCreator</code>, which wraps a
        callable that takes a single argument of type
        <code>tf.distribute.InputContext</code>, and returns a <code>tf.data.Dataset</code>.
        <code>DatasetCreator</code> should be used when users prefer to specify the
        per-replica batching and sharding logic for the <code>Dataset</code>.
        See <code>tf.keras.utils.experimental.DatasetCreator</code> doc for more
        information.
      A more detailed description of unpacking behavior for iterator types
      (Dataset, generator, Sequence) is given below. If using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>, only
      <code>DatasetCreator</code> type is supported for <code>x</code>.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided
        (unless the <code>steps_per_epoch</code> flag is set to
        something other than None).
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 'auto', 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        'auto' defaults to 1 for most cases, but 2 when used with
        <code>ParameterServerStrategy</code>. Note that the progress bar is not
        particularly useful when logged to a file, so verbose=2 is
        recommended when not running interactively (eg, in a production
        environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note <code>tf.keras.callbacks.ProgbarLogger</code>
        and <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
        Callbacks with batch-level calls are currently unsupported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>, and users are
        advised to implement epoch-level calls instead with an appropriate
        <code>steps_per_epoch</code> value.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
        not supported when <code>x</code> is a dataset, generator or
       <code>keras.utils.Sequence</code> instance.
        <code>validation_split</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using <code>validation_split</code>
        or <code>validation_data</code> is not affected by regularization layers like
        noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - A tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors.
          - A tuple <code>(x_val, y_val, val_sample_weights)</code> of NumPy arrays.
          - A <code>tf.data.Dataset</code>.
          - A Python generator or <code>keras.utils.Sequence</code> returning
          <code>(inputs, targets)</code> or <code>(inputs, targets, sample_weights)</code>.
        <code>validation_data</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is ignored
        when <code>x</code> is a generator or an object of tf.data.Dataset.
        'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample. This
        argument is not supported when <code>x</code> is a dataset, generator, or
       <code>keras.utils.Sequence</code> instance, instead provide the sample_weights
        as the third element of <code>x</code>.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is exhausted.
        When passing an infinitely repeating dataset, you must specify the
        <code>steps_per_epoch</code> argument. If <code>steps_per_epoch=-1</code> the training
        will run indefinitely with an infinitely repeating dataset.
        This argument is not supported with array inputs.
        When using <code>tf.distribute.experimental.ParameterServerStrategy</code>:
          * <code>steps_per_epoch=None</code> is not supported.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None, validation
        will run until the <code>validation_data</code> dataset is exhausted. In the
        case of an infinitely repeated dataset, it will run into an
        infinite loop. If 'validation_steps' is specified and only part of
        the dataset will be consumed, the evaluation will start from the
        beginning of the dataset at each epoch. This ensures that the same
        validation samples are used every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    validation_freq: Only relevant if validation data is provided. Integer
        or <code>collections.abc.Container</code> instance (e.g. list, tuple, etc.).
        If an integer, specifies how many training epochs to run before a
        new validation run is performed, e.g. <code>validation_freq=2</code> runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
        validation at the end of the 1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or <code>keras.utils.Sequence</code>
        input only. Maximum size for the generator queue.
        If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as 'x'. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code>x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">In</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">mismatch</span><span class="w"> </span><span class="n">between</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"></span>
<span class="w">    </span><span class="n">and</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="o">.</span><span class="w"></span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Args:</span>

<span class="sd">        x: Input data. It could be:</span>

<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">            if the model has named inputs.</span>

<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">            of either `(inputs, targets)` or</span>

<span class="sd">            `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="sd">            or `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a</span>

<span class="sd">            callable that takes a single argument of type</span>

<span class="sd">            `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.</span>

<span class="sd">            `DatasetCreator` should be used when users prefer to specify the</span>

<span class="sd">            per-replica batching and sharding logic for the `Dataset`.</span>

<span class="sd">            See `tf.keras.utils.experimental.DatasetCreator` doc for more</span>

<span class="sd">            information.</span>

<span class="sd">          A more detailed description of unpacking behavior for iterator types</span>

<span class="sd">          (Dataset, generator, Sequence) is given below. If using</span>

<span class="sd">          `tf.distribute.experimental.ParameterServerStrategy`, only</span>

<span class="sd">          `DatasetCreator` type is supported for `x`.</span>

<span class="sd">        y: Target data. Like the input data `x`,</span>

<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">          not be specified (since targets will be obtained from `x`).</span>

<span class="sd">        batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per gradient update.</span>

<span class="sd">            If unspecified, `batch_size` will default to 32.</span>

<span class="sd">            Do not specify the `batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">            data provided</span>

<span class="sd">            (unless the `steps_per_epoch` flag is set to</span>

<span class="sd">            something other than None).</span>

<span class="sd">            Note that in conjunction with `initial_epoch`,</span>

<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">            The model is not trained for a number of iterations</span>

<span class="sd">            given by `epochs`, but merely until the epoch</span>

<span class="sd">            of index `epochs` is reached.</span>

<span class="sd">        verbose: &#39;auto&#39;, 0, 1, or 2. Verbosity mode.</span>

<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">            &#39;auto&#39; defaults to 1 for most cases, but 2 when used with</span>

<span class="sd">            `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="sd">            particularly useful when logged to a file, so verbose=2 is</span>

<span class="sd">            recommended when not running interactively (eg, in a production</span>

<span class="sd">            environment).</span>

<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`</span>

<span class="sd">            and `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">            and need not be passed into `model.fit`.</span>

<span class="sd">            `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">            `verbose` argument to `model.fit`.</span>

<span class="sd">            Callbacks with batch-level calls are currently unsupported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`, and users are</span>

<span class="sd">            advised to implement epoch-level calls instead with an appropriate</span>

<span class="sd">            `steps_per_epoch` value.</span>

<span class="sd">        validation_split: Float between 0 and 1.</span>

<span class="sd">            Fraction of the training data to be used as validation data.</span>

<span class="sd">            The model will set apart this fraction of the training data,</span>

<span class="sd">            will not train on it, and will evaluate</span>

<span class="sd">            the loss and any model metrics</span>

<span class="sd">            on this data at the end of each epoch.</span>

<span class="sd">            The validation data is selected from the last samples</span>

<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>

<span class="sd">            not supported when `x` is a dataset, generator or</span>

<span class="sd">           `keras.utils.Sequence` instance.</span>

<span class="sd">            `validation_split` is not yet supported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">        validation_data: Data on which to evaluate</span>

<span class="sd">            the loss and any model metrics at the end of each epoch.</span>

<span class="sd">            The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">            that the validation loss of data provided using `validation_split`</span>

<span class="sd">            or `validation_data` is not affected by regularization layers like</span>

<span class="sd">            noise and dropout.</span>

<span class="sd">            `validation_data` will override `validation_split`.</span>

<span class="sd">            `validation_data` could be:</span>

<span class="sd">              - A tuple `(x_val, y_val)` of Numpy arrays or tensors.</span>

<span class="sd">              - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.</span>

<span class="sd">              - A `tf.data.Dataset`.</span>

<span class="sd">              - A Python generator or `keras.utils.Sequence` returning</span>

<span class="sd">              `(inputs, targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">            `validation_data` is not yet supported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">            before each epoch) or str (for &#39;batch&#39;). This argument is ignored</span>

<span class="sd">            when `x` is a generator or an object of tf.data.Dataset.</span>

<span class="sd">            &#39;batch&#39; is a special option for dealing</span>

<span class="sd">            with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">            chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">            to a weight (float) value, used for weighting the loss function</span>

<span class="sd">            (during training only).</span>

<span class="sd">            This can be useful to tell the model to</span>

<span class="sd">            &quot;pay more attention&quot; to samples from</span>

<span class="sd">            an under-represented class.</span>

<span class="sd">        sample_weight: Optional Numpy array of weights for</span>

<span class="sd">            the training samples, used for weighting the loss function</span>

<span class="sd">            (during training only). You can either pass a flat (1D)</span>

<span class="sd">            Numpy array with the same length as the input samples</span>

<span class="sd">            (1:1 mapping between weights and samples),</span>

<span class="sd">            or in the case of temporal data,</span>

<span class="sd">            you can pass a 2D array with shape</span>

<span class="sd">            `(samples, sequence_length)`,</span>

<span class="sd">            to apply a different weight to every timestep of every sample. This</span>

<span class="sd">            argument is not supported when `x` is a dataset, generator, or</span>

<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>

<span class="sd">            as the third element of `x`.</span>

<span class="sd">        initial_epoch: Integer.</span>

<span class="sd">            Epoch at which to start training</span>

<span class="sd">            (useful for resuming a previous training run).</span>

<span class="sd">        steps_per_epoch: Integer or `None`.</span>

<span class="sd">            Total number of steps (batches of samples)</span>

<span class="sd">            before declaring one epoch finished and starting the</span>

<span class="sd">            next epoch. When training with input tensors such as</span>

<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">            the number of samples in your dataset divided by</span>

<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>

<span class="sd">            When passing an infinitely repeating dataset, you must specify the</span>

<span class="sd">            `steps_per_epoch` argument. If `steps_per_epoch=-1` the training</span>

<span class="sd">            will run indefinitely with an infinitely repeating dataset.</span>

<span class="sd">            This argument is not supported with array inputs.</span>

<span class="sd">            When using `tf.distribute.experimental.ParameterServerStrategy`:</span>

<span class="sd">              * `steps_per_epoch=None` is not supported.</span>

<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">            samples) to draw before stopping when performing validation</span>

<span class="sd">            at the end of every epoch. If &#39;validation_steps&#39; is None, validation</span>

<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>

<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>

<span class="sd">            infinite loop. If &#39;validation_steps&#39; is specified and only part of</span>

<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>

<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>

<span class="sd">            validation samples are used every time.</span>

<span class="sd">        validation_batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per validation batch.</span>

<span class="sd">            If unspecified, will default to `batch_size`.</span>

<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>

<span class="sd">            or `collections.abc.Container` instance (e.g. list, tuple, etc.).</span>

<span class="sd">            If an integer, specifies how many training epochs to run before a</span>

<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>

<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>

<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>

<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="sd">            input only. Maximum size for the generator queue.</span>

<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">            only. Maximum number of processes to spin up</span>

<span class="sd">            when using process-based threading. If unspecified, `workers`</span>

<span class="sd">            will default to 1.</span>

<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">            `False`. Note that because this implementation relies on</span>

<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">        A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">      yield not only features (x) but optionally targets (y) and sample weights.</span>

<span class="sd">      Keras requires that the output of such iterator-likes be unambiguous. The</span>

<span class="sd">      iterator should return a tuple of length 1, 2, or 3, where the optional</span>

<span class="sd">      second and third elements will be used for y and sample_weight</span>

<span class="sd">      respectively. Any other type provided will be wrapped in a length one</span>

<span class="sd">      tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they</span>

<span class="sd">      should still adhere to the top-level tuple structure.</span>

<span class="sd">      e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">      features, targets, and weights from the keys of a single dict.</span>

<span class="sd">        A notable unsupported data type is the namedtuple. The reason is that</span>

<span class="sd">      it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">      datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">          `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">      it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">      interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">          `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">      where it is unclear if the tuple was intended to be unpacked into x, y,</span>

<span class="sd">      and sample_weight or passed through as a single element to `x`. As a</span>

<span class="sd">      result the data processing code will simply raise a ValueError if it</span>

<span class="sd">      encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>

<span class="sd">        A `History` object. Its `History.history` attribute is</span>

<span class="sd">        a record of training loss values and metrics values</span>

<span class="sd">        at successive epochs, as well as validation loss values</span>

<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>

<span class="sd">        RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">        2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">        ValueError: In case of mismatch between the provided input data</span>

<span class="sd">            and what the model expects or when the input data is empty.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;auto&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w">  </span><span class="c1"># Default to epoch-level logging for PSStrategy.</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w">  </span><span class="c1"># Default to batch-level logging otherwise.</span><span class="w"></span>

<span class="w">    </span><span class="k">elif</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;`verbose=1` is not allowed with `ParameterServerStrategy` for &#39;</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="s1">&#39;performance reasons. Received: `verbose`={verbose}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">validation_split</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Create the validation data using the training data. Only supported for</span><span class="w"></span>

<span class="w">      </span><span class="c1"># `Tensor` and `NumPy` input.</span><span class="w"></span>

<span class="w">      </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">))</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">val_x</span><span class="p">,</span><span class="w"> </span><span class="n">val_y</span><span class="p">,</span><span class="w"> </span><span class="n">val_sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">))</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">coordinator</span><span class="o">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span>\<span class="w"></span>

<span class="w">         </span><span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Handle fault-tolerance for multi-worker.</span><span class="w"></span>

<span class="w">      </span><span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span><span class="w"></span>

<span class="w">      </span><span class="c1"># happen after `callbacks.on_train_begin`.</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">          </span><span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">))</span><span class="w"></span>

<span class="w">      </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span><span class="w"></span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span><span class="w"></span>

<span class="w">                </span><span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">              </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span><span class="w">  </span><span class="c1"># No error, now safe to assign to logs.</span><span class="w"></span>

<span class="w">              </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="k">break</span><span class="w"></span>

<span class="w">        </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">logs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected result of `train_function` &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;(Empty logs). Please use &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;`Model.compile(..., run_eagerly=True)`, or &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;`tf.config.run_functions_eagerly(True)` for more &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;information of where went wrong, or file a &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;issue/bug to `tf.keras`.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">epoch_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Run validation.</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">validation_freq</span><span class="p">):</span><span class="w"></span>

<span class="w">          </span><span class="c1"># Create data_handler for evaluation and cache it.</span><span class="w"></span>

<span class="w">          </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">_use_cached_eval_dataset</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="s1">&#39;val_&#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">epoch_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">epoch_logs</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="k">break</span><span class="w"></span>

<span class="w">      </span><span class="c1"># If eval data_handler exists, delete it after all epochs are done.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="fit_generator_1">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to use
  this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">fit_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.fit` now supports generators, so there is no longer any need to use</span>

<span class="ss">      this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.fit_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.fit`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_layer_1">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>String, name of layer.</td>
</tr>
<tr>
<td>index</td>
<td>Integer, index of layer.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">    If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">    Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">    Args:</span>

<span class="s2">        name: String, name of layer.</span>

<span class="s2">        index: Integer, index of layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A layer instance.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span><span class="w"></span>

<span class="w">    </span><span class="c1"># since they are constant, but we have not done that yet.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide only a layer name or a layer index. Received: &#39;</span><span class="w"></span>

<span class="w">                       </span><span class="n">f</span><span class="s1">&#39;index={index}, name={name}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="k">index</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Was asked to retrieve layer at index {index}&#39;</span><span class="w"></span>

<span class="w">                         </span><span class="n">f</span><span class="s1">&#39; but model only has {len(self.layers)}&#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39; layers.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">name</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="n">layer</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;No such layer: {name}. Existing layers are: &#39;</span><span class="w"></span>

<span class="w">                       </span><span class="n">f</span><span class="s1">&#39;{list(layer.name for layer in self.layers)}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index at &#39;</span><span class="w"></span>

<span class="w">                     </span><span class="s1">&#39;`get_layer`.&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="load_weights_1">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don't have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<code>tf.keras.Model</code>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>String, path to the weights file to load. For weight files in<br>TensorFlow format, this is the file prefix (the same as was passed<br>to <code>save_weights</code>). This can also be a path to a SavedModel<br>saved from <code>model.save</code>.</td>
</tr>
<tr>
<td>by_name</td>
<td>Boolean, whether to load weights by name or by topological<br>order. Only topological loading is supported for weight files in<br>TensorFlow format.</td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>Boolean, whether to skip loading of layers where there is<br>a mismatch in the number of weights, or a mismatch in the shape of<br>the weight (only valid when <code>by_name=True</code>).</td>
</tr>
<tr>
<td>options</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for loading weights.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same status<br>object as <code>tf.train.Checkpoint.restore</code>. When graph building, restore<br>ops are run automatically as soon as the network is built (on first call<br>for user-defined classes inheriting from <code>Model</code>, immediately if it is<br>already built).<br><br>When loading weights in HDF5 format, returns <code>None</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available and the weight file is in HDF5<br>format.</td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is<br><code>False</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">    If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">    topology. This means the architecture should be the same as when the weights</span>

<span class="sd">    were saved.  Note that layers that don&#39;t have weights are not taken into</span>

<span class="sd">    account in the topological ordering, so adding or removing layers is fine as</span>

<span class="sd">    long as they don&#39;t have weights.</span>

<span class="sd">    If `by_name` is True, weights are loaded into layers only if they share the</span>

<span class="sd">    same name. This is useful for fine-tuning or transfer-learning models where</span>

<span class="sd">    some of the layers have changed.</span>

<span class="sd">    Only topological loading (`by_name=False`) is supported when loading weights</span>

<span class="sd">    from the TensorFlow format. Note that topological loading differs slightly</span>

<span class="sd">    between TensorFlow and HDF5 formats for user-defined classes inheriting from</span>

<span class="sd">    `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>

<span class="sd">    TensorFlow format loads based on the object-local names of attributes to</span>

<span class="sd">    which layers are assigned in the `Model`&#39;s constructor.</span>

<span class="sd">    Args:</span>

<span class="sd">        filepath: String, path to the weights file to load. For weight files in</span>

<span class="sd">            TensorFlow format, this is the file prefix (the same as was passed</span>

<span class="sd">            to `save_weights`). This can also be a path to a SavedModel</span>

<span class="sd">            saved from `model.save`.</span>

<span class="sd">        by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">            order. Only topological loading is supported for weight files in</span>

<span class="sd">            TensorFlow format.</span>

<span class="sd">        skip_mismatch: Boolean, whether to skip loading of layers where there is</span>

<span class="sd">            a mismatch in the number of weights, or a mismatch in the shape of</span>

<span class="sd">            the weight (only valid when `by_name=True`).</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for loading weights.</span>

<span class="sd">    Returns:</span>

<span class="sd">        When loading a weight file in TensorFlow format, returns the same status</span>

<span class="sd">        object as `tf.train.Checkpoint.restore`. When graph building, restore</span>

<span class="sd">        ops are run automatically as soon as the network is built (on first call</span>

<span class="sd">        for user-defined classes inheriting from `Model`, immediately if it is</span>

<span class="sd">        already built).</span>

<span class="sd">        When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If `h5py` is not available and the weight file is in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">          `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"></span>

<span class="w">          </span><span class="p">(</span><span class="ow">not</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span><span class="w"></span>

<span class="w">        </span><span class="n">spr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not implemented with TPUStrategy &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;with `steps_per_run` greater than 1. The &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="n">f</span><span class="s1">&#39;`steps_per_run` is {spr}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;When calling model.load_weights, skip_mismatch can only be set to &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;True when by_name is True.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_detect_save_format</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Weights may only be loaded based on topology into Models when &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;loading TensorFlow-formatted weights (got by_name=True to &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;load_weights).&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Restore existing variables (if any) immediately, and set up a</span><span class="w"></span>

<span class="w">        </span><span class="c1"># streaming restore for any variables created in the future.</span><span class="w"></span>

<span class="w">        </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                   </span><span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;`load_weights` requires h5py package when loading weights from &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;HDF5. Try installing h5py.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Unable to load weights saved in HDF5 format into a subclassed &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Model which has not created its variables yet. Call the Model &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;first, then load the weights.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="s1">&#39;layer_names&#39;</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="s1">&#39;model_weights&#39;</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Perform any layer defined finalization of the layer state.</span><span class="w"></span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">layer</span><span class="o">.</span><span class="n">finalize_state</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">status</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_predict_function_1">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the predict function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">    This method can be overridden to support custom inference logic.</span>

<span class="s2">    This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.predict_step`.</span>

<span class="s2">    This function is cached the first time `Model.predict` or</span>

<span class="s2">    `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the predict function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">tf</span><span class="p">.</span><span class="n">autograph</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span><span class="p">(</span><span class="w"></span>

<span class="w">                  </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span><span class="w"></span>

<span class="w">                                </span><span class="k">for</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="err">]</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">step_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="o">:</span><span class="w"> </span><span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="err">]</span><span class="p">),</span><span class="w"></span>

<span class="w">                                          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">step_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">predict_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_test_function_1">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the test function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">    This method can be overridden to support custom evaluation logic.</span>

<span class="s2">    This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.test_step`.</span>

<span class="s2">    This function is cached the first time `Model.evaluate` or</span>

<span class="s2">    `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the test function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If we&#39;re using a coordinator, use the value of self._steps_per_execution</span><span class="w"></span>

<span class="w">    </span><span class="c1"># at the time the function is called/scheduled, and not when it is actually</span><span class="w"></span>

<span class="w">    </span><span class="c1"># executed.</span><span class="w"></span>

<span class="w">    </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">          </span><span class="n">test_function</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">()))</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_train_function_1">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the train function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">    This method can be overridden to support custom training logic.</span>

<span class="s2">    This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">    logic to `Model.train_step`.</span>

<span class="s2">    This function is cached the first time `Model.fit` or</span>

<span class="s2">    `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the train function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If we&#39;re using a coordinator, use the value of self._steps_per_execution</span><span class="w"></span>

<span class="w">    </span><span class="c1"># at the time the function is called/scheduled, and not when it is actually</span><span class="w"></span>

<span class="w">    </span><span class="c1"># executed.</span><span class="w"></span>

<span class="w">    </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">          </span><span class="n">train_function</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">()))</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_1">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for batch processing
of large numbers of inputs. It is not intended for use inside of loops
that iterate over your data and process small numbers of inputs at a time.</p>
<p>For small numbers of inputs that fit in one batch,
directly use <code>__call__()</code> for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behave differently during
inference. You may pair the individual model call with a <code>tf.function</code>
for additional performance inside your inner loop.
If you need access to numpy array values instead of tensors after your
model call, you can use <code>tensor.numpy()</code> to get the numpy array value of
an eager tensor.</p>
<p>Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p>Note: See <a href="https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call">this FAQ entry</a>
for more details about the difference between <code>Model</code> methods <code>predict()</code>
and <code>__call__()</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input samples. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A <code>tf.data</code> dataset.<br>- A generator or <code>keras.utils.Sequence</code> instance.<br>A more detailed description of unpacking behavior for iterator types<br>(Dataset, generator, Sequence) is given in the <code>Unpacking behavior&lt;br&gt;for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
</tr>
<tr>
<td>batch_size</td>
<td>Integer or <code>None</code>.<br>Number of samples per batch.<br>If unspecified, <code>batch_size</code> will default to 32.<br>Do not specify the <code>batch_size</code> if your data is in the<br>form of dataset, generators, or <code>keras.utils.Sequence</code> instances<br>(since they generate batches).</td>
</tr>
<tr>
<td>verbose</td>
<td>Verbosity mode, 0 or 1.</td>
</tr>
<tr>
<td>steps</td>
<td>Total number of steps (batches of samples)<br>before declaring the prediction round finished.<br>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code><br>dataset and <code>steps</code> is None, <code>predict()</code> will<br>run until the input dataset is exhausted.</td>
</tr>
<tr>
<td>callbacks</td>
<td>List of <code>keras.callbacks.Callback</code> instances.<br>List of callbacks to apply during prediction.<br>See <a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code><br>input only. Maximum size for the generator queue.<br>If unspecified, <code>max_queue_size</code> will default to 10.</td>
</tr>
<tr>
<td>workers</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default<br>to 1.</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children processes.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided<br>input data and the model's expectations,<br>or in case a stateful model receives a number of samples<br>that is not a multiple of the batch size.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">    Computation is done in batches. This method is designed for batch processing</span>

<span class="s2">    of large numbers of inputs. It is not intended for use inside of loops</span>

<span class="s2">    that iterate over your data and process small numbers of inputs at a time.</span>

<span class="s2">    For small numbers of inputs that fit in one batch,</span>

<span class="s2">    directly use `__call__()` for faster execution, e.g.,</span>

<span class="s2">    `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">    `tf.keras.layers.BatchNormalization` that behave differently during</span>

<span class="s2">    inference. You may pair the individual model call with a `tf.function`</span>

<span class="s2">    for additional performance inside your inner loop.</span>

<span class="s2">    If you need access to numpy array values instead of tensors after your</span>

<span class="s2">    model call, you can use `tensor.numpy()` to get the numpy array value of</span>

<span class="s2">    an eager tensor.</span>

<span class="s2">    Also, note the fact that test loss is not affected by</span>

<span class="s2">    regularization layers like noise and dropout.</span>

<span class="s2">    Note: See [this FAQ entry](</span>

<span class="s2">    https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)</span>

<span class="s2">    for more details about the difference between `Model` methods `predict()`</span>

<span class="s2">    and `__call__()`.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input samples. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A `tf.data` dataset.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        batch_size: Integer or `None`.</span>

<span class="s2">            Number of samples per batch.</span>

<span class="s2">            If unspecified, `batch_size` will default to 32.</span>

<span class="s2">            Do not specify the `batch_size` if your data is in the</span>

<span class="s2">            form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">            (since they generate batches).</span>

<span class="s2">        verbose: Verbosity mode, 0 or 1.</span>

<span class="s2">        steps: Total number of steps (batches of samples)</span>

<span class="s2">            before declaring the prediction round finished.</span>

<span class="s2">            Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">            dataset and `steps` is None, `predict()` will</span>

<span class="s2">            run until the input dataset is exhausted.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">            List of callbacks to apply during prediction.</span>

<span class="s2">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">            input only. Maximum size for the generator queue.</span>

<span class="s2">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">            only. Maximum number of processes to spin up when using</span>

<span class="s2">            process-based threading. If unspecified, `workers` will default</span>

<span class="s2">            to 1.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">            `False`. Note that because this implementation relies on</span>

<span class="s2">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`. Note that Model.predict uses the same interpretation rules as</span>

<span class="s2">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>

<span class="s2">    three methods.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Numpy array(s) of predictions.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.predict` is wrapped in a `tf.function`.</span>

<span class="s2">        ValueError: In case of mismatch between the provided</span>

<span class="s2">            input data and the model&#39;s expectations,</span>

<span class="s2">            or in case a stateful model receives a number of samples</span>

<span class="s2">            that is not a multiple of the batch size.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># TODO(yashkatariya): Cache model on the coordinator for faster prediction.</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If running under PSS, then swap it with OneDeviceStrategy so that</span><span class="w"></span>

<span class="w">    </span><span class="c1"># execution will run on the coordinator.</span><span class="w"></span>

<span class="w">    </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Cluster coordinator is set by `.fit()` and `.evaluate()` which is not</span><span class="w"></span>

<span class="w">    </span><span class="c1"># needed in `.predict()` because all the predictions happen on the</span><span class="w"></span>

<span class="w">    </span><span class="c1"># coordinator/locally.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">      </span><span class="n">dataset_types</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">_is_tpu_multi_host</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">))</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">try</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span><span class="w"></span>

<span class="w">          </span><span class="n">data_option</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span><span class="w"></span>

<span class="w">          </span><span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_option</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">except</span><span class="w"> </span><span class="n">ValueError</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;Using Model.predict with MultiWorkerMirroredStrategy or &#39;</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;TPUStrategy and AutoShardPolicy.FILE might lead to out-of-order &#39;</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;result. Consider setting it to AutoShardPolicy.DATA.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">tmp_batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_batch_outputs</span><span class="w">  </span><span class="c1"># No error, now safe to assign.</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span><span class="w"></span>

<span class="w">                                           </span><span class="n">batch_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="w"></span>

<span class="w">                  </span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"></span>

<span class="w">                  </span><span class="n">lambda</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">),</span><span class="w"></span>

<span class="w">                  </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">batch_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="s1">&#39;outputs&#39;</span><span class="o">:</span><span class="w"> </span><span class="n">batch_outputs</span><span class="err">}</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">batch_outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected result of `predict_function` &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;(Empty batch_outputs). Please use &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;`Model.compile(..., run_eagerly=True)`, or &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;`tf.config.run_functions_eagerly(True)` for more &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;information of where went wrong, or file a &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;issue/bug to `tf.keras`.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">all_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"> </span><span class="n">concat</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If originally PSS strategy was used, then replace it back since predict</span><span class="w"></span>

<span class="w">    </span><span class="c1"># is running under `OneDeviceStrategy` after the swap and once its done</span><span class="w"></span>

<span class="w">    </span><span class="c1"># we need to replace it back to PSS again.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_generator_1">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">predict_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.predict` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.predict_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.predict`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_on_batch_1">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">predict_on_batch</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">x</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Returns predictions for a single batch of samples.</span>

    <span class="nv">Args</span>:

        <span class="nv">x</span>: <span class="nv">Input</span> <span class="nv">data</span>. <span class="nv">It</span> <span class="nv">could</span> <span class="nv">be</span>:

          <span class="o">-</span> <span class="nv">A</span> <span class="nv">Numpy</span> <span class="nv">array</span> <span class="ss">(</span><span class="nv">or</span> <span class="nv">array</span><span class="o">-</span><span class="nv">like</span><span class="ss">)</span>, <span class="nv">or</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">of</span> <span class="nv">arrays</span> <span class="ss">(</span><span class="nv">in</span> <span class="nv">case</span> <span class="nv">the</span>

              <span class="nv">model</span> <span class="nv">has</span> <span class="nv">multiple</span> <span class="nv">inputs</span><span class="ss">)</span>.

          <span class="o">-</span> <span class="nv">A</span> <span class="nv">TensorFlow</span> <span class="nv">tensor</span>, <span class="nv">or</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">of</span> <span class="nv">tensors</span> <span class="ss">(</span><span class="nv">in</span> <span class="nv">case</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">has</span>

              <span class="nv">multiple</span> <span class="nv">inputs</span><span class="ss">)</span>.

    <span class="nv">Returns</span>:

        <span class="nv">Numpy</span> <span class="nv">array</span><span class="ss">(</span><span class="nv">s</span><span class="ss">)</span> <span class="nv">of</span> <span class="nv">predictions</span>.

    <span class="nv">Raises</span>:

        <span class="nv">RuntimeError</span>: <span class="k">If</span> `<span class="nv">model</span>.<span class="nv">predict_on_batch</span>` <span class="nv">is</span> <span class="nv">wrapped</span> <span class="nv">in</span> <span class="nv">a</span> `<span class="nv">tf</span>.<span class="nv">function</span>`.

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">self</span>.<span class="nv">_check_call_args</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">predict_on_batch</span><span class="s1">&#39;</span><span class="ss">)</span>

    <span class="nv">_disallow_inside_tf_function</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">predict_on_batch</span><span class="s1">&#39;</span><span class="ss">)</span>

    <span class="nv">with</span> <span class="nv">self</span>.<span class="nv">distribute_strategy</span>.<span class="nv">scope</span><span class="ss">()</span>:

      <span class="nv">iterator</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">single_batch_iterator</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>, <span class="nv">x</span><span class="ss">)</span>

      <span class="nv">self</span>.<span class="nv">predict_function</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">make_predict_function</span><span class="ss">()</span>

      <span class="nv">outputs</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">predict_function</span><span class="ss">(</span><span class="nv">iterator</span><span class="ss">)</span>

    <span class="k">return</span> <span class="nv">tf_utils</span>.<span class="nv">sync_to_numpy_or_python_type</span><span class="ss">(</span><span class="nv">outputs</span><span class="ss">)</span>
</code></pre></div>

</details>
<h4 id="predict_step_1">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference and returns the boxes, scores and labels associated.</p>
<p>Background is discarded the max and argmax operation are performed.
It means that if background was predicted the second maximum score would
be outputed.</p>
<p>Example: background + 3 classes
[0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</p>
<p>"To optimize for AP, we override the prediction of these slots
with the second highest scoring class, using the corresponding confidence"
Part 4. Experiments of Object Detection with Transformers</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>boxes</td>
<td>A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]<br>containing the boxes with the coordinates between 0 and 1.<br>scores: A Tensor of shape [batch_size, self.num_queries] containing<br>    the score of the boxes.<br>classes: A Tensor of shape [batch_size, self.num_queries]<br>    containing the class of the boxes [0, num_classes).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="nv">def</span> <span class="nv">predict_step</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">data</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Perform an inference and returns the boxes, scores and labels associated.</span>

        <span class="nv">Background</span> <span class="nv">is</span> <span class="nv">discarded</span> <span class="nv">the</span> <span class="nv">max</span> <span class="nv">and</span> <span class="nv">argmax</span> <span class="nv">operation</span> <span class="nv">are</span> <span class="nv">performed</span>.

        <span class="nv">It</span> <span class="nv">means</span> <span class="nv">that</span> <span class="k">if</span> <span class="nv">background</span> <span class="nv">was</span> <span class="nv">predicted</span> <span class="nv">the</span> <span class="nv">second</span> <span class="nv">maximum</span> <span class="nv">score</span> <span class="nv">would</span>

        <span class="nv">be</span> <span class="nv">outputed</span>.

        <span class="nv">Example</span>: <span class="nv">background</span> <span class="o">+</span> <span class="mi">3</span> <span class="nv">classes</span>

        [<span class="mi">0</span>.<span class="mi">54</span>, <span class="mi">0</span>.<span class="mi">40</span>, <span class="mi">0</span>.<span class="mi">03</span>, <span class="mi">0</span>.<span class="mi">03</span>] <span class="o">=&gt;</span> <span class="nv">score</span> <span class="o">=</span> <span class="mi">0</span>.<span class="mi">40</span>, <span class="nv">label</span> <span class="o">=</span> <span class="mi">0</span> <span class="ss">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="ss">)</span>

        <span class="s2">&quot;</span><span class="s">To optimize for AP, we override the prediction of these slots</span>

        <span class="nv">with</span> <span class="nv">the</span> <span class="nv">second</span> <span class="nv">highest</span> <span class="nv">scoring</span> <span class="nv">class</span>, <span class="nv">using</span> <span class="nv">the</span> <span class="nv">corresponding</span> <span class="nv">confidence</span><span class="s2">&quot;</span>

        <span class="nv">Part</span> <span class="mi">4</span>. <span class="nv">Experiments</span> <span class="nv">of</span> <span class="nv">Object</span> <span class="nv">Detection</span> <span class="nv">with</span> <span class="nv">Transformers</span>

        <span class="nv">Returns</span>:

            <span class="nv">boxes</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>, <span class="ss">(</span><span class="nv">y1</span>,<span class="nv">x1</span>,<span class="nv">y2</span>,<span class="nv">x2</span><span class="ss">)</span>]

                <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">boxes</span> <span class="nv">with</span> <span class="nv">the</span> <span class="nv">coordinates</span> <span class="nv">between</span> <span class="mi">0</span> <span class="nv">and</span> <span class="mi">1</span>.

            <span class="nv">scores</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>] <span class="nv">containing</span>

                <span class="nv">the</span> <span class="nv">score</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">boxes</span>.

            <span class="nv">classes</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>]

                <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">class</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">boxes</span> [<span class="mi">0</span>, <span class="nv">num_classes</span><span class="ss">)</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">data</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">expand_1d</span><span class="ss">(</span><span class="nv">data</span><span class="ss">)</span>

        <span class="nv">x</span>, <span class="nv">_</span>, <span class="nv">_</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">unpack_x_y_sample_weight</span><span class="ss">(</span><span class="nv">data</span><span class="ss">)</span>

        <span class="nv">y_pred</span> <span class="o">=</span> <span class="nv">self</span><span class="ss">(</span><span class="nv">x</span>, <span class="nv">training</span><span class="o">=</span><span class="nv">False</span><span class="ss">)</span>

        <span class="nv">boxes_without_padding</span>, <span class="nv">scores</span>, <span class="nv">labels</span> <span class="o">=</span> <span class="nv">detr_postprocessing</span><span class="ss">(</span>

            <span class="nv">y_pred</span>[<span class="nv">BoxField</span>.<span class="nv">BOXES</span>],

            <span class="nv">y_pred</span>[<span class="nv">BoxField</span>.<span class="nv">SCORES</span>],

            <span class="nv">x</span>[<span class="nv">DatasetField</span>.<span class="nv">IMAGES_INFO</span>],

            <span class="nv">tf</span>.<span class="nv">shape</span><span class="ss">(</span><span class="nv">x</span>[<span class="nv">DatasetField</span>.<span class="nv">IMAGES</span>]<span class="ss">)</span>[<span class="mi">1</span>:<span class="mi">3</span>],

        <span class="ss">)</span>

        <span class="k">return</span> <span class="nv">boxes_without_padding</span>, <span class="nv">scores</span>, <span class="nv">labels</span>
</code></pre></div>

</details>
<h4 id="reset_metrics_1">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
_ = model.fit(x, y, verbose=0)
assert all(float(m.result()) for m in model.metrics)</p>
<p>model.reset_metrics()
assert all(float(m.result()) == 0 for m in model.metrics)</p>
</blockquote>
</blockquote>
</blockquote>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">reset_metrics</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Resets the state of all the metrics in the model.</span>

    <span class="nv">Examples</span>:

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">inputs</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">layers</span>.<span class="nv">Input</span><span class="ss">(</span><span class="nv">shape</span><span class="o">=</span><span class="ss">(</span><span class="mi">3</span>,<span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">outputs</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">layers</span>.<span class="nv">Dense</span><span class="ss">(</span><span class="mi">2</span><span class="ss">)(</span><span class="nv">inputs</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">models</span>.<span class="nv">Model</span><span class="ss">(</span><span class="nv">inputs</span><span class="o">=</span><span class="nv">inputs</span>, <span class="nv">outputs</span><span class="o">=</span><span class="nv">outputs</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">optimizer</span><span class="o">=</span><span class="s2">&quot;</span><span class="s">Adam</span><span class="s2">&quot;</span>, <span class="nv">loss</span><span class="o">=</span><span class="s2">&quot;</span><span class="s">mse</span><span class="s2">&quot;</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s2">&quot;</span><span class="s">mae</span><span class="s2">&quot;</span>]<span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">x</span> <span class="o">=</span> <span class="nv">np</span>.<span class="k">random</span>.<span class="k">random</span><span class="ss">((</span><span class="mi">2</span>, <span class="mi">3</span><span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">y</span> <span class="o">=</span> <span class="nv">np</span>.<span class="k">random</span>.<span class="nv">randint</span><span class="ss">(</span><span class="mi">0</span>, <span class="mi">2</span>, <span class="ss">(</span><span class="mi">2</span>, <span class="mi">2</span><span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">_</span> <span class="o">=</span> <span class="nv">model</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">x</span>, <span class="nv">y</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">assert</span> <span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span> <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span>.<span class="nv">reset_metrics</span><span class="ss">()</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">assert</span> <span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">metrics</span>:

      <span class="nv">m</span>.<span class="nv">reset_state</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="reset_states_1">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">reset_states</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

    <span class="k">for</span> <span class="nv">layer</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">layers</span>:

      <span class="k">if</span> <span class="nv">hasattr</span><span class="ss">(</span><span class="nv">layer</span>, <span class="s1">&#39;</span><span class="s">reset_states</span><span class="s1">&#39;</span><span class="ss">)</span> <span class="nv">and</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">layer</span>, <span class="s1">&#39;</span><span class="s">stateful</span><span class="s1">&#39;</span>, <span class="nv">False</span><span class="ss">)</span>:

        <span class="nv">layer</span>.<span class="nv">reset_states</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="save_1">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p>Args:
    filepath: String, PathLike, path to SavedModel or H5 file to save the
        model.
    overwrite: Whether to silently overwrite any existing file at the
        target location, or provide the user with a manual prompt.
    include_optimizer: If True, save optimizer's state together.
    save_format: Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the
        model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,
        and 'h5' in TF 1.X.
    signatures: Signatures to save with the SavedModel. Applicable to the
        'tf' format only. Please see the <code>signatures</code> argument in
        <code>tf.saved_model.save</code> for details.
    options: (only applies to SavedModel format)
        <code>tf.saved_model.SaveOptions</code> object that specifies options for
        saving to SavedModel.
    save_traces: (only applies to SavedModel format) When enabled, the
        SavedModel will store the function traces for each layer. This
        can be disabled, so that only the configs of each layer are stored.
        Defaults to <code>True</code>. Disabling this will decrease serialization time
        and reduce file size, but it requires that all custom layers/models
        implement a <code>get_config()</code> method.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>  <span class="c1"># creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a compiled model</span>
<span class="c1"># identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="c1"># pylint: disable=line-too-long</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">    Please see `tf.keras.models.save_model` or the</span>

<span class="s2">    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">    for details.</span>

<span class="s2">    Args:</span>

<span class="s2">        filepath: String, PathLike, path to SavedModel or H5 file to save the</span>

<span class="s2">            model.</span>

<span class="s2">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">            target location, or provide the user with a manual prompt.</span>

<span class="s2">        include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">        save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">            model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X,</span>

<span class="s2">            and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">        signatures: Signatures to save with the SavedModel. Applicable to the</span>

<span class="s2">            &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">            `tf.saved_model.save` for details.</span>

<span class="s2">        options: (only applies to SavedModel format)</span>

<span class="s2">            `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">            saving to SavedModel.</span>

<span class="s2">        save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">            SavedModel will store the function traces for each layer. This</span>

<span class="s2">            can be disabled, so that only the configs of each layer are stored.</span>

<span class="s2">            Defaults to `True`. Disabling this will decrease serialization time</span>

<span class="s2">            and reduce file size, but it requires that all custom layers/models</span>

<span class="s2">            implement a `get_config()` method.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    from keras.models import load_model</span>

<span class="s2">    model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">    del model  # deletes the existing model</span>

<span class="s2">    # returns a compiled model</span>

<span class="s2">    # identical to the previous one</span>

<span class="s2">    model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># pylint: enable=line-too-long</span><span class="w"></span>

<span class="w">    </span><span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">overwrite</span><span class="p">,</span><span class="w"> </span><span class="n">include_optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">signatures</span><span class="p">,</span><span class="w"> </span><span class="k">options</span><span class="p">,</span><span class="w"> </span><span class="n">save_traces</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="save_spec_1">save_spec</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_spec</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dynamic_batch</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the <code>tf.TensorSpec</code> of call inputs as a tuple <code>(args, kwargs)</code>.</p>
<p>This value is automatically defined after calling the model for the first
time. Afterwards, you can use it when exporting the model for serving:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">serve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="c1"># Apply postprocessing steps, or add additional outputs.</span>
  <span class="o">...</span>
  <span class="k">return</span> <span class="n">outputs</span>

<span class="c1"># arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is</span>
<span class="c1"># an empty dict since functional models do not use keyword arguments.</span>
<span class="n">arg_specs</span><span class="p">,</span> <span class="n">kwarg_specs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">save_spec</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">signatures</span><span class="o">=</span><span class="p">{</span>
  <span class="s1">&#39;serving_default&#39;</span><span class="p">:</span> <span class="n">serve</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="o">*</span><span class="n">arg_specs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwarg_specs</span><span class="p">)</span>
<span class="p">})</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>dynamic_batch</td>
<td>Whether to set the batch sizes of all the returned<br><code>tf.TensorSpec</code> to <code>None</code>. (Note that when defining functional or<br>Sequential models with <code>tf.keras.Input([...], batch_size=X)</code>, the<br>batch size will always be preserved). Defaults to <code>True</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>If the model inputs are defined, returns a tuple <code>(args, kwargs)</code>. All<br>elements in <code>args</code> and <code>kwargs</code> are <code>tf.TensorSpec</code>.<br>If the model inputs are not defined, returns <code>None</code>.<br>The model inputs are automatically set when calling the model,<br><code>model.fit</code>, <code>model.evaluate</code> or <code>model.predict</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save_spec</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.</span>

<span class="s2">    This value is automatically defined after calling the model for the first</span>

<span class="s2">    time. Afterwards, you can use it when exporting the model for serving:</span>

<span class="s2">    ```python</span>

<span class="s2">    model = tf.keras.Model(...)</span>

<span class="s2">    @tf.function</span>

<span class="s2">    def serve(*args, **kwargs):</span>

<span class="s2">      outputs = model(*args, **kwargs)</span>

<span class="s2">      # Apply postprocessing steps, or add additional outputs.</span>

<span class="s2">      ...</span>

<span class="s2">      return outputs</span>

<span class="s2">    # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is</span>

<span class="s2">    # an empty dict since functional models do not use keyword arguments.</span>

<span class="s2">    arg_specs, kwarg_specs = model.save_spec()</span>

<span class="s2">    model.save(path, signatures={</span>

<span class="s2">      &#39;serving_default&#39;: serve.get_concrete_function(*arg_specs, **kwarg_specs)</span>

<span class="s2">    })</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      dynamic_batch: Whether to set the batch sizes of all the returned</span>

<span class="s2">        `tf.TensorSpec` to `None`. (Note that when defining functional or</span>

<span class="s2">        Sequential models with `tf.keras.Input([...], batch_size=X)`, the</span>

<span class="s2">        batch size will always be preserved). Defaults to `True`.</span>

<span class="s2">    Returns:</span>

<span class="s2">      If the model inputs are defined, returns a tuple `(args, kwargs)`. All</span>

<span class="s2">      elements in `args` and `kwargs` are `tf.TensorSpec`.</span>

<span class="s2">      If the model inputs are not defined, returns `None`.</span>

<span class="s2">      The model inputs are automatically set when calling the model,</span>

<span class="s2">      `model.fit`, `model.evaluate` or `model.predict`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_save_spec</span><span class="p">(</span><span class="n">dynamic_batch</span><span class="p">,</span><span class="w"> </span><span class="n">inputs_only</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="save_weights_1">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <code>tf.train.Checkpoint</code>, including any <code>Layer</code>
instances or <code>Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code>tf.keras.Model(inputs,
outputs)</code>, <code>Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <code>tf.keras.Model</code>,
<code>Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <code>tf.train.Checkpoint</code> and
<code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should be
loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code> this
is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached. This
means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading into a
<code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa) will not match
the <code>Model</code>'s variables. See the
<a href="https://www.tensorflow.org/guide/checkpoint">guide to training checkpoints</a>
for details on the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>String or PathLike, path to the file to save the weights to.<br>When saving in TensorFlow format, this is the prefix used for<br>checkpoint files (multiple files are generated). Note that the '.h5'<br>suffix causes weights to be saved in HDF5 format.</td>
</tr>
<tr>
<td>overwrite</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
</tr>
<tr>
<td>save_format</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or<br>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>. Otherwise<br><code>None</code> defaults to 'tf'.</td>
</tr>
<tr>
<td>options</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for saving weights.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available when attempting to save in HDF5<br>format.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">    Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">    argument.</span>

<span class="sd">    When saving in HDF5 format, the weight file has:</span>

<span class="sd">      - `layer_names` (attribute), a list of strings</span>

<span class="sd">          (ordered names of model layers).</span>

<span class="sd">      - For every layer, a `group` named `layer.name`</span>

<span class="sd">          - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">              a list of strings</span>

<span class="sd">              (ordered names of weights tensor of the layer).</span>

<span class="sd">          - For every weight in the layer, a dataset</span>

<span class="sd">              storing the weight value, named after the weight tensor.</span>

<span class="sd">    When saving in TensorFlow format, all objects referenced by the network are</span>

<span class="sd">    saved in the same format as `tf.train.Checkpoint`, including any `Layer`</span>

<span class="sd">    instances or `Optimizer` instances assigned to object attributes. For</span>

<span class="sd">    networks constructed from inputs and outputs using `tf.keras.Model(inputs,</span>

<span class="sd">    outputs)`, `Layer` instances used by the network are tracked/saved</span>

<span class="sd">    automatically. For user-defined classes which inherit from `tf.keras.Model`,</span>

<span class="sd">    `Layer` instances must be assigned to object attributes, typically in the</span>

<span class="sd">    constructor. See the documentation of `tf.train.Checkpoint` and</span>

<span class="sd">    `tf.keras.Model` for details.</span>

<span class="sd">    While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be</span>

<span class="sd">    loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">    `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">    `save_weights` for training checkpoints.</span>

<span class="sd">    The TensorFlow format matches objects and variables by starting at a root</span>

<span class="sd">    object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">    names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this</span>

<span class="sd">    is the `Checkpoint` even if the `Checkpoint` has a model attached. This</span>

<span class="sd">    means saving a `tf.keras.Model` using `save_weights` and loading into a</span>

<span class="sd">    `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match</span>

<span class="sd">    the `Model`&#39;s variables. See the</span>

<span class="sd">    [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)</span>

<span class="sd">    for details on the TensorFlow format.</span>

<span class="sd">    Args:</span>

<span class="sd">        filepath: String or PathLike, path to the file to save the weights to.</span>

<span class="sd">            When saving in TensorFlow format, this is the prefix used for</span>

<span class="sd">            checkpoint files (multiple files are generated). Note that the &#39;.h5&#39;</span>

<span class="sd">            suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">            target location, or provide the user with a manual prompt.</span>

<span class="sd">        save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">            &#39;.keras&#39; will default to HDF5 if `save_format` is `None`. Otherwise</span>

<span class="sd">            `None` defaults to &#39;tf&#39;.</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for saving weights.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If `h5py` is not available when attempting to save in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath_is_h5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">user_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">elif</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;hdf5&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;keras&#39;</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">f</span><span class="s1">&#39;Unknown format. Received: `save_format`={save_format}. Was &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="s1">&#39;filepath ({filepath}) looks like an HDF5 file. &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;Omit the &quot;.h5&quot;/&quot;.keras&quot; when saving in TensorFlow format.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;`save_weights` requires h5py when saving in hdf5, but h5py is not &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;available. Try installing h5py package.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;.index&#39;</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If file exists and should not be overwritten:</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">overwrite</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="n">proceed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">proceed</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Record this checkpoint so it&#39;s visible from tf.train.latest_checkpoint.</span><span class="w"></span>

<span class="w">      </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">update_checkpoint_state</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span><span class="w"></span>

<span class="w">          </span><span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">])</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="summary_1">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show_trainable</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>Total length of printed lines<br>(e.g. set this to adapt the display to different<br>terminal window sizes).</td>
</tr>
<tr>
<td>positions</td>
<td>Relative or absolute positions of log elements<br>in each line. If not provided,<br>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
</tr>
<tr>
<td>print_fn</td>
<td>Print function to use. Defaults to <code>print</code>.<br>It will be called on each line of the summary.<br>You can set it to a custom function<br>in order to capture the string summary.</td>
</tr>
<tr>
<td>expand_nested</td>
<td>Whether to expand the nested models.<br>If not provided, defaults to <code>False</code>.</td>
</tr>
<tr>
<td>show_trainable</td>
<td>Whether to show if a layer is trainable.<br>If not provided, defaults to <code>False</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">expand_nested</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">show_trainable</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">    Args:</span>

<span class="s2">        line_length: Total length of printed lines</span>

<span class="s2">            (e.g. set this to adapt the display to different</span>

<span class="s2">            terminal window sizes).</span>

<span class="s2">        positions: Relative or absolute positions of log elements</span>

<span class="s2">            in each line. If not provided,</span>

<span class="s2">            defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">        print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">            It will be called on each line of the summary.</span>

<span class="s2">            You can set it to a custom function</span>

<span class="s2">            in order to capture the string summary.</span>

<span class="s2">        expand_nested: Whether to expand the nested models.</span>

<span class="s2">            If not provided, defaults to `False`.</span>

<span class="s2">        show_trainable: Whether to show if a layer is trainable.</span>

<span class="s2">            If not provided, defaults to `False`.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;This model has not yet been built. &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;Build the model first by calling `build()` or by calling &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;the model on a batch of data.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">expand_nested</span><span class="o">=</span><span class="n">expand_nested</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">show_trainable</span><span class="o">=</span><span class="n">show_trainable</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="test_on_batch_1">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors, if<br>    the model has named inputs.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case of<br>temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated across<br>batches.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">test_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="s2">              model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="s2">              multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors, if</span>

<span class="s2">              the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="test_step_1">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="p">#</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">need</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">get</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">results</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">decoder</span><span class="w"> </span><span class="n">layer</span><span class="w"></span>

<span class="w">        </span><span class="p">#</span><span class="w"> </span><span class="n">Setting</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">True</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">provide</span><span class="w"> </span><span class="n">it</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mh">1</span><span class="o">:</span><span class="mh">3</span><span class="p">],</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_dtype</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">loss_metric</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">m</span><span class="p">.</span><span class="nl">name:</span><span class="w"> </span><span class="n">m</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">}</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="to_json_1">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>Additional keyword arguments<br>to be passed to <code>json.dumps()</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">    To load a network from a JSON save file, use</span>

<span class="sd">    `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">    Args:</span>

<span class="sd">        **kwargs: Additional keyword arguments</span>

<span class="sd">            to be passed to `json.dumps()`.</span>

<span class="sd">    Returns:</span>

<span class="sd">        A JSON string.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">model_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">model_config</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="to_yaml_1">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>Note: Since TF 2.6, this method is no longer supported and will raise a
RuntimeError.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>Additional keyword arguments<br>to be passed to <code>yaml.dump()</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>announces that the method poses a security risk</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">    Note: Since TF 2.6, this method is no longer supported and will raise a</span>

<span class="s2">    RuntimeError.</span>

<span class="s2">    To load a network from a yaml save file, use</span>

<span class="s2">    `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">    `custom_objects` should be a dictionary mapping</span>

<span class="s2">    the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">    functions / classes.</span>

<span class="s2">    Args:</span>

<span class="s2">        **kwargs: Additional keyword arguments</span>

<span class="s2">            to be passed to `yaml.dump()`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A YAML string.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: announces that the method poses a security risk</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">raise</span><span class="w"> </span><span class="n">RuntimeError</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Method `model.to_yaml()` has been removed due to security risk of &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;arbitrary code execution. Please use `model.to_json()` instead.&#39;</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="train_on_batch_1">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>    (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>    (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case of<br>temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
</tr>
<tr>
<td>class_weight</td>
<td>Optional dictionary mapping class indices (integers) to a<br>weight (float) to apply to the model's loss for the samples from this<br>class during training. This can be useful to tell the model to "pay<br>more attention" to samples from an under-represented class.</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated across<br>batches.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss<br>(if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">              if the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        class_weight: Optional dictionary mapping class indices (integers) to a</span>

<span class="s2">          weight (float) to apply to the model&#39;s loss for the samples from this</span>

<span class="s2">          class during training. This can be useful to tell the model to &quot;</span><span class="n">pay</span><span class="w"></span>

<span class="w">          </span><span class="n">more</span><span class="w"> </span><span class="n">attention</span><span class="s2">&quot; to samples from an under-represented class.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar training loss</span>

<span class="s2">        (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">      RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">         </span><span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">class_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="train_step_1">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">tape</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span><span class="w"> </span><span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span><span class="w"></span>
</code></pre></div>

</details>
<h3 id="detrresnet50pytorch">DeTrResnet50Pytorch</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeTrResnet50Pytorch</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="p">,</span>
    <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p><a href="https://arxiv.org/abs/2005.12872">End-to-End Object Detection with Transformers</a></p>
<p>You can use it as follow:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">DeTrResnet50Pytorch</span><span class="p">(</span><span class="mi">80</span><span class="p">)</span>
<span class="n">base_lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">base_lr</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">ds_test</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">11</span><span class="p">,)</span>
</code></pre></div>

<h4 id="arguments_2">Arguments</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_classes</td>
<td>The number of classes of your dataset<br>(<strong>do not include the background class</strong> it is handle for you)</td>
</tr>
<tr>
<td>backbone</td>
<td>A vision model like ResNet50.</td>
</tr>
<tr>
<td>num_queries</td>
<td>number of object queries, ie detection slot.<br>This is the maximal number of objects<br>DETR can detect in a single image. For COCO, we recommend 100 queries.</td>
</tr>
</tbody>
</table>
<h4 id="call-arguments_2">Call arguments</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>Tuple<br>1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]<br>2. image_informations: A 1D tensor of float32 and shape [(height, width),].<br>    It contains the shape of the image without any padding.<br>3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]<br>    composed of 0 and 1 which allows to know where a padding has been applied.</td>
</tr>
<tr>
<td>training</td>
<td>Is automatically set to <code>True</code> in train mode</td>
</tr>
</tbody>
</table>
<h4 id="call-returns_2">Call returns</h4>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tuple</td>
<td>- <code>logits</code>: A Tensor of shape [batch_size, h, num_classes + 1] class logits<br>- <code>boxes</code>: A Tensor of shape [batch_size, h, 4]<br>where h is num_queries * transformer_decoder.transformer_num_layers if<br>training is true and num_queries otherwise.</td>
</tr>
</tbody>
</table>
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>kerod.model.detr.DeTr</li>
<li>keras.engine.training.Model</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
<li>keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="methods_2">Methods</h4>
<h4 id="call_2">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference in training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>Tuple<br>1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]<br>2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape<br>of the image without any padding.<br>3. images_padding_mask: A 3D tensor of int8 and shape<br>    [batch_size, None, None] composed of 0 and 1 which<br>    allows to know where a padding has been applied.</td>
</tr>
<tr>
<td>training</td>
<td>Is automatically set to <code>True</code> in train mode</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tuple</td>
<td>- <code>logits</code>: A Tensor of shape [batch_size, h, num_classes + 1] class logits<br>- <code>boxes</code>: A Tensor of shape [batch_size, h, 4]<br>where h is num_queries * transformer_decoder.transformer_num_layers if<br>training is true and num_queries otherwise.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Perform an inference in training.</span>

<span class="s2">        Arguments:</span>

<span class="s2">            inputs: Tuple</span>

<span class="s2">                1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="s2">                2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="s2">                of the image without any padding.</span>

<span class="s2">                3. images_padding_mask: A 3D tensor of int8 and shape</span>

<span class="s2">                    [batch_size, None, None] composed of 0 and 1 which</span>

<span class="s2">                    allows to know where a padding has been applied.</span>

<span class="s2">            training: Is automatically set to `True` in train mode</span>

<span class="s2">        Returns:</span>

<span class="s2">            Tuple:</span>

<span class="s2">                - `logits`: A Tensor of shape [batch_size, h, num_classes + 1] class logits</span>

<span class="s2">                - `boxes`: A Tensor of shape [batch_size, h, 4]</span>

<span class="s2">                where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="s2">                training is true and num_queries otherwise.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">images_padding_masks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_PMASK</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="err">[</span><span class="p">...,</span><span class="w"> </span><span class="k">None</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="w"></span>

<span class="w">                                        </span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="err">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="err">]</span><span class="p">,</span><span class="w"></span>

<span class="w">                                        </span><span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ResizeMethod</span><span class="p">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="kt">bool</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Positional_encoding for the backbone</span><span class="w"></span>

<span class="w">        </span><span class="n">pos_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, num_queries, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">all_the_queries</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_the_queries</span><span class="err">[</span><span class="k">None</span><span class="err">]</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, num_queries, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">query_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Flatten the position embedding and the spatial tensor</span><span class="w"></span>

<span class="w">        </span><span class="c1"># to allow the preprocessing by the Transformer</span><span class="w"></span>

<span class="w">        </span><span class="c1"># [batch_size, h * w,  self.hidden_dim]</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="n">pos_embed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Flatten the padding masks</span><span class="w"></span>

<span class="w">        </span><span class="n">features_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="n">decoder_out</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">pos_embed</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">query_embed</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span><span class="w"></span>

<span class="w">                                          </span><span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="o">:</span><span class="w"> </span><span class="n">logits</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="o">:</span><span class="w"> </span><span class="n">boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compile_2">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">jit_compile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span>
                       <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FalseNegatives</span><span class="p">()])</span>
</code></pre></div>

<p>Args:
    optimizer: String (name of optimizer) or optimizer instance. See
      <code>tf.keras.optimizers</code>.
    loss: Loss function. Maybe be a string (name of loss function), or
      a <code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. A loss
      function is any callable with the signature <code>loss = fn(y_true,
      y_pred)</code>, where <code>y_true</code> are the ground truth values, and
      <code>y_pred</code> are the model's predictions.
      <code>y_true</code> should have shape
      <code>(batch_size, d0, .. dN)</code> (except in the case of
      sparse loss functions such as
      sparse categorical crossentropy which expects integer arrays of shape
      <code>(batch_size, d0, .. dN-1)</code>).
      <code>y_pred</code> should have shape <code>(batch_size, d0, .. dN)</code>.
      The loss function should return a float tensor.
      If a custom <code>Loss</code> instance is
      used and reduction is set to <code>None</code>, return value has shape
      <code>(batch_size, d0, .. dN-1)</code> i.e. per-sample or per-timestep loss
      values; otherwise, it is a scalar. If the model has multiple outputs,
      you can use a different loss on each output by passing a dictionary
      or a list of losses. The loss value that will be minimized by the
      model will then be the sum of all individual losses, unless
      <code>loss_weights</code> is specified.
    metrics: List of metrics to be evaluated by the model during training
      and testing. Each of this can be a string (name of a built-in
      function), function or a <code>tf.keras.metrics.Metric</code> instance. See
      <code>tf.keras.metrics</code>. Typically you will use <code>metrics=['accuracy']</code>. A
      function is any callable with the signature <code>result = fn(y_true,
      y_pred)</code>. To specify different metrics for different outputs of a
      multi-output model, you could also pass a dictionary, such as
      <code>metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>.
      You can also pass a list to specify a metric or a list of metrics
      for each output, such as <code>metrics=[['accuracy'], ['accuracy', 'mse']]</code>
      or <code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the
      strings 'accuracy' or 'acc', we convert this to one of
      <code>tf.keras.metrics.BinaryAccuracy</code>,
      <code>tf.keras.metrics.CategoricalAccuracy</code>,
      <code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss
      function used and the model output shape. We do a similar
      conversion for the strings 'crossentropy' and 'ce' as well.
    loss_weights: Optional list or dictionary specifying scalar coefficients
      (Python floats) to weight the loss contributions of different model
      outputs. The loss value that will be minimized by the model will then
      be the <em>weighted sum</em> of all individual losses, weighted by the
      <code>loss_weights</code> coefficients.
        If a list, it is expected to have a 1:1 mapping to the model's
          outputs. If a dict, it is expected to map output names (strings)
          to scalar coefficients.
    weighted_metrics: List of metrics to be evaluated and weighted by
      <code>sample_weight</code> or <code>class_weight</code> during training and testing.
    run_eagerly: Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s
      logic will not be wrapped in a <code>tf.function</code>. Recommended to leave
      this as <code>None</code> unless your <code>Model</code> cannot be run inside a
      <code>tf.function</code>. <code>run_eagerly=True</code> is not supported when using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    steps_per_execution: Int. Defaults to 1. The number of batches to run
      during each <code>tf.function</code> call. Running multiple batches inside a
      single <code>tf.function</code> call can greatly improve performance on TPUs or
      small models with a large Python overhead. At most, one full epoch
      will be run each execution. If a number larger than the size of the
      epoch is passed, the execution will be truncated to the size of the
      epoch. Note that if <code>steps_per_execution</code> is set to <code>N</code>,
      <code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods will
      only be called every <code>N</code> batches (i.e. before/after each <code>tf.function</code>
      execution).
    jit_compile: If <code>True</code>, compile the model training step with XLA.
      <a href="https://www.tensorflow.org/xla">XLA</a> is an optimizing compiler for
      machine learning.
      <code>jit_compile</code> is not enabled for by default.
      This option cannot be enabled with <code>run_eagerly=True</code>.
      Note that <code>jit_compile=True</code> is
      may not necessarily work for all models.
      For more information on supported operations please refer to the
      <a href="https://www.tensorflow.org/xla">XLA documentation</a>.
      Also refer to
      <a href="https://www.tensorflow.org/xla/known_issues">known XLA issues</a> for
      more details.
    **kwargs: Arguments supported for backwards compatibility only.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="p">@</span><span class="n">traceback_utils</span><span class="p">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compile</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">optimizer</span><span class="o">=</span><span class="err">&#39;</span><span class="n">rmsprop</span><span class="err">&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">loss</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">loss_weights</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">weighted_metrics</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">jit_compile</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;Configures the model for training.</span>

<span class="w">    </span><span class="nl">Example</span><span class="p">:</span><span class="w"></span>

<span class="w">    </span><span class="err">```</span><span class="n">python</span><span class="w"></span>

<span class="w">    </span><span class="n">model</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span><span class="w"></span>

<span class="w">                  </span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span><span class="w"></span>

<span class="w">                  </span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span><span class="w"></span>

<span class="w">                           </span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">FalseNegatives</span><span class="p">()])</span><span class="w"></span>

<span class="w">    </span><span class="err">```</span><span class="w"></span>

<span class="w">    </span><span class="nl">Args</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="nl">optimizer</span><span class="p">:</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">optimizer</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="n">function</span><span class="p">.</span><span class="w"> </span><span class="n">Maybe</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">or</span><span class="w"></span>

<span class="w">          </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ground</span><span class="w"> </span><span class="n">truth</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">predictions</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_true</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="p">(</span><span class="n">except</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"></span>

<span class="w">          </span><span class="n">sparse</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">functions</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"></span>

<span class="w">          </span><span class="n">sparse</span><span class="w"> </span><span class="n">categorical</span><span class="w"> </span><span class="n">crossentropy</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">integer</span><span class="w"> </span><span class="n">arrays</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="p">).</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">y_pred</span><span class="err">`</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">custom</span><span class="w"> </span><span class="err">`</span><span class="n">Loss</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="w"> </span><span class="n">is</span><span class="w"></span>

<span class="w">          </span><span class="n">used</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">reduction</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">shape</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">d0</span><span class="p">,</span><span class="w"> </span><span class="p">..</span><span class="w"> </span><span class="n">dN</span><span class="mi">-1</span><span class="p">)</span><span class="err">`</span><span class="w"> </span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">sample</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">per</span><span class="o">-</span><span class="n">timestep</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">values</span><span class="p">;</span><span class="w"> </span><span class="n">otherwise</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">scalar</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">you</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">passing</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dictionary</span><span class="w"></span>

<span class="w">          </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">losses</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">unless</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">specified</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"></span>

<span class="w">          </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">built</span><span class="o">-</span><span class="k">in</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Metric</span><span class="err">`</span><span class="w"> </span><span class="n">instance</span><span class="p">.</span><span class="w"> </span><span class="n">See</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Typically</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">A</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">callable</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">signature</span><span class="w"> </span><span class="err">`</span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y_pred</span><span class="p">)</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="n">multi</span><span class="o">-</span><span class="n">output</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dictionary</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="err">&#39;</span><span class="n">output_a</span><span class="err">&#39;</span><span class="o">:</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">output_b</span><span class="err">&#39;</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]}</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">specify</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="w"></span>

<span class="w">          </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="n">mse</span><span class="err">&#39;</span><span class="p">]]</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">When</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">pass</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">accuracy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">&#39;</span><span class="n">acc</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">convert</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">of</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">CategoricalAccuracy</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="err">`</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">          </span><span class="n">function</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">similar</span><span class="w"></span>

<span class="w">          </span><span class="n">conversion</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">strings</span><span class="w"> </span><span class="err">&#39;</span><span class="n">crossentropy</span><span class="err">&#39;</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">&#39;</span><span class="n">ce</span><span class="err">&#39;</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">well</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">loss_weights</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">dictionary</span><span class="w"> </span><span class="n">specifying</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="n">coefficients</span><span class="w"></span>

<span class="w">          </span><span class="p">(</span><span class="n">Python</span><span class="w"> </span><span class="n">floats</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">contributions</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">model</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimized</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">then</span><span class="w"></span>

<span class="w">          </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">*</span><span class="n">weighted</span><span class="w"> </span><span class="n">sum</span><span class="o">*</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">loss_weights</span><span class="err">`</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w"></span>

<span class="w">            </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="w"> </span><span class="n">mapping</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="err">&#39;</span><span class="n">s</span><span class="w"></span>

<span class="w">              </span><span class="n">outputs</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dict</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">map</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="p">(</span><span class="n">strings</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">to</span><span class="w"> </span><span class="n">scalar</span><span class="w"> </span><span class="n">coefficients</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">weighted_metrics</span><span class="p">:</span><span class="w"> </span><span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">evaluated</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">by</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">sample_weight</span><span class="err">`</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="err">`</span><span class="n">class_weight</span><span class="err">`</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">testing</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">run_eagerly</span><span class="p">:</span><span class="w"> </span><span class="n">Bool</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">False</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`&#39;</span><span class="n">s</span><span class="w"></span>

<span class="w">          </span><span class="n">logic</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">wrapped</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="n">Recommended</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">leave</span><span class="w"></span>

<span class="w">          </span><span class="n">this</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="err">`</span><span class="n">None</span><span class="err">`</span><span class="w"> </span><span class="n">unless</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="err">`</span><span class="n">Model</span><span class="err">`</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="p">.</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">using</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">ParameterServerStrategy</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="nl">steps_per_execution</span><span class="p">:</span><span class="w"> </span><span class="n">Int</span><span class="p">.</span><span class="w"> </span><span class="n">Defaults</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mf">1.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">run</span><span class="w"></span>

<span class="w">          </span><span class="n">during</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="p">.</span><span class="w"> </span><span class="n">Running</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="n">a</span><span class="w"></span>

<span class="w">          </span><span class="n">single</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">greatly</span><span class="w"> </span><span class="n">improve</span><span class="w"> </span><span class="n">performance</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">TPUs</span><span class="w"> </span><span class="n">or</span><span class="w"></span>

<span class="w">          </span><span class="n">small</span><span class="w"> </span><span class="n">models</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="n">overhead</span><span class="p">.</span><span class="w"> </span><span class="n">At</span><span class="w"> </span><span class="n">most</span><span class="p">,</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">full</span><span class="w"> </span><span class="n">epoch</span><span class="w"></span>

<span class="w">          </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">execution</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">larger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">passed</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">truncated</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch</span><span class="p">.</span><span class="w"> </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_begin</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">Callback</span><span class="p">.</span><span class="n">on_batch_end</span><span class="err">`</span><span class="w"> </span><span class="n">methods</span><span class="w"> </span><span class="n">will</span><span class="w"></span>

<span class="w">          </span><span class="n">only</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">every</span><span class="w"> </span><span class="err">`</span><span class="n">N</span><span class="err">`</span><span class="w"> </span><span class="n">batches</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="w"> </span><span class="n">before</span><span class="o">/</span><span class="n">after</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="err">`</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="err">`</span><span class="w"></span>

<span class="w">          </span><span class="n">execution</span><span class="p">).</span><span class="w"></span>

<span class="w">        </span><span class="nl">jit_compile</span><span class="p">:</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="err">`</span><span class="n">True</span><span class="err">`</span><span class="p">,</span><span class="w"> </span><span class="n">compile</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">XLA</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">XLA</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla) is an optimizing compiler for</span>

<span class="w">          </span><span class="n">machine</span><span class="w"> </span><span class="n">learning</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="k">default</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">This</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">enabled</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">Note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="o">=</span><span class="n">True</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"></span>

<span class="w">          </span><span class="n">may</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">necessarily</span><span class="w"> </span><span class="n">work</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">models</span><span class="p">.</span><span class="w"></span>

<span class="w">          </span><span class="n">For</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">information</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="n">operations</span><span class="w"> </span><span class="n">please</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">XLA</span><span class="w"> </span><span class="n">documentation</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla).</span>

<span class="w">          </span><span class="n">Also</span><span class="w"> </span><span class="n">refer</span><span class="w"> </span><span class="n">to</span><span class="w"></span>

<span class="w">          </span><span class="p">[</span><span class="n">known</span><span class="w"> </span><span class="n">XLA</span><span class="w"> </span><span class="n">issues</span><span class="p">](</span><span class="n">https</span><span class="o">:</span><span class="c1">//www.tensorflow.org/xla/known_issues) for</span>

<span class="w">          </span><span class="n">more</span><span class="w"> </span><span class="n">details</span><span class="p">.</span><span class="w"></span>

<span class="w">        </span><span class="o">**</span><span class="n">kwargs</span><span class="o">:</span><span class="w"> </span><span class="n">Arguments</span><span class="w"> </span><span class="n">supported</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">backwards</span><span class="w"> </span><span class="n">compatibility</span><span class="w"> </span><span class="n">only</span><span class="p">.</span><span class="w"></span>

<span class="w">    </span><span class="s">&quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="err">&#39;</span><span class="n">compile</span><span class="err">&#39;</span><span class="p">).</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="err">&#39;</span><span class="n">experimental_steps_per_execution</span><span class="err">&#39;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="err">&#39;</span><span class="n">The</span><span class="w"> </span><span class="n">argument</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">longer</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">                        </span><span class="err">&#39;</span><span class="n">experimental</span><span class="p">.</span><span class="w"> </span><span class="n">Pass</span><span class="w"> </span><span class="err">`</span><span class="n">steps_per_execution</span><span class="err">`</span><span class="w"> </span><span class="n">instead</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">                        </span><span class="err">&#39;`</span><span class="n">experimental_steps_per_execution</span><span class="err">`</span><span class="p">.</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="err">&#39;</span><span class="n">experimental_steps_per_execution</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="cp"># When compiling from an already-serialized model, we do not want to</span>

<span class="w">      </span><span class="cp"># reapply some processing steps (e.g. metric renaming for multi-output</span>

<span class="w">      </span><span class="cp"># models, which have prefixes added for each corresponding output name).</span>

<span class="w">      </span><span class="n">from_serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="err">&#39;</span><span class="n">from_serialized</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">False</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_eagerly</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">loss_weights</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">metrics</span><span class="p">,</span><span class="w"> </span><span class="n">weighted_metrics</span><span class="p">,</span><span class="w"> </span><span class="n">output_names</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">from_serialized</span><span class="o">=</span><span class="n">from_serialized</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="cp"># Initializes attrs that are reset each time `compile` is called.</span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">_is_compiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span><span class="w"></span>

<span class="w">      </span><span class="nb">self</span><span class="p">.</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="p">{}</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">self</span><span class="p">.</span><span class="n">_run_eagerly</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="nb">self</span><span class="p">.</span><span class="n">dynamic</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="err">&#39;</span><span class="n">You</span><span class="w"> </span><span class="n">cannot</span><span class="w"> </span><span class="n">enable</span><span class="w"> </span><span class="err">`</span><span class="n">run_eagerly</span><span class="err">`</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="err">`</span><span class="n">jit_compile</span><span class="err">`</span><span class="w"> </span><span class="err">&#39;</span><span class="w"></span>

<span class="w">            </span><span class="err">&#39;</span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">same</span><span class="w"> </span><span class="n">time</span><span class="p">.</span><span class="err">&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="nl">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="nb">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jit_compile</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_loss_2">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

<p>Apply the GIoU, L1 and SCC to each layers of the transformer decoder</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ground_truths</td>
<td>see output kerod.dataset.preprocessing for the doc</td>
</tr>
<tr>
<td>y_pred</td>
<td>A dict<br>- <em>scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits<br>- </em>bbox*: A Tensor of shape [batch_size, num_queries, 4]</td>
</tr>
<tr>
<td>input_shape</td>
<td>[height, width] of the input tensor.<br>It is the shape of the images will all the padding included.<br>It is used to normalize the ground_truths boxes.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">ground_truths</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">int</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="ss">        Arguments:</span>

<span class="ss">            ground_truths: see output kerod.dataset.preprocessing for the doc</span>

<span class="ss">            y_pred: A dict</span>

<span class="ss">                - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="ss">                - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="ss">            input_shape: [height, width] of the input tensor.</span>

<span class="ss">                It is the shape of the images will all the padding included.</span>

<span class="ss">                It is used to normalize the ground_truths boxes.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, 2</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">centered_normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">counted</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">LABELS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">centered_normalized_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">WEIGHTS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.WEIGHTS</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">NUM_BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.SCORES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">{</span>

<span class="n">            BoxField.BOXES: boxes,</span>

<span class="n">            BoxField.SCORES: logits</span>

<span class="n">        } for boxes, logits in zip(boxes_per_lvl, logits_per_lvl)</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Giou</span><span class="p">,</span><span class="w"> </span><span class="n">L1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">SCC</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">layers</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Logs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">            </span><span class="n">compute_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">num_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_metrics_2">compute_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span>
<span class="p">)</span>
</code></pre></div>

<p>Update metric states and collect all metrics to be returned.</p>
<p>Subclasses can optionally override this method to provide custom metric
updating and collection logic.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>

    <span class="c1"># This super call updates `self.compiled_metrics` and returns results</span>
    <span class="c1"># for all metrics listed in `self.metrics`.</span>
    <span class="n">metric_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="c1"># Note that `self.custom_metric` is not listed in `self.metrics`.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">metric_results</span><span class="p">[</span><span class="s1">&#39;custom_metric_name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">metric_results</span>
</code></pre></div>

<p>Args:
  x: Input data.
  y: Target data.
  y_pred: Predictions returned by the model (output of <code>model.call(x)</code>)
  sample_weight: Sample weights for weighting the loss function.</p>
<p>Returns:
  A <code>dict</code> containing values that will be passed to
  <code>tf.keras.callbacks.CallbackList.on_train_batch_end()</code>. Typically, the
  values of the metrics listed in <code>self.metrics</code> are returned. Example:
  <code>{'loss': 0.2, 'accuracy': 0.7}</code>.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Update metric states and collect all metrics to be returned.</span>

<span class="s2">    Subclasses can optionally override this method to provide custom metric</span>

<span class="s2">    updating and collection logic.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    class MyModel(tf.keras.Sequential):</span>

<span class="s2">      def compute_metrics(self, x, y, y_pred, sample_weight):</span>

<span class="s2">        # This super call updates `self.compiled_metrics` and returns results</span>

<span class="s2">        # for all metrics listed in `self.metrics`.</span>

<span class="s2">        metric_results = super(MyModel, self).compute_metrics(</span>

<span class="s2">            x, y, y_pred, sample_weight)</span>

<span class="s2">        # Note that `self.custom_metric` is not listed in `self.metrics`.</span>

<span class="s2">        self.custom_metric.update_state(x, y, y_pred, sample_weight)</span>

<span class="s2">        metric_results[&#39;custom_metric_name&#39;] = self.custom_metric.result()</span>

<span class="s2">        return metric_results</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      x: Input data.</span>

<span class="s2">      y: Target data.</span>

<span class="s2">      y_pred: Predictions returned by the model (output of `model.call(x)`)</span>

<span class="s2">      sample_weight: Sample weights for weighting the loss function.</span>

<span class="s2">    Returns:</span>

<span class="s2">      A `dict` containing values that will be passed to</span>

<span class="s2">      `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the</span>

<span class="s2">      values of the metrics listed in `self.metrics` are returned. Example:</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">del</span><span class="w"> </span><span class="n">x</span><span class="w">  </span><span class="c1"># The default implementation does not use `x`.</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Collect metrics to return</span><span class="w"></span>

<span class="w">    </span><span class="n">return_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metric</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">return_metrics</span><span class="p">.</span><span class="k">update</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">return_metrics</span><span class="err">[</span><span class="n">metric</span><span class="p">.</span><span class="k">name</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">return_metrics</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="evaluate_2">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>  if the model has named inputs.<br>- A <code>tf.data</code> dataset. Should return a tuple<br>  of either <code>(inputs, targets)</code> or<br>  <code>(inputs, targets, sample_weights)</code>.<br>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code><br>  or <code>(inputs, targets, sample_weights)</code>.<br>A more detailed description of unpacking behavior for iterator types<br>(Dataset, generator, Sequence) is given in the <code>Unpacking behavior&lt;br&gt;for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely). If<br><code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance, <code>y</code><br>should not be specified (since targets will be obtained from the<br>iterator/dataset).</td>
</tr>
<tr>
<td>batch_size</td>
<td>Integer or <code>None</code>. Number of samples per batch of<br>computation. If unspecified, <code>batch_size</code> will default to 32. Do not<br>specify the <code>batch_size</code> if your data is in the form of a dataset,<br>generators, or <code>keras.utils.Sequence</code> instances (since they generate<br>batches).</td>
</tr>
<tr>
<td>verbose</td>
<td>0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional Numpy array of weights for the test samples,<br>used for weighting the loss function. You can either pass a flat (1D)<br>Numpy array with the same length as the input samples<br>  (1:1 mapping between weights and samples), or in the case of<br>    temporal data, you can pass a 2D array with shape <code>(samples,&lt;br&gt;    sequence_length)</code>, to apply a different weight to every timestep<br>    of every sample. This argument is not supported when <code>x</code> is a<br>    dataset, instead pass sample weights as the third element of <code>x</code>.</td>
</tr>
<tr>
<td>steps</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)<br>before declaring the evaluation round finished. Ignored with the<br>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code> is<br>None, 'evaluate' will run until the dataset is exhausted. This<br>argument is not supported with array inputs.</td>
</tr>
<tr>
<td>callbacks</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of<br>callbacks to apply during evaluation. See<br><a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code><br>input only. Maximum size for the generator queue. If unspecified,<br><code>max_queue_size</code> will default to 10.</td>
</tr>
<tr>
<td>workers</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using process-based<br>threading. If unspecified, <code>workers</code> will default to 1.</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to the<br>generator as they can't be passed easily to children processes.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
<tr>
<td>**kwargs</td>
<td>Unused at this time.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">               </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">    Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">            if the model has named inputs.</span>

<span class="s2">          - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">            of either `(inputs, targets)` or</span>

<span class="s2">            `(inputs, targets, sample_weights)`.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="s2">            or `(inputs, targets, sample_weights)`.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>

<span class="s2">          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`</span>

<span class="s2">          should not be specified (since targets will be obtained from the</span>

<span class="s2">          iterator/dataset).</span>

<span class="s2">        batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">          computation. If unspecified, `batch_size` will default to 32. Do not</span>

<span class="s2">          specify the `batch_size` if your data is in the form of a dataset,</span>

<span class="s2">          generators, or `keras.utils.Sequence` instances (since they generate</span>

<span class="s2">          batches).</span>

<span class="s2">        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</span>

<span class="s2">        sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">          used for weighting the loss function. You can either pass a flat (1D)</span>

<span class="s2">          Numpy array with the same length as the input samples</span>

<span class="s2">            (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">              temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">              sequence_length)`, to apply a different weight to every timestep</span>

<span class="s2">              of every sample. This argument is not supported when `x` is a</span>

<span class="s2">              dataset, instead pass sample weights as the third element of `x`.</span>

<span class="s2">        steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">          before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">          default value of `None`. If x is a `tf.data` dataset and `steps` is</span>

<span class="s2">          None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">          argument is not supported with array inputs.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">          callbacks to apply during evaluation. See</span>

<span class="s2">          [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">          input only. Maximum size for the generator queue. If unspecified,</span>

<span class="s2">          `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">          only. Maximum number of processes to spin up when using process-based</span>

<span class="s2">          threading. If unspecified, `workers` will default to 1.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">          `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">          threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">          `False`. Note that because this implementation relies on</span>

<span class="s2">          multiprocessing, you should not pass non-picklable arguments to the</span>

<span class="s2">          generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">        **kwargs: Unused at this time.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">use_cached_eval_dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;_use_cached_eval_dataset&#39;</span><span class="p">,</span><span class="w"> </span><span class="no">False</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">kwargs</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Invalid keyword arguments: {list(kwargs.keys())}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">coordinator</span><span class="p">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">use_cached_eval_dataset</span><span class="w"></span>

<span class="w">          </span><span class="k">and</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">        </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">            </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">profiler</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"> </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span><span class="w"></span>

<span class="w">                </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">              </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span><span class="w">  </span><span class="c1"># No error, now safe to assign to logs.</span><span class="w"></span>

<span class="w">              </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="evaluate_generator_2">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                         </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.evaluate` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.evaluate_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.evaluate`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="fit_2">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Args:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code>
        or <code>(inputs, targets, sample_weights)</code>.
      - A <code>tf.keras.utils.experimental.DatasetCreator</code>, which wraps a
        callable that takes a single argument of type
        <code>tf.distribute.InputContext</code>, and returns a <code>tf.data.Dataset</code>.
        <code>DatasetCreator</code> should be used when users prefer to specify the
        per-replica batching and sharding logic for the <code>Dataset</code>.
        See <code>tf.keras.utils.experimental.DatasetCreator</code> doc for more
        information.
      A more detailed description of unpacking behavior for iterator types
      (Dataset, generator, Sequence) is given below. If using
      <code>tf.distribute.experimental.ParameterServerStrategy</code>, only
      <code>DatasetCreator</code> type is supported for <code>x</code>.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided
        (unless the <code>steps_per_epoch</code> flag is set to
        something other than None).
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 'auto', 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        'auto' defaults to 1 for most cases, but 2 when used with
        <code>ParameterServerStrategy</code>. Note that the progress bar is not
        particularly useful when logged to a file, so verbose=2 is
        recommended when not running interactively (eg, in a production
        environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note <code>tf.keras.callbacks.ProgbarLogger</code>
        and <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
        Callbacks with batch-level calls are currently unsupported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>, and users are
        advised to implement epoch-level calls instead with an appropriate
        <code>steps_per_epoch</code> value.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
        not supported when <code>x</code> is a dataset, generator or
       <code>keras.utils.Sequence</code> instance.
        <code>validation_split</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using <code>validation_split</code>
        or <code>validation_data</code> is not affected by regularization layers like
        noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - A tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors.
          - A tuple <code>(x_val, y_val, val_sample_weights)</code> of NumPy arrays.
          - A <code>tf.data.Dataset</code>.
          - A Python generator or <code>keras.utils.Sequence</code> returning
          <code>(inputs, targets)</code> or <code>(inputs, targets, sample_weights)</code>.
        <code>validation_data</code> is not yet supported with
        <code>tf.distribute.experimental.ParameterServerStrategy</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is ignored
        when <code>x</code> is a generator or an object of tf.data.Dataset.
        'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample. This
        argument is not supported when <code>x</code> is a dataset, generator, or
       <code>keras.utils.Sequence</code> instance, instead provide the sample_weights
        as the third element of <code>x</code>.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is exhausted.
        When passing an infinitely repeating dataset, you must specify the
        <code>steps_per_epoch</code> argument. If <code>steps_per_epoch=-1</code> the training
        will run indefinitely with an infinitely repeating dataset.
        This argument is not supported with array inputs.
        When using <code>tf.distribute.experimental.ParameterServerStrategy</code>:
          * <code>steps_per_epoch=None</code> is not supported.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None, validation
        will run until the <code>validation_data</code> dataset is exhausted. In the
        case of an infinitely repeated dataset, it will run into an
        infinite loop. If 'validation_steps' is specified and only part of
        the dataset will be consumed, the evaluation will start from the
        beginning of the dataset at each epoch. This ensures that the same
        validation samples are used every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    validation_freq: Only relevant if validation data is provided. Integer
        or <code>collections.abc.Container</code> instance (e.g. list, tuple, etc.).
        If an integer, specifies how many training epochs to run before a
        new validation run is performed, e.g. <code>validation_freq=2</code> runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
        validation at the end of the 1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or <code>keras.utils.Sequence</code>
        input only. Maximum size for the generator queue.
        If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as 'x'. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code>x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span><span class="w"> </span><span class="n">In</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">mismatch</span><span class="w"> </span><span class="n">between</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"></span>
<span class="w">    </span><span class="n">and</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">expects</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="o">.</span><span class="w"></span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Args:</span>

<span class="sd">        x: Input data. It could be:</span>

<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">            if the model has named inputs.</span>

<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">            of either `(inputs, targets)` or</span>

<span class="sd">            `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="sd">            or `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a</span>

<span class="sd">            callable that takes a single argument of type</span>

<span class="sd">            `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.</span>

<span class="sd">            `DatasetCreator` should be used when users prefer to specify the</span>

<span class="sd">            per-replica batching and sharding logic for the `Dataset`.</span>

<span class="sd">            See `tf.keras.utils.experimental.DatasetCreator` doc for more</span>

<span class="sd">            information.</span>

<span class="sd">          A more detailed description of unpacking behavior for iterator types</span>

<span class="sd">          (Dataset, generator, Sequence) is given below. If using</span>

<span class="sd">          `tf.distribute.experimental.ParameterServerStrategy`, only</span>

<span class="sd">          `DatasetCreator` type is supported for `x`.</span>

<span class="sd">        y: Target data. Like the input data `x`,</span>

<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">          not be specified (since targets will be obtained from `x`).</span>

<span class="sd">        batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per gradient update.</span>

<span class="sd">            If unspecified, `batch_size` will default to 32.</span>

<span class="sd">            Do not specify the `batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">            data provided</span>

<span class="sd">            (unless the `steps_per_epoch` flag is set to</span>

<span class="sd">            something other than None).</span>

<span class="sd">            Note that in conjunction with `initial_epoch`,</span>

<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">            The model is not trained for a number of iterations</span>

<span class="sd">            given by `epochs`, but merely until the epoch</span>

<span class="sd">            of index `epochs` is reached.</span>

<span class="sd">        verbose: &#39;auto&#39;, 0, 1, or 2. Verbosity mode.</span>

<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">            &#39;auto&#39; defaults to 1 for most cases, but 2 when used with</span>

<span class="sd">            `ParameterServerStrategy`. Note that the progress bar is not</span>

<span class="sd">            particularly useful when logged to a file, so verbose=2 is</span>

<span class="sd">            recommended when not running interactively (eg, in a production</span>

<span class="sd">            environment).</span>

<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`</span>

<span class="sd">            and `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">            and need not be passed into `model.fit`.</span>

<span class="sd">            `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">            `verbose` argument to `model.fit`.</span>

<span class="sd">            Callbacks with batch-level calls are currently unsupported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`, and users are</span>

<span class="sd">            advised to implement epoch-level calls instead with an appropriate</span>

<span class="sd">            `steps_per_epoch` value.</span>

<span class="sd">        validation_split: Float between 0 and 1.</span>

<span class="sd">            Fraction of the training data to be used as validation data.</span>

<span class="sd">            The model will set apart this fraction of the training data,</span>

<span class="sd">            will not train on it, and will evaluate</span>

<span class="sd">            the loss and any model metrics</span>

<span class="sd">            on this data at the end of each epoch.</span>

<span class="sd">            The validation data is selected from the last samples</span>

<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>

<span class="sd">            not supported when `x` is a dataset, generator or</span>

<span class="sd">           `keras.utils.Sequence` instance.</span>

<span class="sd">            `validation_split` is not yet supported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">        validation_data: Data on which to evaluate</span>

<span class="sd">            the loss and any model metrics at the end of each epoch.</span>

<span class="sd">            The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">            that the validation loss of data provided using `validation_split`</span>

<span class="sd">            or `validation_data` is not affected by regularization layers like</span>

<span class="sd">            noise and dropout.</span>

<span class="sd">            `validation_data` will override `validation_split`.</span>

<span class="sd">            `validation_data` could be:</span>

<span class="sd">              - A tuple `(x_val, y_val)` of Numpy arrays or tensors.</span>

<span class="sd">              - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.</span>

<span class="sd">              - A `tf.data.Dataset`.</span>

<span class="sd">              - A Python generator or `keras.utils.Sequence` returning</span>

<span class="sd">              `(inputs, targets)` or `(inputs, targets, sample_weights)`.</span>

<span class="sd">            `validation_data` is not yet supported with</span>

<span class="sd">            `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">            before each epoch) or str (for &#39;batch&#39;). This argument is ignored</span>

<span class="sd">            when `x` is a generator or an object of tf.data.Dataset.</span>

<span class="sd">            &#39;batch&#39; is a special option for dealing</span>

<span class="sd">            with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">            chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">            to a weight (float) value, used for weighting the loss function</span>

<span class="sd">            (during training only).</span>

<span class="sd">            This can be useful to tell the model to</span>

<span class="sd">            &quot;pay more attention&quot; to samples from</span>

<span class="sd">            an under-represented class.</span>

<span class="sd">        sample_weight: Optional Numpy array of weights for</span>

<span class="sd">            the training samples, used for weighting the loss function</span>

<span class="sd">            (during training only). You can either pass a flat (1D)</span>

<span class="sd">            Numpy array with the same length as the input samples</span>

<span class="sd">            (1:1 mapping between weights and samples),</span>

<span class="sd">            or in the case of temporal data,</span>

<span class="sd">            you can pass a 2D array with shape</span>

<span class="sd">            `(samples, sequence_length)`,</span>

<span class="sd">            to apply a different weight to every timestep of every sample. This</span>

<span class="sd">            argument is not supported when `x` is a dataset, generator, or</span>

<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>

<span class="sd">            as the third element of `x`.</span>

<span class="sd">        initial_epoch: Integer.</span>

<span class="sd">            Epoch at which to start training</span>

<span class="sd">            (useful for resuming a previous training run).</span>

<span class="sd">        steps_per_epoch: Integer or `None`.</span>

<span class="sd">            Total number of steps (batches of samples)</span>

<span class="sd">            before declaring one epoch finished and starting the</span>

<span class="sd">            next epoch. When training with input tensors such as</span>

<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">            the number of samples in your dataset divided by</span>

<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>

<span class="sd">            When passing an infinitely repeating dataset, you must specify the</span>

<span class="sd">            `steps_per_epoch` argument. If `steps_per_epoch=-1` the training</span>

<span class="sd">            will run indefinitely with an infinitely repeating dataset.</span>

<span class="sd">            This argument is not supported with array inputs.</span>

<span class="sd">            When using `tf.distribute.experimental.ParameterServerStrategy`:</span>

<span class="sd">              * `steps_per_epoch=None` is not supported.</span>

<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">            samples) to draw before stopping when performing validation</span>

<span class="sd">            at the end of every epoch. If &#39;validation_steps&#39; is None, validation</span>

<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>

<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>

<span class="sd">            infinite loop. If &#39;validation_steps&#39; is specified and only part of</span>

<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>

<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>

<span class="sd">            validation samples are used every time.</span>

<span class="sd">        validation_batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per validation batch.</span>

<span class="sd">            If unspecified, will default to `batch_size`.</span>

<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>

<span class="sd">            or `collections.abc.Container` instance (e.g. list, tuple, etc.).</span>

<span class="sd">            If an integer, specifies how many training epochs to run before a</span>

<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>

<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>

<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>

<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="sd">            input only. Maximum size for the generator queue.</span>

<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">            only. Maximum number of processes to spin up</span>

<span class="sd">            when using process-based threading. If unspecified, `workers`</span>

<span class="sd">            will default to 1.</span>

<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">            `False`. Note that because this implementation relies on</span>

<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">        A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">      yield not only features (x) but optionally targets (y) and sample weights.</span>

<span class="sd">      Keras requires that the output of such iterator-likes be unambiguous. The</span>

<span class="sd">      iterator should return a tuple of length 1, 2, or 3, where the optional</span>

<span class="sd">      second and third elements will be used for y and sample_weight</span>

<span class="sd">      respectively. Any other type provided will be wrapped in a length one</span>

<span class="sd">      tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they</span>

<span class="sd">      should still adhere to the top-level tuple structure.</span>

<span class="sd">      e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">      features, targets, and weights from the keys of a single dict.</span>

<span class="sd">        A notable unsupported data type is the namedtuple. The reason is that</span>

<span class="sd">      it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">      datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">          `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">      it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">      interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">          `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">      where it is unclear if the tuple was intended to be unpacked into x, y,</span>

<span class="sd">      and sample_weight or passed through as a single element to `x`. As a</span>

<span class="sd">      result the data processing code will simply raise a ValueError if it</span>

<span class="sd">      encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>

<span class="sd">        A `History` object. Its `History.history` attribute is</span>

<span class="sd">        a record of training loss values and metrics values</span>

<span class="sd">        at successive epochs, as well as validation loss values</span>

<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>

<span class="sd">        RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">        2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">        ValueError: In case of mismatch between the provided input data</span>

<span class="sd">            and what the model expects or when the input data is empty.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;auto&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w">  </span><span class="c1"># Default to epoch-level logging for PSStrategy.</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w">  </span><span class="c1"># Default to batch-level logging otherwise.</span><span class="w"></span>

<span class="w">    </span><span class="k">elif</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;`verbose=1` is not allowed with `ParameterServerStrategy` for &#39;</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="s1">&#39;performance reasons. Received: `verbose`={verbose}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">validation_split</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Create the validation data using the training data. Only supported for</span><span class="w"></span>

<span class="w">      </span><span class="c1"># `Tensor` and `NumPy` input.</span><span class="w"></span>

<span class="w">      </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">),</span><span class="w"> </span><span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">))</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">val_x</span><span class="p">,</span><span class="w"> </span><span class="n">val_y</span><span class="p">,</span><span class="w"> </span><span class="n">val_sample_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">))</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">coordinator</span><span class="o">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span>\<span class="w"></span>

<span class="w">         </span><span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Handle fault-tolerance for multi-worker.</span><span class="w"></span>

<span class="w">      </span><span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span><span class="w"></span>

<span class="w">      </span><span class="c1"># happen after `callbacks.on_train_begin`.</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">          </span><span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">))</span><span class="w"></span>

<span class="w">      </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span><span class="w"></span>

<span class="w">            </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span><span class="w"></span>

<span class="w">                </span><span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="n">tmp_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">              </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_logs</span><span class="w">  </span><span class="c1"># No error, now safe to assign to logs.</span><span class="w"></span>

<span class="w">              </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="k">break</span><span class="w"></span>

<span class="w">        </span><span class="n">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">logs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected result of `train_function` &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;(Empty logs). Please use &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;`Model.compile(..., run_eagerly=True)`, or &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;`tf.config.run_functions_eagerly(True)` for more &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;information of where went wrong, or file a &#39;</span><span class="w"></span>

<span class="w">                           </span><span class="s1">&#39;issue/bug to `tf.keras`.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">epoch_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Run validation.</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">validation_data</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">validation_freq</span><span class="p">):</span><span class="w"></span>

<span class="w">          </span><span class="c1"># Create data_handler for evaluation and cache it.</span><span class="w"></span>

<span class="w">          </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">                </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">_use_cached_eval_dataset</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">val_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="s1">&#39;val_&#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span><span class="w"></span>

<span class="w">          </span><span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">epoch_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">training_logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">epoch_logs</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="k">break</span><span class="w"></span>

<span class="w">      </span><span class="c1"># If eval data_handler exists, delete it after all epochs are done.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">del</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="fit_generator_2">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to use
  this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">fit_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.fit` now supports generators, so there is no longer any need to use</span>

<span class="ss">      this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.fit_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.fit`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_layer_2">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>String, name of layer.</td>
</tr>
<tr>
<td>index</td>
<td>Integer, index of layer.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">    If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">    Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">    Args:</span>

<span class="s2">        name: String, name of layer.</span>

<span class="s2">        index: Integer, index of layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A layer instance.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span><span class="w"></span>

<span class="w">    </span><span class="c1"># since they are constant, but we have not done that yet.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide only a layer name or a layer index. Received: &#39;</span><span class="w"></span>

<span class="w">                       </span><span class="n">f</span><span class="s1">&#39;index={index}, name={name}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="k">index</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Was asked to retrieve layer at index {index}&#39;</span><span class="w"></span>

<span class="w">                         </span><span class="n">f</span><span class="s1">&#39; but model only has {len(self.layers)}&#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39; layers.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">name</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">layer</span><span class="p">.</span><span class="k">name</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">name</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="n">layer</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;No such layer: {name}. Existing layers are: &#39;</span><span class="w"></span>

<span class="w">                       </span><span class="n">f</span><span class="s1">&#39;{list(layer.name for layer in self.layers)}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index at &#39;</span><span class="w"></span>

<span class="w">                     </span><span class="s1">&#39;`get_layer`.&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="load_weights_2">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don't have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<code>tf.keras.Model</code>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>String, path to the weights file to load. For weight files in<br>TensorFlow format, this is the file prefix (the same as was passed<br>to <code>save_weights</code>). This can also be a path to a SavedModel<br>saved from <code>model.save</code>.</td>
</tr>
<tr>
<td>by_name</td>
<td>Boolean, whether to load weights by name or by topological<br>order. Only topological loading is supported for weight files in<br>TensorFlow format.</td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>Boolean, whether to skip loading of layers where there is<br>a mismatch in the number of weights, or a mismatch in the shape of<br>the weight (only valid when <code>by_name=True</code>).</td>
</tr>
<tr>
<td>options</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for loading weights.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same status<br>object as <code>tf.train.Checkpoint.restore</code>. When graph building, restore<br>ops are run automatically as soon as the network is built (on first call<br>for user-defined classes inheriting from <code>Model</code>, immediately if it is<br>already built).<br><br>When loading weights in HDF5 format, returns <code>None</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available and the weight file is in HDF5<br>format.</td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is<br><code>False</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">    If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">    topology. This means the architecture should be the same as when the weights</span>

<span class="sd">    were saved.  Note that layers that don&#39;t have weights are not taken into</span>

<span class="sd">    account in the topological ordering, so adding or removing layers is fine as</span>

<span class="sd">    long as they don&#39;t have weights.</span>

<span class="sd">    If `by_name` is True, weights are loaded into layers only if they share the</span>

<span class="sd">    same name. This is useful for fine-tuning or transfer-learning models where</span>

<span class="sd">    some of the layers have changed.</span>

<span class="sd">    Only topological loading (`by_name=False`) is supported when loading weights</span>

<span class="sd">    from the TensorFlow format. Note that topological loading differs slightly</span>

<span class="sd">    between TensorFlow and HDF5 formats for user-defined classes inheriting from</span>

<span class="sd">    `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>

<span class="sd">    TensorFlow format loads based on the object-local names of attributes to</span>

<span class="sd">    which layers are assigned in the `Model`&#39;s constructor.</span>

<span class="sd">    Args:</span>

<span class="sd">        filepath: String, path to the weights file to load. For weight files in</span>

<span class="sd">            TensorFlow format, this is the file prefix (the same as was passed</span>

<span class="sd">            to `save_weights`). This can also be a path to a SavedModel</span>

<span class="sd">            saved from `model.save`.</span>

<span class="sd">        by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">            order. Only topological loading is supported for weight files in</span>

<span class="sd">            TensorFlow format.</span>

<span class="sd">        skip_mismatch: Boolean, whether to skip loading of layers where there is</span>

<span class="sd">            a mismatch in the number of weights, or a mismatch in the shape of</span>

<span class="sd">            the weight (only valid when `by_name=True`).</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for loading weights.</span>

<span class="sd">    Returns:</span>

<span class="sd">        When loading a weight file in TensorFlow format, returns the same status</span>

<span class="sd">        object as `tf.train.Checkpoint.restore`. When graph building, restore</span>

<span class="sd">        ops are run automatically as soon as the network is built (on first call</span>

<span class="sd">        for user-defined classes inheriting from `Model`, immediately if it is</span>

<span class="sd">        already built).</span>

<span class="sd">        When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If `h5py` is not available and the weight file is in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">          `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="ow">and</span><span class="w"></span>

<span class="w">          </span><span class="p">(</span><span class="ow">not</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span><span class="w"></span>

<span class="w">        </span><span class="n">spr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not implemented with TPUStrategy &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;with `steps_per_run` greater than 1. The &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="n">f</span><span class="s1">&#39;`steps_per_run` is {spr}&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;When calling model.load_weights, skip_mismatch can only be set to &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;True when by_name is True.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_detect_save_format</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Weights may only be loaded based on topology into Models when &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;loading TensorFlow-formatted weights (got by_name=True to &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;load_weights).&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Restore existing variables (if any) immediately, and set up a</span><span class="w"></span>

<span class="w">        </span><span class="c1"># streaming restore for any variables created in the future.</span><span class="w"></span>

<span class="w">        </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                   </span><span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;`load_weights` requires h5py package when loading weights from &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;HDF5. Try installing h5py.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Unable to load weights saved in HDF5 format into a subclassed &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Model which has not created its variables yet. Call the Model &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;first, then load the weights.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="s1">&#39;layer_names&#39;</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="s1">&#39;model_weights&#39;</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">by_name</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">skip_mismatch</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">          </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Perform any layer defined finalization of the layer state.</span><span class="w"></span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">layer</span><span class="o">.</span><span class="n">finalize_state</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">status</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_predict_function_2">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the predict function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">    This method can be overridden to support custom inference logic.</span>

<span class="s2">    This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.predict_step`.</span>

<span class="s2">    This function is cached the first time `Model.predict` or</span>

<span class="s2">    `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the predict function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">tf</span><span class="p">.</span><span class="n">autograph</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span><span class="p">(</span><span class="w"></span>

<span class="w">                  </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span><span class="w"></span>

<span class="w">                                </span><span class="k">for</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="err">]</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">step_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="o">:</span><span class="w"> </span><span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="err">]</span><span class="p">),</span><span class="w"></span>

<span class="w">                                          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">step_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">predict_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_test_function_2">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the test function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">    This method can be overridden to support custom evaluation logic.</span>

<span class="s2">    This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.test_step`.</span>

<span class="s2">    This function is cached the first time `Model.evaluate` or</span>

<span class="s2">    `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the test function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If we&#39;re using a coordinator, use the value of self._steps_per_execution</span><span class="w"></span>

<span class="w">    </span><span class="c1"># at the time the function is called/scheduled, and not when it is actually</span><span class="w"></span>

<span class="w">    </span><span class="c1"># executed.</span><span class="w"></span>

<span class="w">    </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">          </span><span class="n">test_function</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">()))</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a test execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">test_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="make_train_function_2">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">force</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called. You can skip the cache and generate again the
function with <code>force=True</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>force</td>
<td>Whether to regenerate the train function and skip the cached<br>function if available.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a<br><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will<br>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as<br><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">force</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">    This method can be overridden to support custom training logic.</span>

<span class="s2">    This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">    logic to `Model.train_step`.</span>

<span class="s2">    This function is cached the first time `Model.fit` or</span>

<span class="s2">    `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called. You can skip the cache and generate again the</span>

<span class="s2">    function with `force=True`.</span>

<span class="s2">    Args:</span>

<span class="s2">      force: Whether to regenerate the train function and skip the cached</span>

<span class="s2">        function if available.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">force</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_jit_compile</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">run_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">jit_compile</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduce_per_replica</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Special case if steps_per_execution is one.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">or</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with a single step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,))</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If we&#39;re using a coordinator, use the value of self._steps_per_execution</span><span class="w"></span>

<span class="w">    </span><span class="c1"># at the time the function is called/scheduled, and not when it is actually</span><span class="w"></span>

<span class="w">    </span><span class="c1"># executed.</span><span class="w"></span>

<span class="w">    </span><span class="n">elif</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span><span class="w"> </span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="n">it</span><span class="o">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="p">.</span><span class="k">schedule</span><span class="p">(</span><span class="w">  </span><span class="c1"># pylint: disable=g-long-lambda</span><span class="w"></span>

<span class="w">          </span><span class="n">train_function</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="k">value</span><span class="p">()))</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">def</span><span class="w"> </span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">outputs</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">function</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">train_function</span><span class="p">,</span><span class="w"> </span><span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">train_tf_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_function</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_2">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for batch processing
of large numbers of inputs. It is not intended for use inside of loops
that iterate over your data and process small numbers of inputs at a time.</p>
<p>For small numbers of inputs that fit in one batch,
directly use <code>__call__()</code> for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behave differently during
inference. You may pair the individual model call with a <code>tf.function</code>
for additional performance inside your inner loop.
If you need access to numpy array values instead of tensors after your
model call, you can use <code>tensor.numpy()</code> to get the numpy array value of
an eager tensor.</p>
<p>Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p>Note: See <a href="https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call">this FAQ entry</a>
for more details about the difference between <code>Model</code> methods <code>predict()</code>
and <code>__call__()</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input samples. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>  (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>  (in case the model has multiple inputs).<br>- A <code>tf.data</code> dataset.<br>- A generator or <code>keras.utils.Sequence</code> instance.<br>A more detailed description of unpacking behavior for iterator types<br>(Dataset, generator, Sequence) is given in the <code>Unpacking behavior&lt;br&gt;for iterator-like inputs</code> section of <code>Model.fit</code>.</td>
</tr>
<tr>
<td>batch_size</td>
<td>Integer or <code>None</code>.<br>Number of samples per batch.<br>If unspecified, <code>batch_size</code> will default to 32.<br>Do not specify the <code>batch_size</code> if your data is in the<br>form of dataset, generators, or <code>keras.utils.Sequence</code> instances<br>(since they generate batches).</td>
</tr>
<tr>
<td>verbose</td>
<td>Verbosity mode, 0 or 1.</td>
</tr>
<tr>
<td>steps</td>
<td>Total number of steps (batches of samples)<br>before declaring the prediction round finished.<br>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code><br>dataset and <code>steps</code> is None, <code>predict()</code> will<br>run until the input dataset is exhausted.</td>
</tr>
<tr>
<td>callbacks</td>
<td>List of <code>keras.callbacks.Callback</code> instances.<br>List of callbacks to apply during prediction.<br>See <a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
</tr>
<tr>
<td>max_queue_size</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code><br>input only. Maximum size for the generator queue.<br>If unspecified, <code>max_queue_size</code> will default to 10.</td>
</tr>
<tr>
<td>workers</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input<br>only. Maximum number of processes to spin up when using<br>process-based threading. If unspecified, <code>workers</code> will default<br>to 1.</td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>Boolean. Used for generator or<br><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based<br>threading. If unspecified, <code>use_multiprocessing</code> will default to<br><code>False</code>. Note that because this implementation relies on<br>multiprocessing, you should not pass non-picklable arguments to<br>the generator as they can't be passed easily to children processes.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided<br>input data and the model's expectations,<br>or in case a stateful model receives a number of samples<br>that is not a multiple of the batch size.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">    Computation is done in batches. This method is designed for batch processing</span>

<span class="s2">    of large numbers of inputs. It is not intended for use inside of loops</span>

<span class="s2">    that iterate over your data and process small numbers of inputs at a time.</span>

<span class="s2">    For small numbers of inputs that fit in one batch,</span>

<span class="s2">    directly use `__call__()` for faster execution, e.g.,</span>

<span class="s2">    `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">    `tf.keras.layers.BatchNormalization` that behave differently during</span>

<span class="s2">    inference. You may pair the individual model call with a `tf.function`</span>

<span class="s2">    for additional performance inside your inner loop.</span>

<span class="s2">    If you need access to numpy array values instead of tensors after your</span>

<span class="s2">    model call, you can use `tensor.numpy()` to get the numpy array value of</span>

<span class="s2">    an eager tensor.</span>

<span class="s2">    Also, note the fact that test loss is not affected by</span>

<span class="s2">    regularization layers like noise and dropout.</span>

<span class="s2">    Note: See [this FAQ entry](</span>

<span class="s2">    https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)</span>

<span class="s2">    for more details about the difference between `Model` methods `predict()`</span>

<span class="s2">    and `__call__()`.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input samples. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A `tf.data` dataset.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        batch_size: Integer or `None`.</span>

<span class="s2">            Number of samples per batch.</span>

<span class="s2">            If unspecified, `batch_size` will default to 32.</span>

<span class="s2">            Do not specify the `batch_size` if your data is in the</span>

<span class="s2">            form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">            (since they generate batches).</span>

<span class="s2">        verbose: Verbosity mode, 0 or 1.</span>

<span class="s2">        steps: Total number of steps (batches of samples)</span>

<span class="s2">            before declaring the prediction round finished.</span>

<span class="s2">            Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">            dataset and `steps` is None, `predict()` will</span>

<span class="s2">            run until the input dataset is exhausted.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">            List of callbacks to apply during prediction.</span>

<span class="s2">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">            input only. Maximum size for the generator queue.</span>

<span class="s2">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">            only. Maximum number of processes to spin up when using</span>

<span class="s2">            process-based threading. If unspecified, `workers` will default</span>

<span class="s2">            to 1.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">            `False`. Note that because this implementation relies on</span>

<span class="s2">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`. Note that Model.predict uses the same interpretation rules as</span>

<span class="s2">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>

<span class="s2">    three methods.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Numpy array(s) of predictions.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.predict` is wrapped in a `tf.function`.</span>

<span class="s2">        ValueError: In case of mismatch between the provided</span>

<span class="s2">            input data and the model&#39;s expectations,</span>

<span class="s2">            or in case a stateful model receives a number of samples</span>

<span class="s2">            that is not a multiple of the batch size.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># TODO(yashkatariya): Cache model on the coordinator for faster prediction.</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If running under PSS, then swap it with OneDeviceStrategy so that</span><span class="w"></span>

<span class="w">    </span><span class="c1"># execution will run on the coordinator.</span><span class="w"></span>

<span class="w">    </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">_should_use_with_coordinator</span><span class="o">:</span><span class="w">  </span><span class="c1"># pylint: disable=protected-access</span><span class="w"></span>

<span class="w">      </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Cluster coordinator is set by `.fit()` and `.evaluate()` which is not</span><span class="w"></span>

<span class="w">    </span><span class="c1"># needed in `.predict()` because all the predictions happen on the</span><span class="w"></span>

<span class="w">    </span><span class="c1"># coordinator/locally.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_cluster_coordinator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span><span class="w"></span>

<span class="w">      </span><span class="n">dataset_types</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">_is_tpu_multi_host</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">))</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">try</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span><span class="w"></span>

<span class="w">          </span><span class="n">data_option</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span><span class="w"></span>

<span class="w">          </span><span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_option</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">except</span><span class="w"> </span><span class="n">ValueError</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;Using Model.predict with MultiWorkerMirroredStrategy or &#39;</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;TPUStrategy and AutoShardPolicy.FILE might lead to out-of-order &#39;</span><span class="w"></span>

<span class="w">              </span><span class="s1">&#39;result. Consider setting it to AutoShardPolicy.DATA.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">data_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">get_data_handler</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="n">iterator</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span><span class="w">  </span><span class="c1"># Single epoch.</span><span class="w"></span>

<span class="w">        </span><span class="k">with</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">tmp_batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span><span class="w"></span>

<span class="w">            </span><span class="n">batch_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_batch_outputs</span><span class="w">  </span><span class="c1"># No error, now safe to assign.</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span><span class="w"></span>

<span class="w">                                           </span><span class="n">batch_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">              </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="w"></span>

<span class="w">                  </span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"></span>

<span class="w">                  </span><span class="n">lambda</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">batch_output</span><span class="o">:</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">),</span><span class="w"></span>

<span class="w">                  </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">batch_outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">end_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span><span class="w"></span>

<span class="w">            </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="s1">&#39;outputs&#39;</span><span class="o">:</span><span class="w"> </span><span class="n">batch_outputs</span><span class="err">}</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">batch_outputs</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected result of `predict_function` &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;(Empty batch_outputs). Please use &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;`Model.compile(..., run_eagerly=True)`, or &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;`tf.config.run_functions_eagerly(True)` for more &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;information of where went wrong, or file a &#39;</span><span class="w"></span>

<span class="w">                         </span><span class="s1">&#39;issue/bug to `tf.keras`.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">all_outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">__internal__</span><span class="p">.</span><span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="n">batch_outputs</span><span class="p">,</span><span class="w"> </span><span class="n">concat</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If originally PSS strategy was used, then replace it back since predict</span><span class="w"></span>

<span class="w">    </span><span class="c1"># is running under `OneDeviceStrategy` after the swap and once its done</span><span class="w"></span>

<span class="w">    </span><span class="c1"># we need to replace it back to PSS again.</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">None</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">_distribution_strategy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">original_pss_strategy</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_generator_2">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_generate_docs</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">predict_generator</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span><span class="w"></span>

<span class="w">                        </span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.predict` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;`Model.predict_generator` is deprecated and &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Please use `Model.predict`, which supports generators.&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">generator</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="predict_on_batch_2">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">predict_on_batch</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">x</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Returns predictions for a single batch of samples.</span>

    <span class="nv">Args</span>:

        <span class="nv">x</span>: <span class="nv">Input</span> <span class="nv">data</span>. <span class="nv">It</span> <span class="nv">could</span> <span class="nv">be</span>:

          <span class="o">-</span> <span class="nv">A</span> <span class="nv">Numpy</span> <span class="nv">array</span> <span class="ss">(</span><span class="nv">or</span> <span class="nv">array</span><span class="o">-</span><span class="nv">like</span><span class="ss">)</span>, <span class="nv">or</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">of</span> <span class="nv">arrays</span> <span class="ss">(</span><span class="nv">in</span> <span class="nv">case</span> <span class="nv">the</span>

              <span class="nv">model</span> <span class="nv">has</span> <span class="nv">multiple</span> <span class="nv">inputs</span><span class="ss">)</span>.

          <span class="o">-</span> <span class="nv">A</span> <span class="nv">TensorFlow</span> <span class="nv">tensor</span>, <span class="nv">or</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">of</span> <span class="nv">tensors</span> <span class="ss">(</span><span class="nv">in</span> <span class="nv">case</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">has</span>

              <span class="nv">multiple</span> <span class="nv">inputs</span><span class="ss">)</span>.

    <span class="nv">Returns</span>:

        <span class="nv">Numpy</span> <span class="nv">array</span><span class="ss">(</span><span class="nv">s</span><span class="ss">)</span> <span class="nv">of</span> <span class="nv">predictions</span>.

    <span class="nv">Raises</span>:

        <span class="nv">RuntimeError</span>: <span class="k">If</span> `<span class="nv">model</span>.<span class="nv">predict_on_batch</span>` <span class="nv">is</span> <span class="nv">wrapped</span> <span class="nv">in</span> <span class="nv">a</span> `<span class="nv">tf</span>.<span class="nv">function</span>`.

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">self</span>.<span class="nv">_check_call_args</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">predict_on_batch</span><span class="s1">&#39;</span><span class="ss">)</span>

    <span class="nv">_disallow_inside_tf_function</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">predict_on_batch</span><span class="s1">&#39;</span><span class="ss">)</span>

    <span class="nv">with</span> <span class="nv">self</span>.<span class="nv">distribute_strategy</span>.<span class="nv">scope</span><span class="ss">()</span>:

      <span class="nv">iterator</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">single_batch_iterator</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">distribute_strategy</span>, <span class="nv">x</span><span class="ss">)</span>

      <span class="nv">self</span>.<span class="nv">predict_function</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">make_predict_function</span><span class="ss">()</span>

      <span class="nv">outputs</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">predict_function</span><span class="ss">(</span><span class="nv">iterator</span><span class="ss">)</span>

    <span class="k">return</span> <span class="nv">tf_utils</span>.<span class="nv">sync_to_numpy_or_python_type</span><span class="ss">(</span><span class="nv">outputs</span><span class="ss">)</span>
</code></pre></div>

</details>
<h4 id="predict_step_2">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference and returns the boxes, scores and labels associated.</p>
<p>Background is discarded the max and argmax operation are performed.
It means that if background was predicted the second maximum score would
be outputed.</p>
<p>Example: background + 3 classes
[0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</p>
<p>"To optimize for AP, we override the prediction of these slots
with the second highest scoring class, using the corresponding confidence"
Part 4. Experiments of Object Detection with Transformers</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>boxes</td>
<td>A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]<br>containing the boxes with the coordinates between 0 and 1.<br>scores: A Tensor of shape [batch_size, self.num_queries] containing<br>    the score of the boxes.<br>classes: A Tensor of shape [batch_size, self.num_queries]<br>    containing the class of the boxes [0, num_classes).</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    <span class="nv">def</span> <span class="nv">predict_step</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">data</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Perform an inference and returns the boxes, scores and labels associated.</span>

        <span class="nv">Background</span> <span class="nv">is</span> <span class="nv">discarded</span> <span class="nv">the</span> <span class="nv">max</span> <span class="nv">and</span> <span class="nv">argmax</span> <span class="nv">operation</span> <span class="nv">are</span> <span class="nv">performed</span>.

        <span class="nv">It</span> <span class="nv">means</span> <span class="nv">that</span> <span class="k">if</span> <span class="nv">background</span> <span class="nv">was</span> <span class="nv">predicted</span> <span class="nv">the</span> <span class="nv">second</span> <span class="nv">maximum</span> <span class="nv">score</span> <span class="nv">would</span>

        <span class="nv">be</span> <span class="nv">outputed</span>.

        <span class="nv">Example</span>: <span class="nv">background</span> <span class="o">+</span> <span class="mi">3</span> <span class="nv">classes</span>

        [<span class="mi">0</span>.<span class="mi">54</span>, <span class="mi">0</span>.<span class="mi">40</span>, <span class="mi">0</span>.<span class="mi">03</span>, <span class="mi">0</span>.<span class="mi">03</span>] <span class="o">=&gt;</span> <span class="nv">score</span> <span class="o">=</span> <span class="mi">0</span>.<span class="mi">40</span>, <span class="nv">label</span> <span class="o">=</span> <span class="mi">0</span> <span class="ss">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="ss">)</span>

        <span class="s2">&quot;</span><span class="s">To optimize for AP, we override the prediction of these slots</span>

        <span class="nv">with</span> <span class="nv">the</span> <span class="nv">second</span> <span class="nv">highest</span> <span class="nv">scoring</span> <span class="nv">class</span>, <span class="nv">using</span> <span class="nv">the</span> <span class="nv">corresponding</span> <span class="nv">confidence</span><span class="s2">&quot;</span>

        <span class="nv">Part</span> <span class="mi">4</span>. <span class="nv">Experiments</span> <span class="nv">of</span> <span class="nv">Object</span> <span class="nv">Detection</span> <span class="nv">with</span> <span class="nv">Transformers</span>

        <span class="nv">Returns</span>:

            <span class="nv">boxes</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>, <span class="ss">(</span><span class="nv">y1</span>,<span class="nv">x1</span>,<span class="nv">y2</span>,<span class="nv">x2</span><span class="ss">)</span>]

                <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">boxes</span> <span class="nv">with</span> <span class="nv">the</span> <span class="nv">coordinates</span> <span class="nv">between</span> <span class="mi">0</span> <span class="nv">and</span> <span class="mi">1</span>.

            <span class="nv">scores</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>] <span class="nv">containing</span>

                <span class="nv">the</span> <span class="nv">score</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">boxes</span>.

            <span class="nv">classes</span>: <span class="nv">A</span> <span class="nv">Tensor</span> <span class="nv">of</span> <span class="nv">shape</span> [<span class="nv">batch_size</span>, <span class="nv">self</span>.<span class="nv">num_queries</span>]

                <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">class</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">boxes</span> [<span class="mi">0</span>, <span class="nv">num_classes</span><span class="ss">)</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">data</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">expand_1d</span><span class="ss">(</span><span class="nv">data</span><span class="ss">)</span>

        <span class="nv">x</span>, <span class="nv">_</span>, <span class="nv">_</span> <span class="o">=</span> <span class="nv">data_adapter</span>.<span class="nv">unpack_x_y_sample_weight</span><span class="ss">(</span><span class="nv">data</span><span class="ss">)</span>

        <span class="nv">y_pred</span> <span class="o">=</span> <span class="nv">self</span><span class="ss">(</span><span class="nv">x</span>, <span class="nv">training</span><span class="o">=</span><span class="nv">False</span><span class="ss">)</span>

        <span class="nv">boxes_without_padding</span>, <span class="nv">scores</span>, <span class="nv">labels</span> <span class="o">=</span> <span class="nv">detr_postprocessing</span><span class="ss">(</span>

            <span class="nv">y_pred</span>[<span class="nv">BoxField</span>.<span class="nv">BOXES</span>],

            <span class="nv">y_pred</span>[<span class="nv">BoxField</span>.<span class="nv">SCORES</span>],

            <span class="nv">x</span>[<span class="nv">DatasetField</span>.<span class="nv">IMAGES_INFO</span>],

            <span class="nv">tf</span>.<span class="nv">shape</span><span class="ss">(</span><span class="nv">x</span>[<span class="nv">DatasetField</span>.<span class="nv">IMAGES</span>]<span class="ss">)</span>[<span class="mi">1</span>:<span class="mi">3</span>],

        <span class="ss">)</span>

        <span class="k">return</span> <span class="nv">boxes_without_padding</span>, <span class="nv">scores</span>, <span class="nv">labels</span>
</code></pre></div>

</details>
<h4 id="reset_metrics_2">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
_ = model.fit(x, y, verbose=0)
assert all(float(m.result()) for m in model.metrics)</p>
<p>model.reset_metrics()
assert all(float(m.result()) == 0 for m in model.metrics)</p>
</blockquote>
</blockquote>
</blockquote>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">reset_metrics</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Resets the state of all the metrics in the model.</span>

    <span class="nv">Examples</span>:

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">inputs</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">layers</span>.<span class="nv">Input</span><span class="ss">(</span><span class="nv">shape</span><span class="o">=</span><span class="ss">(</span><span class="mi">3</span>,<span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">outputs</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">layers</span>.<span class="nv">Dense</span><span class="ss">(</span><span class="mi">2</span><span class="ss">)(</span><span class="nv">inputs</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span> <span class="o">=</span> <span class="nv">tf</span>.<span class="nv">keras</span>.<span class="nv">models</span>.<span class="nv">Model</span><span class="ss">(</span><span class="nv">inputs</span><span class="o">=</span><span class="nv">inputs</span>, <span class="nv">outputs</span><span class="o">=</span><span class="nv">outputs</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">optimizer</span><span class="o">=</span><span class="s2">&quot;</span><span class="s">Adam</span><span class="s2">&quot;</span>, <span class="nv">loss</span><span class="o">=</span><span class="s2">&quot;</span><span class="s">mse</span><span class="s2">&quot;</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s2">&quot;</span><span class="s">mae</span><span class="s2">&quot;</span>]<span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">x</span> <span class="o">=</span> <span class="nv">np</span>.<span class="k">random</span>.<span class="k">random</span><span class="ss">((</span><span class="mi">2</span>, <span class="mi">3</span><span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">y</span> <span class="o">=</span> <span class="nv">np</span>.<span class="k">random</span>.<span class="nv">randint</span><span class="ss">(</span><span class="mi">0</span>, <span class="mi">2</span>, <span class="ss">(</span><span class="mi">2</span>, <span class="mi">2</span><span class="ss">))</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">_</span> <span class="o">=</span> <span class="nv">model</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">x</span>, <span class="nv">y</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">assert</span> <span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span> <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">model</span>.<span class="nv">reset_metrics</span><span class="ss">()</span>

    <span class="o">&gt;&gt;&gt;</span> <span class="nv">assert</span> <span class="nv">all</span><span class="ss">(</span><span class="nv">float</span><span class="ss">(</span><span class="nv">m</span>.<span class="nb">result</span><span class="ss">())</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">model</span>.<span class="nv">metrics</span><span class="ss">)</span>

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="nv">m</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">metrics</span>:

      <span class="nv">m</span>.<span class="nv">reset_state</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="reset_states_2">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>  <span class="nv">def</span> <span class="nv">reset_states</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

    <span class="k">for</span> <span class="nv">layer</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">layers</span>:

      <span class="k">if</span> <span class="nv">hasattr</span><span class="ss">(</span><span class="nv">layer</span>, <span class="s1">&#39;</span><span class="s">reset_states</span><span class="s1">&#39;</span><span class="ss">)</span> <span class="nv">and</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">layer</span>, <span class="s1">&#39;</span><span class="s">stateful</span><span class="s1">&#39;</span>, <span class="nv">False</span><span class="ss">)</span>:

        <span class="nv">layer</span>.<span class="nv">reset_states</span><span class="ss">()</span>
</code></pre></div>

</details>
<h4 id="save_2">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p>Args:
    filepath: String, PathLike, path to SavedModel or H5 file to save the
        model.
    overwrite: Whether to silently overwrite any existing file at the
        target location, or provide the user with a manual prompt.
    include_optimizer: If True, save optimizer's state together.
    save_format: Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the
        model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,
        and 'h5' in TF 1.X.
    signatures: Signatures to save with the SavedModel. Applicable to the
        'tf' format only. Please see the <code>signatures</code> argument in
        <code>tf.saved_model.save</code> for details.
    options: (only applies to SavedModel format)
        <code>tf.saved_model.SaveOptions</code> object that specifies options for
        saving to SavedModel.
    save_traces: (only applies to SavedModel format) When enabled, the
        SavedModel will store the function traces for each layer. This
        can be disabled, so that only the configs of each layer are stored.
        Defaults to <code>True</code>. Disabling this will decrease serialization time
        and reduce file size, but it requires that all custom layers/models
        implement a <code>get_config()</code> method.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>  <span class="c1"># creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a compiled model</span>
<span class="c1"># identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@traceback_utils.filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">           </span><span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="c1"># pylint: disable=line-too-long</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">    Please see `tf.keras.models.save_model` or the</span>

<span class="s2">    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">    for details.</span>

<span class="s2">    Args:</span>

<span class="s2">        filepath: String, PathLike, path to SavedModel or H5 file to save the</span>

<span class="s2">            model.</span>

<span class="s2">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">            target location, or provide the user with a manual prompt.</span>

<span class="s2">        include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">        save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">            model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X,</span>

<span class="s2">            and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">        signatures: Signatures to save with the SavedModel. Applicable to the</span>

<span class="s2">            &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">            `tf.saved_model.save` for details.</span>

<span class="s2">        options: (only applies to SavedModel format)</span>

<span class="s2">            `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">            saving to SavedModel.</span>

<span class="s2">        save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">            SavedModel will store the function traces for each layer. This</span>

<span class="s2">            can be disabled, so that only the configs of each layer are stored.</span>

<span class="s2">            Defaults to `True`. Disabling this will decrease serialization time</span>

<span class="s2">            and reduce file size, but it requires that all custom layers/models</span>

<span class="s2">            implement a `get_config()` method.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    from keras.models import load_model</span>

<span class="s2">    model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">    del model  # deletes the existing model</span>

<span class="s2">    # returns a compiled model</span>

<span class="s2">    # identical to the previous one</span>

<span class="s2">    model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># pylint: enable=line-too-long</span><span class="w"></span>

<span class="w">    </span><span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">overwrite</span><span class="p">,</span><span class="w"> </span><span class="n">include_optimizer</span><span class="p">,</span><span class="w"> </span><span class="n">save_format</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">signatures</span><span class="p">,</span><span class="w"> </span><span class="k">options</span><span class="p">,</span><span class="w"> </span><span class="n">save_traces</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="save_spec_2">save_spec</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_spec</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dynamic_batch</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the <code>tf.TensorSpec</code> of call inputs as a tuple <code>(args, kwargs)</code>.</p>
<p>This value is automatically defined after calling the model for the first
time. Afterwards, you can use it when exporting the model for serving:</p>
<div class="codehilite"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">serve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="c1"># Apply postprocessing steps, or add additional outputs.</span>
  <span class="o">...</span>
  <span class="k">return</span> <span class="n">outputs</span>

<span class="c1"># arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is</span>
<span class="c1"># an empty dict since functional models do not use keyword arguments.</span>
<span class="n">arg_specs</span><span class="p">,</span> <span class="n">kwarg_specs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">save_spec</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">signatures</span><span class="o">=</span><span class="p">{</span>
  <span class="s1">&#39;serving_default&#39;</span><span class="p">:</span> <span class="n">serve</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="o">*</span><span class="n">arg_specs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwarg_specs</span><span class="p">)</span>
<span class="p">})</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>dynamic_batch</td>
<td>Whether to set the batch sizes of all the returned<br><code>tf.TensorSpec</code> to <code>None</code>. (Note that when defining functional or<br>Sequential models with <code>tf.keras.Input([...], batch_size=X)</code>, the<br>batch size will always be preserved). Defaults to <code>True</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>If the model inputs are defined, returns a tuple <code>(args, kwargs)</code>. All<br>elements in <code>args</code> and <code>kwargs</code> are <code>tf.TensorSpec</code>.<br>If the model inputs are not defined, returns <code>None</code>.<br>The model inputs are automatically set when calling the model,<br><code>model.fit</code>, <code>model.evaluate</code> or <code>model.predict</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save_spec</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.</span>

<span class="s2">    This value is automatically defined after calling the model for the first</span>

<span class="s2">    time. Afterwards, you can use it when exporting the model for serving:</span>

<span class="s2">    ```python</span>

<span class="s2">    model = tf.keras.Model(...)</span>

<span class="s2">    @tf.function</span>

<span class="s2">    def serve(*args, **kwargs):</span>

<span class="s2">      outputs = model(*args, **kwargs)</span>

<span class="s2">      # Apply postprocessing steps, or add additional outputs.</span>

<span class="s2">      ...</span>

<span class="s2">      return outputs</span>

<span class="s2">    # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is</span>

<span class="s2">    # an empty dict since functional models do not use keyword arguments.</span>

<span class="s2">    arg_specs, kwarg_specs = model.save_spec()</span>

<span class="s2">    model.save(path, signatures={</span>

<span class="s2">      &#39;serving_default&#39;: serve.get_concrete_function(*arg_specs, **kwarg_specs)</span>

<span class="s2">    })</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      dynamic_batch: Whether to set the batch sizes of all the returned</span>

<span class="s2">        `tf.TensorSpec` to `None`. (Note that when defining functional or</span>

<span class="s2">        Sequential models with `tf.keras.Input([...], batch_size=X)`, the</span>

<span class="s2">        batch size will always be preserved). Defaults to `True`.</span>

<span class="s2">    Returns:</span>

<span class="s2">      If the model inputs are defined, returns a tuple `(args, kwargs)`. All</span>

<span class="s2">      elements in `args` and `kwargs` are `tf.TensorSpec`.</span>

<span class="s2">      If the model inputs are not defined, returns `None`.</span>

<span class="s2">      The model inputs are automatically set when calling the model,</span>

<span class="s2">      `model.fit`, `model.evaluate` or `model.predict`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_save_spec</span><span class="p">(</span><span class="n">dynamic_batch</span><span class="p">,</span><span class="w"> </span><span class="n">inputs_only</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="save_weights_2">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <code>tf.train.Checkpoint</code>, including any <code>Layer</code>
instances or <code>Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code>tf.keras.Model(inputs,
outputs)</code>, <code>Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <code>tf.keras.Model</code>,
<code>Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <code>tf.train.Checkpoint</code> and
<code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should be
loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code> this
is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached. This
means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading into a
<code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa) will not match
the <code>Model</code>'s variables. See the
<a href="https://www.tensorflow.org/guide/checkpoint">guide to training checkpoints</a>
for details on the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>String or PathLike, path to the file to save the weights to.<br>When saving in TensorFlow format, this is the prefix used for<br>checkpoint files (multiple files are generated). Note that the '.h5'<br>suffix causes weights to be saved in HDF5 format.</td>
</tr>
<tr>
<td>overwrite</td>
<td>Whether to silently overwrite any existing file at the<br>target location, or provide the user with a manual prompt.</td>
</tr>
<tr>
<td>save_format</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or<br>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>. Otherwise<br><code>None</code> defaults to 'tf'.</td>
</tr>
<tr>
<td>options</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies<br>options for saving weights.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If <code>h5py</code> is not available when attempting to save in HDF5<br>format.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="err">@</span><span class="n">traceback_utils</span><span class="o">.</span><span class="n">filter_traceback</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                   </span><span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">    Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">    argument.</span>

<span class="sd">    When saving in HDF5 format, the weight file has:</span>

<span class="sd">      - `layer_names` (attribute), a list of strings</span>

<span class="sd">          (ordered names of model layers).</span>

<span class="sd">      - For every layer, a `group` named `layer.name`</span>

<span class="sd">          - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">              a list of strings</span>

<span class="sd">              (ordered names of weights tensor of the layer).</span>

<span class="sd">          - For every weight in the layer, a dataset</span>

<span class="sd">              storing the weight value, named after the weight tensor.</span>

<span class="sd">    When saving in TensorFlow format, all objects referenced by the network are</span>

<span class="sd">    saved in the same format as `tf.train.Checkpoint`, including any `Layer`</span>

<span class="sd">    instances or `Optimizer` instances assigned to object attributes. For</span>

<span class="sd">    networks constructed from inputs and outputs using `tf.keras.Model(inputs,</span>

<span class="sd">    outputs)`, `Layer` instances used by the network are tracked/saved</span>

<span class="sd">    automatically. For user-defined classes which inherit from `tf.keras.Model`,</span>

<span class="sd">    `Layer` instances must be assigned to object attributes, typically in the</span>

<span class="sd">    constructor. See the documentation of `tf.train.Checkpoint` and</span>

<span class="sd">    `tf.keras.Model` for details.</span>

<span class="sd">    While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be</span>

<span class="sd">    loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">    `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">    `save_weights` for training checkpoints.</span>

<span class="sd">    The TensorFlow format matches objects and variables by starting at a root</span>

<span class="sd">    object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">    names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this</span>

<span class="sd">    is the `Checkpoint` even if the `Checkpoint` has a model attached. This</span>

<span class="sd">    means saving a `tf.keras.Model` using `save_weights` and loading into a</span>

<span class="sd">    `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match</span>

<span class="sd">    the `Model`&#39;s variables. See the</span>

<span class="sd">    [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)</span>

<span class="sd">    for details on the TensorFlow format.</span>

<span class="sd">    Args:</span>

<span class="sd">        filepath: String or PathLike, path to the file to save the weights to.</span>

<span class="sd">            When saving in TensorFlow format, this is the prefix used for</span>

<span class="sd">            checkpoint files (multiple files are generated). Note that the &#39;.h5&#39;</span>

<span class="sd">            suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">            target location, or provide the user with a manual prompt.</span>

<span class="sd">        save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">            &#39;.keras&#39; will default to HDF5 if `save_format` is `None`. Otherwise</span>

<span class="sd">            `None` defaults to &#39;tf&#39;.</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for saving weights.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If `h5py` is not available when attempting to save in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">filepath_is_h5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">saving_utils</span><span class="o">.</span><span class="n">is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">user_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">elif</span><span class="w"> </span><span class="n">user_format</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="p">(</span><span class="s1">&#39;hdf5&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;keras&#39;</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">save_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">            </span><span class="n">f</span><span class="s1">&#39;Unknown format. Received: `save_format`={save_format}. Was &#39;</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">filepath_is_h5</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span><span class="w"></span>

<span class="w">          </span><span class="n">f</span><span class="s1">&#39;filepath ({filepath}) looks like an HDF5 file. &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;Omit the &quot;.h5&quot;/&quot;.keras&quot; when saving in TensorFlow format.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">h5py</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ImportError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;`save_weights` requires h5py when saving in hdf5, but h5py is not &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;available. Try installing h5py package.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;tf&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;.index&#39;</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">check_filepath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filepath</span><span class="w"></span>

<span class="w">    </span><span class="c1"># If file exists and should not be overwritten:</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">overwrite</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span><span class="w"></span>

<span class="w">      </span><span class="n">proceed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">proceed</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">save_format</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;h5&#39;</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="n">with</span><span class="w"> </span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">f</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"></span>

<span class="w">      </span><span class="k">else</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="c1"># Record this checkpoint so it&#39;s visible from tf.train.latest_checkpoint.</span><span class="w"></span>

<span class="w">      </span><span class="n">tf</span><span class="o">.</span><span class="n">__internal__</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">update_checkpoint_state</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span><span class="w"></span>

<span class="w">          </span><span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="w"></span>

<span class="w">          </span><span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">])</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="summary_2">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show_trainable</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>Total length of printed lines<br>(e.g. set this to adapt the display to different<br>terminal window sizes).</td>
</tr>
<tr>
<td>positions</td>
<td>Relative or absolute positions of log elements<br>in each line. If not provided,<br>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
</tr>
<tr>
<td>print_fn</td>
<td>Print function to use. Defaults to <code>print</code>.<br>It will be called on each line of the summary.<br>You can set it to a custom function<br>in order to capture the string summary.</td>
</tr>
<tr>
<td>expand_nested</td>
<td>Whether to expand the nested models.<br>If not provided, defaults to <code>False</code>.</td>
</tr>
<tr>
<td>show_trainable</td>
<td>Whether to show if a layer is trainable.<br>If not provided, defaults to <code>False</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">expand_nested</span><span class="o">=</span><span class="no">False</span><span class="p">,</span><span class="w"></span>

<span class="w">              </span><span class="n">show_trainable</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">    Args:</span>

<span class="s2">        line_length: Total length of printed lines</span>

<span class="s2">            (e.g. set this to adapt the display to different</span>

<span class="s2">            terminal window sizes).</span>

<span class="s2">        positions: Relative or absolute positions of log elements</span>

<span class="s2">            in each line. If not provided,</span>

<span class="s2">            defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">        print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">            It will be called on each line of the summary.</span>

<span class="s2">            You can set it to a custom function</span>

<span class="s2">            in order to capture the string summary.</span>

<span class="s2">        expand_nested: Whether to expand the nested models.</span>

<span class="s2">            If not provided, defaults to `False`.</span>

<span class="s2">        show_trainable: Whether to show if a layer is trainable.</span>

<span class="s2">            If not provided, defaults to `False`.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">raise</span><span class="w"> </span><span class="n">ValueError</span><span class="p">(</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;This model has not yet been built. &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;Build the model first by calling `build()` or by calling &#39;</span><span class="w"></span>

<span class="w">          </span><span class="s1">&#39;the model on a batch of data.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">expand_nested</span><span class="o">=</span><span class="n">expand_nested</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="n">show_trainable</span><span class="o">=</span><span class="n">show_trainable</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="test_on_batch_2">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays (in case the<br>    model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors (in case the model has<br>    multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors, if<br>    the model has named inputs.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case of<br>temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated across<br>batches.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">test_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                    </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays (in case the</span>

<span class="s2">              model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors (in case the model has</span>

<span class="s2">              multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors, if</span>

<span class="s2">              the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="test_step_2">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="p">#</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">need</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">get</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">results</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">decoder</span><span class="w"> </span><span class="n">layer</span><span class="w"></span>

<span class="w">        </span><span class="p">#</span><span class="w"> </span><span class="n">Setting</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">True</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">provide</span><span class="w"> </span><span class="n">it</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mh">1</span><span class="o">:</span><span class="mh">3</span><span class="p">],</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_dtype</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">loss_metric</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">m</span><span class="p">.</span><span class="nl">name:</span><span class="w"> </span><span class="n">m</span><span class="p">.</span><span class="n">result</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">}</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="to_json_2">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>Additional keyword arguments<br>to be passed to <code>json.dumps()</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span><span class="w"></span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">    To load a network from a JSON save file, use</span>

<span class="sd">    `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">    Args:</span>

<span class="sd">        **kwargs: Additional keyword arguments</span>

<span class="sd">            to be passed to `json.dumps()`.</span>

<span class="sd">    Returns:</span>

<span class="sd">        A JSON string.</span>

<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">model_config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">model_config</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="to_yaml_2">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>Note: Since TF 2.6, this method is no longer supported and will raise a
RuntimeError.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>Additional keyword arguments<br>to be passed to <code>yaml.dump()</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>announces that the method poses a security risk</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">    Note: Since TF 2.6, this method is no longer supported and will raise a</span>

<span class="s2">    RuntimeError.</span>

<span class="s2">    To load a network from a yaml save file, use</span>

<span class="s2">    `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">    `custom_objects` should be a dictionary mapping</span>

<span class="s2">    the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">    functions / classes.</span>

<span class="s2">    Args:</span>

<span class="s2">        **kwargs: Additional keyword arguments</span>

<span class="s2">            to be passed to `yaml.dump()`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A YAML string.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: announces that the method poses a security risk</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">raise</span><span class="w"> </span><span class="n">RuntimeError</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;Method `model.to_yaml()` has been removed due to security risk of &#39;</span><span class="w"></span>

<span class="w">        </span><span class="s1">&#39;arbitrary code execution. Please use `model.to_json()` instead.&#39;</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="train_on_batch_2">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>Input data. It could be:<br>- A Numpy array (or array-like), or a list of arrays<br>    (in case the model has multiple inputs).<br>- A TensorFlow tensor, or a list of tensors<br>    (in case the model has multiple inputs).<br>- A dict mapping input names to the corresponding array/tensors,<br>    if the model has named inputs.</td>
</tr>
<tr>
<td>y</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy<br>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code><br>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
</tr>
<tr>
<td>sample_weight</td>
<td>Optional array of the same length as x, containing<br>weights to apply to the model's loss for each sample. In the case of<br>temporal data, you can pass a 2D array with shape (samples,<br>sequence_length), to apply a different weight to every timestep of<br>every sample.</td>
</tr>
<tr>
<td>class_weight</td>
<td>Optional dictionary mapping class indices (integers) to a<br>weight (float) to apply to the model's loss for the samples from this<br>class during training. This can be useful to tell the model to "pay<br>more attention" to samples from an under-represented class.</td>
</tr>
<tr>
<td>reset_metrics</td>
<td>If <code>True</code>, the metrics returned will be only for this<br>batch. If <code>False</code>, the metrics will be statefully accumulated across<br>batches.</td>
</tr>
<tr>
<td>return_dict</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,<br>with each key being the name of the metric. If <code>False</code>, they are<br>returned as a list.</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss<br>(if the model has a single output and no metrics)<br>or list of scalars (if the model has multiple outputs<br>and/or metrics). The attribute <code>model.metrics_names</code> will give you<br>the display labels for the scalar outputs.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in a <code>tf.function</code>.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span><span class="w"></span>

<span class="w">                     </span><span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">    </span><span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">    Args:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">              if the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        class_weight: Optional dictionary mapping class indices (integers) to a</span>

<span class="s2">          weight (float) to apply to the model&#39;s loss for the samples from this</span>

<span class="s2">          class during training. This can be useful to tell the model to &quot;</span><span class="n">pay</span><span class="w"></span>

<span class="w">          </span><span class="n">more</span><span class="w"> </span><span class="n">attention</span><span class="s2">&quot; to samples from an under-represented class.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar training loss</span>

<span class="s2">        (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">      RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">reset_metrics</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">         </span><span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="n">iterator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">sample_weight</span><span class="p">,</span><span class="w"></span>

<span class="w">                                                    </span><span class="n">class_weight</span><span class="p">)</span><span class="w"></span>

<span class="w">      </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span><span class="w"></span>

<span class="w">      </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">logs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf_utils</span><span class="p">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">return_dict</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">logs</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="o">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">flatten_metrics_in_order</span><span class="p">(</span><span class="k">logs</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="train_step_2">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">):</span><span class="w"></span>

<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">tape</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">input_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">input_shape</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span><span class="w"> </span><span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span><span class="w"></span>
</code></pre></div>

</details>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../layers/smca/weight_map/" title="Weight Map" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Weight Map
              </span>
            </div>
          </a>
        
        
          <a href="../factory/" title="Factory" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Factory
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["header.autohide"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../../assets/javascripts/workers/search.f8263e09.min.js", "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.4fc53ad4.min.js"></script>
      
    
  </body>
</html>